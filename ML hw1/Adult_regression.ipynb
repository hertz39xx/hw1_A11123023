{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0f6b4d5-3c62-4ab9-9876-3050915e4f37",
   "metadata": {},
   "source": [
    "*目標 -> 迴歸預測：預測hours-per-week數值型欄位的數值*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed5fd8c-40f9-491e-9a51-9ec6afe33b80",
   "metadata": {},
   "source": [
    "**載入資料集**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccafa22c-ad29-4a8e-a5a7-aaa5961c21e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trian data shape:  (32561, 15)\n",
      "test data shape:  (16282, 15)\n",
      "Train features shape: (32561, 15)\n",
      "Test features shape: (16282, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802.0</td>\n",
       "      <td>11th</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951.0</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323.0</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>103497.0</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16276</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>215419.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16277</th>\n",
       "      <td>64</td>\n",
       "      <td>?</td>\n",
       "      <td>321403.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16278</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>374983.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16279</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>83891.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>5455.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16280</th>\n",
       "      <td>35</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>182148.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16281 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age      workclass    fnlwgt      education  education_num   \n",
       "0      25        Private  226802.0           11th            7.0  \\\n",
       "1      38        Private   89814.0        HS-grad            9.0   \n",
       "2      28      Local-gov  336951.0     Assoc-acdm           12.0   \n",
       "3      44        Private  160323.0   Some-college           10.0   \n",
       "4      18              ?  103497.0   Some-college           10.0   \n",
       "...    ..            ...       ...            ...            ...   \n",
       "16276  39        Private  215419.0      Bachelors           13.0   \n",
       "16277  64              ?  321403.0        HS-grad            9.0   \n",
       "16278  38        Private  374983.0      Bachelors           13.0   \n",
       "16279  44        Private   83891.0      Bachelors           13.0   \n",
       "16280  35   Self-emp-inc  182148.0      Bachelors           13.0   \n",
       "\n",
       "            marital_status          occupation     relationship   \n",
       "0            Never-married   Machine-op-inspct        Own-child  \\\n",
       "1       Married-civ-spouse     Farming-fishing          Husband   \n",
       "2       Married-civ-spouse     Protective-serv          Husband   \n",
       "3       Married-civ-spouse   Machine-op-inspct          Husband   \n",
       "4            Never-married                   ?        Own-child   \n",
       "...                    ...                 ...              ...   \n",
       "16276             Divorced      Prof-specialty    Not-in-family   \n",
       "16277              Widowed                   ?   Other-relative   \n",
       "16278   Married-civ-spouse      Prof-specialty          Husband   \n",
       "16279             Divorced        Adm-clerical        Own-child   \n",
       "16280   Married-civ-spouse     Exec-managerial          Husband   \n",
       "\n",
       "                      race      sex  capital_gain  capital_loss   \n",
       "0                    Black     Male           0.0           0.0  \\\n",
       "1                    White     Male           0.0           0.0   \n",
       "2                    White     Male           0.0           0.0   \n",
       "3                    Black     Male        7688.0           0.0   \n",
       "4                    White   Female           0.0           0.0   \n",
       "...                    ...      ...           ...           ...   \n",
       "16276                White   Female           0.0           0.0   \n",
       "16277                Black     Male           0.0           0.0   \n",
       "16278                White     Male           0.0           0.0   \n",
       "16279   Asian-Pac-Islander     Male        5455.0           0.0   \n",
       "16280                White     Male           0.0           0.0   \n",
       "\n",
       "       hours_per_week  native_country   income  \n",
       "0                40.0   United-States   <=50K.  \n",
       "1                50.0   United-States   <=50K.  \n",
       "2                40.0   United-States    >50K.  \n",
       "3                40.0   United-States    >50K.  \n",
       "4                30.0   United-States   <=50K.  \n",
       "...               ...             ...      ...  \n",
       "16276            36.0   United-States   <=50K.  \n",
       "16277            40.0   United-States   <=50K.  \n",
       "16278            50.0   United-States   <=50K.  \n",
       "16279            40.0   United-States   <=50K.  \n",
       "16280            60.0   United-States    >50K.  \n",
       "\n",
       "[16281 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data_path = \"./adult/adult.data\"\n",
    "test_data_path = \"./adult/adult.test\"\n",
    "\n",
    "column_name = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', 'relationship', 'race', 'sex', \n",
    "               'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income']\n",
    "\n",
    "train_data_df = pd.read_csv(train_data_path, names = column_name)\n",
    "test_data_df = pd.read_csv(test_data_path, names = column_name)\n",
    "\n",
    "print(\"trian data shape: \", train_data_df.shape)\n",
    "print(\"test data shape: \", test_data_df.shape)\n",
    "\n",
    "#測試資料的第一row非資料內容，移除掉\n",
    "print(\"Train features shape:\", train_data_df.shape)\n",
    "print(\"Test features shape:\", test_data_df.shape)\n",
    "\n",
    "test_data_df = test_data_df.drop(test_data_df.index[0])\n",
    "test_data_df.reset_index(drop=True, inplace=True)\n",
    "test_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84da3f7-d432-44ee-b7ed-f758bf77406a",
   "metadata": {},
   "source": [
    "**前處理**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6e8f40c-77db-4d57-8e72-fa0aba8b9adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age               0\n",
      "workclass         0\n",
      "fnlwgt            0\n",
      "education         0\n",
      "education_num     0\n",
      "marital_status    0\n",
      "occupation        0\n",
      "relationship      0\n",
      "race              0\n",
      "sex               0\n",
      "capital_gain      0\n",
      "capital_loss      0\n",
      "hours_per_week    0\n",
      "native_country    0\n",
      "income            0\n",
      "dtype: int64\n",
      "--------------------------------------------------\n",
      "workclass值的內容: ['State-gov' 'Self-emp-not-inc' 'Private' 'Federal-gov' 'Local-gov' '?'\n",
      " 'Self-emp-inc' 'Without-pay' 'Never-worked']\n",
      "\n",
      "occupation值的內容: ['Adm-clerical' 'Exec-managerial' 'Handlers-cleaners' 'Prof-specialty'\n",
      " 'Other-service' 'Sales' 'Craft-repair' 'Transport-moving'\n",
      " 'Farming-fishing' 'Machine-op-inspct' 'Tech-support' '?'\n",
      " 'Protective-serv' 'Armed-Forces' 'Priv-house-serv']\n",
      "\n",
      "native-country值的內容: ['United-States' 'Cuba' 'Jamaica' 'India' '?' 'Mexico' 'South'\n",
      " 'Puerto-Rico' 'Honduras' 'England' 'Canada' 'Germany' 'Iran'\n",
      " 'Philippines' 'Italy' 'Poland' 'Columbia' 'Cambodia' 'Thailand' 'Ecuador'\n",
      " 'Laos' 'Taiwan' 'Haiti' 'Portugal' 'Dominican-Republic' 'El-Salvador'\n",
      " 'France' 'Guatemala' 'China' 'Japan' 'Yugoslavia' 'Peru'\n",
      " 'Outlying-US(Guam-USVI-etc)' 'Scotland' 'Trinadad&Tobago' 'Greece'\n",
      " 'Nicaragua' 'Vietnam' 'Hong' 'Ireland' 'Hungary' 'Holand-Netherlands']\n",
      "--------------------------------------------------\n",
      "訓練資料 workclass 中有缺失值的欄位: 1836\n",
      "訓練資料 occupation 中有缺失值的欄位: 1843\n",
      "訓練資料 native_country 中有缺失值的欄位: 583\n",
      "--------------------------------------------------\n",
      "測試資料 workclass 中有缺失值的欄位: 963\n",
      "測試資料 occupation 中有缺失值的欄位: 966\n",
      "測試資料 native_country 中有缺失值的欄位: 274\n",
      "train_data: (30162, 15)\n",
      "test_data: (15060, 15)\n",
      "--------------------------------------------------\n",
      "age 中有缺失值的欄位: 0\n",
      "workclass 中有缺失值的欄位: 0\n",
      "fnlwgt 中有缺失值的欄位: 0\n",
      "education 中有缺失值的欄位: 0\n",
      "education_num 中有缺失值的欄位: 0\n",
      "marital_status 中有缺失值的欄位: 0\n",
      "occupation 中有缺失值的欄位: 0\n",
      "relationship 中有缺失值的欄位: 0\n",
      "race 中有缺失值的欄位: 0\n",
      "sex 中有缺失值的欄位: 0\n",
      "capital_gain 中有缺失值的欄位: 0\n",
      "capital_loss 中有缺失值的欄位: 0\n",
      "hours_per_week 中有缺失值的欄位: 0\n",
      "native_country 中有缺失值的欄位: 0\n",
      "income 中有缺失值的欄位: 0\n",
      "--------------------------------------------------\n",
      "age 中有缺失值的欄位: 0\n",
      "workclass 中有缺失值的欄位: 0\n",
      "fnlwgt 中有缺失值的欄位: 0\n",
      "education 中有缺失值的欄位: 0\n",
      "education_num 中有缺失值的欄位: 0\n",
      "marital_status 中有缺失值的欄位: 0\n",
      "occupation 中有缺失值的欄位: 0\n",
      "relationship 中有缺失值的欄位: 0\n",
      "race 中有缺失值的欄位: 0\n",
      "sex 中有缺失值的欄位: 0\n",
      "capital_gain 中有缺失值的欄位: 0\n",
      "capital_loss 中有缺失值的欄位: 0\n",
      "hours_per_week 中有缺失值的欄位: 0\n",
      "native_country 中有缺失值的欄位: 0\n",
      "income 中有缺失值的欄位: 0\n"
     ]
    }
   ],
   "source": [
    "# 移除字串前的空白 & 收入後方的.\n",
    "train_data_df = train_data_df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "test_data_df = test_data_df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "train_data_df[\"income\"] = train_data_df[\"income\"].str.replace(\".\", \"\")\n",
    "test_data_df[\"income\"] = test_data_df[\"income\"].str.replace(\".\", \"\")\n",
    "\n",
    "# 檢查缺失值\n",
    "print(train_data_df.isnull().sum()) # 檢查空值\n",
    "print(\"-\"*50)\n",
    "\n",
    "# 檢查缺失值使用什麼替代\n",
    "print(\"workclass值的內容:\", train_data_df.workclass.unique())\n",
    "print(\"\\noccupation值的內容:\", train_data_df.occupation.unique())\n",
    "print(\"\\nnative-country值的內容:\", train_data_df.native_country.unique())\n",
    "print(\"-\"*50)\n",
    "\n",
    "# 確認缺失值數量\n",
    "check_columns = ['workclass', 'occupation', 'native_country']\n",
    "for check_c in check_columns:\n",
    "    print(\"訓練資料\", check_c, \"中有缺失值的欄位:\",train_data_df[check_c].isin(['?']).sum())\n",
    "print(\"-\"*50)\n",
    "for check_c in check_columns:\n",
    "    print(\"測試資料\", check_c, \"中有缺失值的欄位:\",test_data_df[check_c].isin(['?']).sum())\n",
    "\n",
    "# 把具有缺失值的資料去除掉\n",
    "train_data_df = train_data_df[(train_data_df.workclass != \"?\") & (train_data_df.occupation != \"?\") & (train_data_df.native_country != \"?\")]\n",
    "test_data_df = test_data_df[(test_data_df.workclass != \"?\") & (test_data_df.occupation != \"?\") & (test_data_df.native_country != \"?\")]\n",
    "\n",
    "print(\"train_data:\", train_data_df.shape)\n",
    "print(\"test_data:\", test_data_df.shape)\n",
    "\n",
    "print(\"-\"*50)\n",
    "for check_c in train_data_df.columns:\n",
    "    print(check_c, \"中有缺失值的欄位:\",train_data_df[check_c].isin(['?']).sum())\n",
    "print(\"-\"*50)\n",
    "for check_c in test_data_df.columns:\n",
    "    print(check_c, \"中有缺失值的欄位:\",test_data_df[check_c].isin(['?']).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2560b978-5d3e-4d39-93ce-f20eafd9fd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "education值的內容: ['Bachelors' 'HS-grad' '11th' 'Masters' '9th' 'Some-college' 'Assoc-acdm'\n",
      " '7th-8th' 'Doctorate' 'Assoc-voc' 'Prof-school' '5th-6th' '10th'\n",
      " 'Preschool' '12th' '1st-4th']\n",
      "education_num值的內容: [13  9  7 14  5 10 12  4 16 11 15  3  6  1  8  2]\n",
      "['Bachelors'] 13\n",
      "['HS-grad'] 9\n",
      "['11th'] 7\n",
      "['Masters'] 14\n",
      "['9th'] 5\n",
      "['Some-college'] 10\n",
      "['Assoc-acdm'] 12\n",
      "['7th-8th'] 4\n",
      "['Doctorate'] 16\n",
      "['Assoc-voc'] 11\n",
      "['Prof-school'] 15\n",
      "['5th-6th'] 3\n",
      "['10th'] 6\n",
      "['Preschool'] 1\n",
      "['12th'] 8\n",
      "['1st-4th'] 2\n",
      "Index(['age', 'workclass', 'fnlwgt', 'education_num', 'marital_status',\n",
      "       'occupation', 'relationship', 'race', 'sex', 'capital_gain',\n",
      "       'capital_loss', 'hours_per_week', 'native_country', 'income'],\n",
      "      dtype='object')\n",
      "Index(['age', 'workclass', 'fnlwgt', 'education_num', 'marital_status',\n",
      "       'occupation', 'relationship', 'race', 'sex', 'capital_gain',\n",
      "       'capital_loss', 'hours_per_week', 'native_country', 'income'],\n",
      "      dtype='object')\n",
      "marital_status值的內容: ['Never-married' 'Married-civ-spouse' 'Divorced' 'Married-spouse-absent'\n",
      " 'Separated' 'Married-AF-spouse' 'Widowed']\n",
      "marital_status值的內容: ['Never-married' 'Married' 'Divorced' 'Separated' 'Widowed']\n",
      "workclass值的內容: ['Goverment' 'Self-employed' 'Private' 'Unpaid']\n"
     ]
    }
   ],
   "source": [
    "# 檢查 education 以及 education_num 是否代表一樣的學歷, 若一樣則保留education_num即可\n",
    "\n",
    "print(\"education值的內容:\", train_data_df.education.unique())\n",
    "print(\"education_num值的內容:\", train_data_df.education_num.unique())\n",
    "\n",
    "edu_level = train_data_df.education_num.unique()\n",
    "\n",
    "for i in train_data_df.education_num.unique():\n",
    "    print(train_data_df[train_data_df[\"education_num\"] == i][\"education\"].unique(), i)\n",
    "\n",
    "# 意義相同且數字大小與學歷高低有關, 去除掉 education :D\n",
    "train_data_df = train_data_df.drop(\"education\", axis=1)\n",
    "test_data_df = test_data_df.drop(\"education\", axis=1)\n",
    "print(train_data_df.columns)\n",
    "print(test_data_df.columns)\n",
    "\n",
    "print(\"marital_status值的內容:\", train_data_df.marital_status.unique())\n",
    "\n",
    "# 參照 United States Census Bureau 轉換 marital_status 欄位\n",
    "\n",
    "marital_replace_dice = {\n",
    "    \"Never-married\": \"Never-married\",\n",
    "    \"Married-civ-spouse\": \"Married\",\n",
    "    \"Divorced\": \"Divorced\",\n",
    "    \"Married-spouse-absent\": \"Married\",\n",
    "    \"Separated\": \"Separated\",\n",
    "    \"Married-AF-spouse\": \"Married\",\n",
    "    \"Widowed\": \"Widowed\"\n",
    "}\n",
    "\n",
    "train_data_df[\"marital_status\"] = train_data_df[\"marital_status\"].replace(marital_replace_dice)\n",
    "test_data_df[\"marital_status\"] = test_data_df[\"marital_status\"].replace(marital_replace_dice)\n",
    "\n",
    "print(\"marital_status值的內容:\", train_data_df.marital_status.unique())\n",
    "\n",
    "# 參照 United States Census Bureau 轉換 workclass\n",
    "\n",
    "workclass_replace_dict = {\n",
    "    \"State-gov\": \"Goverment\",\n",
    "    \"Self-emp-not-inc\": \"Self-employed\",\n",
    "    \"Private\": \"Private\",\n",
    "    \"Federal-gov\": \"Goverment\",\n",
    "    \"Local-gov\": \"Goverment\",\n",
    "    \"Self-emp-inc\": \"Self-employed\",\n",
    "    \"Without-pay\": \"Unpaid\",\n",
    "    \"Never-worked\": \"Unpaid\"\n",
    "}\n",
    "\n",
    "train_data_df[\"workclass\"] = train_data_df[\"workclass\"].replace(workclass_replace_dict)\n",
    "test_data_df[\"workclass\"] = test_data_df[\"workclass\"].replace(workclass_replace_dict)\n",
    "\n",
    "print(\"workclass值的內容:\", train_data_df.workclass.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270ef5f0-77af-44c9-a763-b2b33269fff7",
   "metadata": {},
   "source": [
    "**將名目欄位轉換成數值欄位**  \n",
    "income及sex為二元分類的欄位，使用labelEncoder轉換成0跟1  \n",
    "其他名目欄位數值之間沒有大小關係(如種族之類的)，因此用one-hot轉換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff0a7747-177f-4656-b7e1-fdd78536b0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test features shape: (15060, 83)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "category_columns = ['workclass', 'marital_status', 'occupation', 'relationship', 'race','native_country']\n",
    "binary_columns = ['income', 'sex']\n",
    "\n",
    "for col in binary_columns:\n",
    "    train_data_df[col] = labelencoder.fit_transform(train_data_df[col])\n",
    "    test_data_df[col] = labelencoder.transform(test_data_df[col])\n",
    "\n",
    "# 使用pd.get_dummies()對多類別型特徵進行one-hot encoding\n",
    "train_data_df = pd.get_dummies(train_data_df, columns=category_columns)\n",
    "test_data_df = pd.get_dummies(test_data_df, columns=category_columns)\n",
    "\n",
    "missing_columns = set(train_data_df.columns) - set(test_data_df.columns)\n",
    "for col in missing_columns:\n",
    "    test_data_df[col] = 0\n",
    "\n",
    "print(\"Test features shape:\", test_data_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "642d9980-c336-4557-97a8-5f734d982c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features shape: (30162, 82)\n",
      "Test features shape: (15060, 82)\n"
     ]
    }
   ],
   "source": [
    "# 分離特徵跟預測目標\n",
    "\n",
    "train_features = train_data_df.drop(columns=['hours_per_week'])\n",
    "train_target = train_data_df['hours_per_week']\n",
    "\n",
    "test_features = test_data_df.drop(columns=['hours_per_week'])\n",
    "test_target = test_data_df['hours_per_week']\n",
    "\n",
    "print(\"Train features shape:\", train_features.shape)\n",
    "print(\"Test features shape:\", test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6414620-4388-4078-ab99-1c1c61f1309a",
   "metadata": {},
   "source": [
    "**正規化**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4e60751-dd52-4db4-8cf5-d4061f72b19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education_num</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>income</th>\n",
       "      <th>workclass_Goverment</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>workclass_Self-employed</th>\n",
       "      <th>...</th>\n",
       "      <th>native_country_Portugal</th>\n",
       "      <th>native_country_Puerto-Rico</th>\n",
       "      <th>native_country_Scotland</th>\n",
       "      <th>native_country_South</th>\n",
       "      <th>native_country_Taiwan</th>\n",
       "      <th>native_country_Thailand</th>\n",
       "      <th>native_country_Trinadad&amp;Tobago</th>\n",
       "      <th>native_country_United-States</th>\n",
       "      <th>native_country_Vietnam</th>\n",
       "      <th>native_country_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.042796</td>\n",
       "      <td>-1.062722</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>1</td>\n",
       "      <td>0.146092</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>0</td>\n",
       "      <td>2.456096</td>\n",
       "      <td>-1.682144</td>\n",
       "      <td>-0.366577</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033593</td>\n",
       "      <td>-0.060224</td>\n",
       "      <td>-0.019101</td>\n",
       "      <td>-0.048575</td>\n",
       "      <td>-0.037342</td>\n",
       "      <td>-0.023747</td>\n",
       "      <td>-0.024436</td>\n",
       "      <td>0.310871</td>\n",
       "      <td>-0.046113</td>\n",
       "      <td>-0.023038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.880288</td>\n",
       "      <td>-1.007871</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.407150</td>\n",
       "      <td>-1.682144</td>\n",
       "      <td>2.727938</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033593</td>\n",
       "      <td>-0.060224</td>\n",
       "      <td>-0.019101</td>\n",
       "      <td>-0.048575</td>\n",
       "      <td>-0.037342</td>\n",
       "      <td>-0.023747</td>\n",
       "      <td>-0.024436</td>\n",
       "      <td>0.310871</td>\n",
       "      <td>-0.046113</td>\n",
       "      <td>-0.023038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.033340</td>\n",
       "      <td>0.244693</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.407150</td>\n",
       "      <td>0.594479</td>\n",
       "      <td>-0.366577</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033593</td>\n",
       "      <td>-0.060224</td>\n",
       "      <td>-0.019101</td>\n",
       "      <td>-0.048575</td>\n",
       "      <td>-0.037342</td>\n",
       "      <td>-0.023747</td>\n",
       "      <td>-0.024436</td>\n",
       "      <td>0.310871</td>\n",
       "      <td>-0.046113</td>\n",
       "      <td>-0.023038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.108695</td>\n",
       "      <td>0.425240</td>\n",
       "      <td>-1.224066</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.407150</td>\n",
       "      <td>0.594479</td>\n",
       "      <td>-0.366577</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033593</td>\n",
       "      <td>-0.060224</td>\n",
       "      <td>-0.019101</td>\n",
       "      <td>-0.048575</td>\n",
       "      <td>-0.037342</td>\n",
       "      <td>-0.023747</td>\n",
       "      <td>-0.024436</td>\n",
       "      <td>0.310871</td>\n",
       "      <td>-0.046113</td>\n",
       "      <td>-0.023038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.794697</td>\n",
       "      <td>1.406658</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.407150</td>\n",
       "      <td>0.594479</td>\n",
       "      <td>-0.366577</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033593</td>\n",
       "      <td>-0.060224</td>\n",
       "      <td>-0.019101</td>\n",
       "      <td>-0.048575</td>\n",
       "      <td>-0.037342</td>\n",
       "      <td>-0.023747</td>\n",
       "      <td>-0.024436</td>\n",
       "      <td>-3.216773</td>\n",
       "      <td>-0.046113</td>\n",
       "      <td>-0.023038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>-0.870832</td>\n",
       "      <td>0.638972</td>\n",
       "      <td>0.736754</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.407150</td>\n",
       "      <td>0.594479</td>\n",
       "      <td>-0.366577</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033593</td>\n",
       "      <td>-0.060224</td>\n",
       "      <td>-0.019101</td>\n",
       "      <td>-0.048575</td>\n",
       "      <td>-0.037342</td>\n",
       "      <td>-0.023747</td>\n",
       "      <td>-0.024436</td>\n",
       "      <td>0.310871</td>\n",
       "      <td>-0.046113</td>\n",
       "      <td>-0.023038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>0.118931</td>\n",
       "      <td>-0.335252</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.407150</td>\n",
       "      <td>0.594479</td>\n",
       "      <td>-0.366577</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033593</td>\n",
       "      <td>-0.060224</td>\n",
       "      <td>-0.019101</td>\n",
       "      <td>-0.048575</td>\n",
       "      <td>-0.037342</td>\n",
       "      <td>-0.023747</td>\n",
       "      <td>-0.024436</td>\n",
       "      <td>0.310871</td>\n",
       "      <td>-0.046113</td>\n",
       "      <td>-0.023038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>1.489374</td>\n",
       "      <td>-0.358575</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.407150</td>\n",
       "      <td>0.594479</td>\n",
       "      <td>-0.366577</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033593</td>\n",
       "      <td>-0.060224</td>\n",
       "      <td>-0.019101</td>\n",
       "      <td>-0.048575</td>\n",
       "      <td>-0.037342</td>\n",
       "      <td>-0.023747</td>\n",
       "      <td>-0.024436</td>\n",
       "      <td>0.310871</td>\n",
       "      <td>-0.046113</td>\n",
       "      <td>-0.023038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>-1.251511</td>\n",
       "      <td>0.110705</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.407150</td>\n",
       "      <td>0.594479</td>\n",
       "      <td>-0.366577</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033593</td>\n",
       "      <td>-0.060224</td>\n",
       "      <td>-0.019101</td>\n",
       "      <td>-0.048575</td>\n",
       "      <td>-0.037342</td>\n",
       "      <td>-0.023747</td>\n",
       "      <td>-0.024436</td>\n",
       "      <td>0.310871</td>\n",
       "      <td>-0.046113</td>\n",
       "      <td>-0.023038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>1.032559</td>\n",
       "      <td>0.928841</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>0</td>\n",
       "      <td>1.881120</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.407150</td>\n",
       "      <td>-1.682144</td>\n",
       "      <td>2.727938</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033593</td>\n",
       "      <td>-0.060224</td>\n",
       "      <td>-0.019101</td>\n",
       "      <td>-0.048575</td>\n",
       "      <td>-0.037342</td>\n",
       "      <td>-0.023747</td>\n",
       "      <td>-0.024436</td>\n",
       "      <td>0.310871</td>\n",
       "      <td>-0.046113</td>\n",
       "      <td>-0.023038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30162 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age    fnlwgt  education_num  sex  capital_gain  capital_loss   \n",
       "0      0.042796 -1.062722       1.128918    1      0.146092     -0.218586  \\\n",
       "1      0.880288 -1.007871       1.128918    1     -0.147445     -0.218586   \n",
       "2     -0.033340  0.244693      -0.439738    1     -0.147445     -0.218586   \n",
       "3      1.108695  0.425240      -1.224066    1     -0.147445     -0.218586   \n",
       "4     -0.794697  1.406658       1.128918    0     -0.147445     -0.218586   \n",
       "...         ...       ...            ...  ...           ...           ...   \n",
       "32556 -0.870832  0.638972       0.736754    0     -0.147445     -0.218586   \n",
       "32557  0.118931 -0.335252      -0.439738    1     -0.147445     -0.218586   \n",
       "32558  1.489374 -0.358575      -0.439738    0     -0.147445     -0.218586   \n",
       "32559 -1.251511  0.110705      -0.439738    1     -0.147445     -0.218586   \n",
       "32560  1.032559  0.928841      -0.439738    0      1.881120     -0.218586   \n",
       "\n",
       "       income  workclass_Goverment  workclass_Private   \n",
       "0           0             2.456096          -1.682144  \\\n",
       "1           0            -0.407150          -1.682144   \n",
       "2           0            -0.407150           0.594479   \n",
       "3           0            -0.407150           0.594479   \n",
       "4           0            -0.407150           0.594479   \n",
       "...       ...                  ...                ...   \n",
       "32556       0            -0.407150           0.594479   \n",
       "32557       1            -0.407150           0.594479   \n",
       "32558       0            -0.407150           0.594479   \n",
       "32559       0            -0.407150           0.594479   \n",
       "32560       1            -0.407150          -1.682144   \n",
       "\n",
       "       workclass_Self-employed  ...  native_country_Portugal   \n",
       "0                    -0.366577  ...                -0.033593  \\\n",
       "1                     2.727938  ...                -0.033593   \n",
       "2                    -0.366577  ...                -0.033593   \n",
       "3                    -0.366577  ...                -0.033593   \n",
       "4                    -0.366577  ...                -0.033593   \n",
       "...                        ...  ...                      ...   \n",
       "32556                -0.366577  ...                -0.033593   \n",
       "32557                -0.366577  ...                -0.033593   \n",
       "32558                -0.366577  ...                -0.033593   \n",
       "32559                -0.366577  ...                -0.033593   \n",
       "32560                 2.727938  ...                -0.033593   \n",
       "\n",
       "       native_country_Puerto-Rico  native_country_Scotland   \n",
       "0                       -0.060224                -0.019101  \\\n",
       "1                       -0.060224                -0.019101   \n",
       "2                       -0.060224                -0.019101   \n",
       "3                       -0.060224                -0.019101   \n",
       "4                       -0.060224                -0.019101   \n",
       "...                           ...                      ...   \n",
       "32556                   -0.060224                -0.019101   \n",
       "32557                   -0.060224                -0.019101   \n",
       "32558                   -0.060224                -0.019101   \n",
       "32559                   -0.060224                -0.019101   \n",
       "32560                   -0.060224                -0.019101   \n",
       "\n",
       "       native_country_South  native_country_Taiwan  native_country_Thailand   \n",
       "0                 -0.048575              -0.037342                -0.023747  \\\n",
       "1                 -0.048575              -0.037342                -0.023747   \n",
       "2                 -0.048575              -0.037342                -0.023747   \n",
       "3                 -0.048575              -0.037342                -0.023747   \n",
       "4                 -0.048575              -0.037342                -0.023747   \n",
       "...                     ...                    ...                      ...   \n",
       "32556             -0.048575              -0.037342                -0.023747   \n",
       "32557             -0.048575              -0.037342                -0.023747   \n",
       "32558             -0.048575              -0.037342                -0.023747   \n",
       "32559             -0.048575              -0.037342                -0.023747   \n",
       "32560             -0.048575              -0.037342                -0.023747   \n",
       "\n",
       "       native_country_Trinadad&Tobago  native_country_United-States   \n",
       "0                           -0.024436                      0.310871  \\\n",
       "1                           -0.024436                      0.310871   \n",
       "2                           -0.024436                      0.310871   \n",
       "3                           -0.024436                      0.310871   \n",
       "4                           -0.024436                     -3.216773   \n",
       "...                               ...                           ...   \n",
       "32556                       -0.024436                      0.310871   \n",
       "32557                       -0.024436                      0.310871   \n",
       "32558                       -0.024436                      0.310871   \n",
       "32559                       -0.024436                      0.310871   \n",
       "32560                       -0.024436                      0.310871   \n",
       "\n",
       "       native_country_Vietnam  native_country_Yugoslavia  \n",
       "0                   -0.046113                  -0.023038  \n",
       "1                   -0.046113                  -0.023038  \n",
       "2                   -0.046113                  -0.023038  \n",
       "3                   -0.046113                  -0.023038  \n",
       "4                   -0.046113                  -0.023038  \n",
       "...                       ...                        ...  \n",
       "32556               -0.046113                  -0.023038  \n",
       "32557               -0.046113                  -0.023038  \n",
       "32558               -0.046113                  -0.023038  \n",
       "32559               -0.046113                  -0.023038  \n",
       "32560               -0.046113                  -0.023038  \n",
       "\n",
       "[30162 rows x 82 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean = train_features.mean(axis=0)\n",
    "# train_features -= mean\n",
    "# std = train_features.std(axis=0)\n",
    "# train_features /= std\n",
    "\n",
    "# test_features -= mean\n",
    "# test_features /= std\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "standardscaler = StandardScaler()\n",
    "\n",
    "# 篩選出不在binary_columns和category_columns中的特徵欄位\n",
    "numerical_columns = [col for col in train_features.columns if col not in binary_columns + category_columns]\n",
    "\n",
    "# 對這些特徵欄位進行正規化\n",
    "standardscaler.fit(train_features[numerical_columns])\n",
    "scaled_values_train = standardscaler.transform(train_features[numerical_columns])\n",
    "train_features[numerical_columns] = scaled_values_train\n",
    "\n",
    "scaled_values_test = standardscaler.transform(test_features[numerical_columns])\n",
    "test_features[numerical_columns] = scaled_values_test\n",
    "\n",
    "# 確保特徵欄位名稱不變\n",
    "train_features.columns = train_features.columns\n",
    "test_features.columns = test_features.columns\n",
    "\n",
    "train_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e9f24f-48ee-4a81-aaed-4a1c45f80ae6",
   "metadata": {},
   "source": [
    "**預處理結束，建立模型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8540e78e-6b04-48b7-a17c-59b4b9a93f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(true, pred):\n",
    "    abs_percentage_error = []\n",
    "    for true_val, pred_val in zip(true, pred):\n",
    "        abs_error = np.abs(true_val - pred_val)\n",
    "        abs_percentage_error.append(abs_error / max(np.abs(true_val), 1))\n",
    "    mape = np.mean(abs_percentage_error) * 100\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13951915-dc8c-4c0e-a778-7525a90be832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 224.6463 - mae: 9.9727\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 192.4971 - mae: 8.6612\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "訓練集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 27.904987335205078\n",
      "RMSE score: 14.235763666311897\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import math\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "history = model.fit(train_features, train_target, epochs=1, batch_size=32)\n",
    "    \n",
    "test_mse_score, test_mae_score = model.evaluate(test_features, test_target)\n",
    "\n",
    "train_predict = model.predict(train_features)\n",
    "test_mape_score = mean_absolute_percentage_error(train_target, train_predict)\n",
    "test_rmse_score = math.sqrt(test_mse_score)\n",
    "\n",
    "print(\"-\"*50)\n",
    "print(\"訓練集績效:\")\n",
    "print(\"MAE score:\", test_mae_score)\n",
    "print(\"MAPE score:\", test_mape_score)\n",
    "print(\"RMSE score:\", test_rmse_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dbfc09f-7f95-4aa3-a677-063032cf63c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "MAE score: 8.81426407185842\n",
      "MAPE score: 30.825048685073853\n",
      "RMSE score: 14.239368114492928\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(test_features)\n",
    "\n",
    "mae = mean_absolute_error(test_target, prediction)\n",
    "mape = mean_absolute_percentage_error(test_target, prediction)\n",
    "mse = mean_squared_error(test_target, prediction)\n",
    "rmse = math.sqrt(mse)\n",
    "    \n",
    "print(\"-\"*50)\n",
    "print(\"MAE score:\", mae)\n",
    "print(\"MAPE score:\", mape)\n",
    "print(\"RMSE score:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb6cc56-9b2a-4355-8438-ddab5be7d352",
   "metadata": {},
   "source": [
    "**超參數實驗**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6c0ad04-a88d-4bdd-9798-b686b6ca70d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "943/943 - 2s - 2ms/step - loss: 487.1689 - mae: 16.4501\n",
      "Epoch 2/5\n",
      "943/943 - 1s - 1ms/step - loss: 122.1035 - mae: 7.7886\n",
      "Epoch 3/5\n",
      "943/943 - 1s - 1ms/step - loss: 117.3680 - mae: 7.5514\n",
      "Epoch 4/5\n",
      "943/943 - 1s - 978us/step - loss: 114.7311 - mae: 7.4289\n",
      "Epoch 5/5\n",
      "943/943 - 1s - 985us/step - loss: 112.3978 - mae: 7.3239\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 107.1999 - mae: 7.1421\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 983us/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點64, epoch5, batch32 訓練集績效:\n",
      "MAE score: 7.222611904144287\n",
      "MAPE score: 26.867493987083435\n",
      "RMSE score: 10.513422787837476\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點64, epoch5, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 30.203649401664734\n",
      "RMSE score: 14.235763666311897\n",
      "WARNING:tensorflow:From C:\\Users\\love7\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:73: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "Epoch 1/5\n",
      "472/472 - 1s - 3ms/step - loss: 655.8179 - mae: 20.8482\n",
      "Epoch 2/5\n",
      "472/472 - 0s - 1ms/step - loss: 128.5428 - mae: 8.0709\n",
      "Epoch 3/5\n",
      "472/472 - 1s - 2ms/step - loss: 121.5584 - mae: 7.7481\n",
      "Epoch 4/5\n",
      "472/472 - 1s - 1ms/step - loss: 118.3102 - mae: 7.5893\n",
      "Epoch 5/5\n",
      "472/472 - 1s - 1ms/step - loss: 116.3100 - mae: 7.4942\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 111.3820 - mae: 7.3449\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點64, epoch5, batch64 訓練集績效:\n",
      "MAE score: 7.421987056732178\n",
      "MAPE score: 27.84073054790497\n",
      "RMSE score: 10.702857689408308\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點64, epoch5, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 30.5501788854599\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "236/236 - 1s - 5ms/step - loss: 1245.9225 - mae: 32.8820\n",
      "Epoch 2/5\n",
      "236/236 - 0s - 1ms/step - loss: 231.5026 - mae: 11.7855\n",
      "Epoch 3/5\n",
      "236/236 - 0s - 2ms/step - loss: 129.7339 - mae: 8.0843\n",
      "Epoch 4/5\n",
      "236/236 - 0s - 1ms/step - loss: 123.8275 - mae: 7.8546\n",
      "Epoch 5/5\n",
      "236/236 - 0s - 1ms/step - loss: 120.5337 - mae: 7.7150\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 115.2770 - mae: 7.5636\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點64, epoch5, batch128 訓練集績效:\n",
      "MAE score: 7.647298336029053\n",
      "MAPE score: 28.31076681613922\n",
      "RMSE score: 10.895463653964583\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點64, epoch5, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 30.916696786880493\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "118/118 - 1s - 9ms/step - loss: 1532.1666 - mae: 37.2374\n",
      "Epoch 2/5\n",
      "118/118 - 0s - 1ms/step - loss: 849.6845 - mae: 26.6802\n",
      "Epoch 3/5\n",
      "118/118 - 0s - 1ms/step - loss: 314.5015 - mae: 14.5468\n",
      "Epoch 4/5\n",
      "118/118 - 0s - 1ms/step - loss: 152.2759 - mae: 9.1296\n",
      "Epoch 5/5\n",
      "118/118 - 0s - 1ms/step - loss: 132.7650 - mae: 8.2459\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 957us/step - loss: 125.7481 - mae: 8.0374\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點64, epoch5, batch256 訓練集績效:\n",
      "MAE score: 8.118735313415527\n",
      "MAPE score: 29.46229577064514\n",
      "RMSE score: 11.379989703396662\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點64, epoch5, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 32.13045299053192\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "943/943 - 2s - 2ms/step - loss: 466.2333 - mae: 16.0456\n",
      "Epoch 2/10\n",
      "943/943 - 1s - 935us/step - loss: 121.1091 - mae: 7.7304\n",
      "Epoch 3/10\n",
      "943/943 - 1s - 938us/step - loss: 116.9238 - mae: 7.5223\n",
      "Epoch 4/10\n",
      "943/943 - 1s - 954us/step - loss: 114.6658 - mae: 7.4086\n",
      "Epoch 5/10\n",
      "943/943 - 1s - 938us/step - loss: 112.7827 - mae: 7.3347\n",
      "Epoch 6/10\n",
      "943/943 - 1s - 951us/step - loss: 111.0506 - mae: 7.2703\n",
      "Epoch 7/10\n",
      "943/943 - 1s - 902us/step - loss: 109.6565 - mae: 7.2208\n",
      "Epoch 8/10\n",
      "943/943 - 1s - 929us/step - loss: 108.5124 - mae: 7.1829\n",
      "Epoch 9/10\n",
      "943/943 - 1s - 949us/step - loss: 107.6070 - mae: 7.1624\n",
      "Epoch 10/10\n",
      "943/943 - 1s - 1ms/step - loss: 107.0205 - mae: 7.1403\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 943us/step - loss: 102.2988 - mae: 6.9520\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 982us/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點64, epoch10, batch32 訓練集績效:\n",
      "MAE score: 7.028019905090332\n",
      "MAPE score: 25.865256786346436\n",
      "RMSE score: 10.265083937415588\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點64, epoch10, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.877708315849304\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "472/472 - 2s - 5ms/step - loss: 739.3182 - mae: 22.5124\n",
      "Epoch 2/10\n",
      "472/472 - 1s - 2ms/step - loss: 130.2019 - mae: 8.1272\n",
      "Epoch 3/10\n",
      "472/472 - 1s - 2ms/step - loss: 121.9059 - mae: 7.7737\n",
      "Epoch 4/10\n",
      "472/472 - 0s - 1ms/step - loss: 118.4181 - mae: 7.6002\n",
      "Epoch 5/10\n",
      "472/472 - 0s - 972us/step - loss: 116.3318 - mae: 7.4883\n",
      "Epoch 6/10\n",
      "472/472 - 0s - 966us/step - loss: 114.1822 - mae: 7.3906\n",
      "Epoch 7/10\n",
      "472/472 - 0s - 975us/step - loss: 112.6697 - mae: 7.3185\n",
      "Epoch 8/10\n",
      "472/472 - 0s - 975us/step - loss: 111.1980 - mae: 7.2678\n",
      "Epoch 9/10\n",
      "472/472 - 0s - 983us/step - loss: 110.0735 - mae: 7.2185\n",
      "Epoch 10/10\n",
      "472/472 - 0s - 960us/step - loss: 108.8545 - mae: 7.1858\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 990us/step - loss: 104.1810 - mae: 7.0304\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點64, epoch10, batch64 訓練集績效:\n",
      "MAE score: 7.11116886138916\n",
      "MAPE score: 26.319333910942078\n",
      "RMSE score: 10.364886030572542\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點64, epoch10, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.305025935173035\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "236/236 - 1s - 4ms/step - loss: 1220.5598 - mae: 32.4916\n",
      "Epoch 2/10\n",
      "236/236 - 0s - 1ms/step - loss: 239.6333 - mae: 12.1313\n",
      "Epoch 3/10\n",
      "236/236 - 0s - 1ms/step - loss: 130.8415 - mae: 8.1689\n",
      "Epoch 4/10\n",
      "236/236 - 0s - 1ms/step - loss: 124.1279 - mae: 7.9115\n",
      "Epoch 5/10\n",
      "236/236 - 0s - 1ms/step - loss: 120.6845 - mae: 7.7510\n",
      "Epoch 6/10\n",
      "236/236 - 0s - 1ms/step - loss: 118.2782 - mae: 7.6422\n",
      "Epoch 7/10\n",
      "236/236 - 0s - 1ms/step - loss: 116.4498 - mae: 7.5640\n",
      "Epoch 8/10\n",
      "236/236 - 0s - 1ms/step - loss: 115.0834 - mae: 7.4936\n",
      "Epoch 9/10\n",
      "236/236 - 0s - 1ms/step - loss: 113.8199 - mae: 7.4307\n",
      "Epoch 10/10\n",
      "236/236 - 0s - 1ms/step - loss: 112.8893 - mae: 7.3870\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 965us/step - loss: 108.2651 - mae: 7.2762\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點64, epoch10, batch128 訓練集績效:\n",
      "MAE score: 7.354572296142578\n",
      "MAPE score: 27.23422348499298\n",
      "RMSE score: 10.565355264853075\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點64, epoch10, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 30.288007855415344\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "118/118 - 1s - 7ms/step - loss: 1514.0427 - mae: 37.0212\n",
      "Epoch 2/10\n",
      "118/118 - 0s - 1ms/step - loss: 813.3915 - mae: 26.0343\n",
      "Epoch 3/10\n",
      "118/118 - 0s - 3ms/step - loss: 285.6872 - mae: 13.7996\n",
      "Epoch 4/10\n",
      "118/118 - 0s - 1ms/step - loss: 147.8082 - mae: 8.9048\n",
      "Epoch 5/10\n",
      "118/118 - 0s - 1ms/step - loss: 132.0134 - mae: 8.2154\n",
      "Epoch 6/10\n",
      "118/118 - 0s - 1ms/step - loss: 127.0905 - mae: 8.0219\n",
      "Epoch 7/10\n",
      "118/118 - 0s - 1ms/step - loss: 123.9597 - mae: 7.8926\n",
      "Epoch 8/10\n",
      "118/118 - 0s - 3ms/step - loss: 121.7035 - mae: 7.7911\n",
      "Epoch 9/10\n",
      "118/118 - 0s - 1ms/step - loss: 119.9564 - mae: 7.7113\n",
      "Epoch 10/10\n",
      "118/118 - 0s - 1ms/step - loss: 118.5327 - mae: 7.6507\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 113.8990 - mae: 7.5231\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 998us/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點64, epoch10, batch256 訓練集績效:\n",
      "MAE score: 7.604226589202881\n",
      "MAPE score: 28.191977739334106\n",
      "RMSE score: 10.839044874841516\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點64, epoch10, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 30.60816526412964\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "943/943 - 2s - 2ms/step - loss: 473.6389 - mae: 16.0754\n",
      "Epoch 2/20\n",
      "943/943 - 1s - 1ms/step - loss: 121.5601 - mae: 7.7420\n",
      "Epoch 3/20\n",
      "943/943 - 1s - 1ms/step - loss: 117.4205 - mae: 7.5391\n",
      "Epoch 4/20\n",
      "943/943 - 1s - 1ms/step - loss: 115.1639 - mae: 7.4370\n",
      "Epoch 5/20\n",
      "943/943 - 1s - 1ms/step - loss: 113.2890 - mae: 7.3419\n",
      "Epoch 6/20\n",
      "943/943 - 1s - 1ms/step - loss: 111.4863 - mae: 7.2924\n",
      "Epoch 7/20\n",
      "943/943 - 1s - 1ms/step - loss: 109.9214 - mae: 7.2255\n",
      "Epoch 8/20\n",
      "943/943 - 1s - 982us/step - loss: 108.7227 - mae: 7.1959\n",
      "Epoch 9/20\n",
      "943/943 - 1s - 977us/step - loss: 107.8013 - mae: 7.1589\n",
      "Epoch 10/20\n",
      "943/943 - 1s - 988us/step - loss: 107.0384 - mae: 7.1375\n",
      "Epoch 11/20\n",
      "943/943 - 1s - 975us/step - loss: 106.5887 - mae: 7.1261\n",
      "Epoch 12/20\n",
      "943/943 - 1s - 952us/step - loss: 105.9791 - mae: 7.0940\n",
      "Epoch 13/20\n",
      "943/943 - 1s - 917us/step - loss: 105.4539 - mae: 7.0922\n",
      "Epoch 14/20\n",
      "943/943 - 1s - 960us/step - loss: 104.9757 - mae: 7.0636\n",
      "Epoch 15/20\n",
      "943/943 - 1s - 985us/step - loss: 104.7288 - mae: 7.0600\n",
      "Epoch 16/20\n",
      "943/943 - 1s - 1ms/step - loss: 104.3588 - mae: 7.0472\n",
      "Epoch 17/20\n",
      "943/943 - 1s - 975us/step - loss: 104.1076 - mae: 7.0434\n",
      "Epoch 18/20\n",
      "943/943 - 1s - 1ms/step - loss: 103.9091 - mae: 7.0230\n",
      "Epoch 19/20\n",
      "943/943 - 1s - 1ms/step - loss: 103.5995 - mae: 7.0228\n",
      "Epoch 20/20\n",
      "943/943 - 1s - 1ms/step - loss: 103.3356 - mae: 7.0114\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 98.9504 - mae: 6.8610\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 984us/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點64, epoch20, batch32 訓練集績效:\n",
      "MAE score: 6.949417591094971\n",
      "MAPE score: 25.39319097995758\n",
      "RMSE score: 10.110911044795207\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點64, epoch20, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.42545211315155\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "472/472 - 1s - 3ms/step - loss: 836.2452 - mae: 24.5560\n",
      "Epoch 2/20\n",
      "472/472 - 1s - 1ms/step - loss: 130.3134 - mae: 8.1531\n",
      "Epoch 3/20\n",
      "472/472 - 1s - 1ms/step - loss: 121.3700 - mae: 7.7457\n",
      "Epoch 4/20\n",
      "472/472 - 0s - 1ms/step - loss: 117.7559 - mae: 7.5655\n",
      "Epoch 5/20\n",
      "472/472 - 0s - 1ms/step - loss: 115.4715 - mae: 7.4624\n",
      "Epoch 6/20\n",
      "472/472 - 1s - 1ms/step - loss: 114.2154 - mae: 7.3944\n",
      "Epoch 7/20\n",
      "472/472 - 0s - 994us/step - loss: 112.5418 - mae: 7.3330\n",
      "Epoch 8/20\n",
      "472/472 - 0s - 1ms/step - loss: 111.1679 - mae: 7.2874\n",
      "Epoch 9/20\n",
      "472/472 - 0s - 1ms/step - loss: 110.0922 - mae: 7.2355\n",
      "Epoch 10/20\n",
      "472/472 - 1s - 1ms/step - loss: 108.9848 - mae: 7.2044\n",
      "Epoch 11/20\n",
      "472/472 - 1s - 1ms/step - loss: 108.0825 - mae: 7.1843\n",
      "Epoch 12/20\n",
      "472/472 - 0s - 987us/step - loss: 107.4862 - mae: 7.1447\n",
      "Epoch 13/20\n",
      "472/472 - 0s - 1ms/step - loss: 106.8454 - mae: 7.1357\n",
      "Epoch 14/20\n",
      "472/472 - 0s - 1ms/step - loss: 106.3874 - mae: 7.1100\n",
      "Epoch 15/20\n",
      "472/472 - 0s - 1ms/step - loss: 105.9435 - mae: 7.0971\n",
      "Epoch 16/20\n",
      "472/472 - 0s - 1000us/step - loss: 105.4950 - mae: 7.0794\n",
      "Epoch 17/20\n",
      "472/472 - 0s - 1ms/step - loss: 105.1856 - mae: 7.0801\n",
      "Epoch 18/20\n",
      "472/472 - 0s - 1ms/step - loss: 105.0728 - mae: 7.0640\n",
      "Epoch 19/20\n",
      "472/472 - 0s - 1ms/step - loss: 104.7834 - mae: 7.0491\n",
      "Epoch 20/20\n",
      "472/472 - 0s - 987us/step - loss: 104.3726 - mae: 7.0532\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 99.6949 - mae: 6.8853\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step  \n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點64, epoch20, batch64 訓練集績效:\n",
      "MAE score: 6.968047618865967\n",
      "MAPE score: 25.477999448776245\n",
      "RMSE score: 10.148047318567391\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點64, epoch20, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.289160132408142\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "236/236 - 1s - 4ms/step - loss: 1240.3168 - mae: 32.8122\n",
      "Epoch 2/20\n",
      "236/236 - 0s - 1ms/step - loss: 252.5275 - mae: 12.4686\n",
      "Epoch 3/20\n",
      "236/236 - 0s - 1ms/step - loss: 131.5362 - mae: 8.2048\n",
      "Epoch 4/20\n",
      "236/236 - 0s - 1ms/step - loss: 124.7161 - mae: 7.9259\n",
      "Epoch 5/20\n",
      "236/236 - 0s - 1ms/step - loss: 121.1748 - mae: 7.7633\n",
      "Epoch 6/20\n",
      "236/236 - 0s - 1ms/step - loss: 118.8333 - mae: 7.6531\n",
      "Epoch 7/20\n",
      "236/236 - 0s - 1ms/step - loss: 117.0868 - mae: 7.5562\n",
      "Epoch 8/20\n",
      "236/236 - 0s - 1ms/step - loss: 115.5457 - mae: 7.4913\n",
      "Epoch 9/20\n",
      "236/236 - 0s - 1ms/step - loss: 114.2952 - mae: 7.4247\n",
      "Epoch 10/20\n",
      "236/236 - 0s - 1ms/step - loss: 113.1065 - mae: 7.3665\n",
      "Epoch 11/20\n",
      "236/236 - 0s - 1ms/step - loss: 111.9005 - mae: 7.3154\n",
      "Epoch 12/20\n",
      "236/236 - 0s - 1ms/step - loss: 110.8888 - mae: 7.2768\n",
      "Epoch 13/20\n",
      "236/236 - 0s - 1ms/step - loss: 109.8354 - mae: 7.2313\n",
      "Epoch 14/20\n",
      "236/236 - 0s - 1ms/step - loss: 108.9251 - mae: 7.2096\n",
      "Epoch 15/20\n",
      "236/236 - 0s - 1ms/step - loss: 108.1655 - mae: 7.1697\n",
      "Epoch 16/20\n",
      "236/236 - 0s - 2ms/step - loss: 107.5657 - mae: 7.1507\n",
      "Epoch 17/20\n",
      "236/236 - 0s - 1ms/step - loss: 106.9218 - mae: 7.1268\n",
      "Epoch 18/20\n",
      "236/236 - 0s - 1ms/step - loss: 106.6518 - mae: 7.1103\n",
      "Epoch 19/20\n",
      "236/236 - 0s - 1ms/step - loss: 106.1023 - mae: 7.0977\n",
      "Epoch 20/20\n",
      "236/236 - 0s - 1ms/step - loss: 105.6493 - mae: 7.0759\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 938us/step - loss: 101.4382 - mae: 6.9534\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點64, epoch20, batch128 訓練集績效:\n",
      "MAE score: 7.038013935089111\n",
      "MAPE score: 25.820007920265198\n",
      "RMSE score: 10.23214953737842\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點64, epoch20, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.865617513656616\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "118/118 - 1s - 9ms/step - loss: 1542.8640 - mae: 37.4164\n",
      "Epoch 2/20\n",
      "118/118 - 0s - 2ms/step - loss: 863.5942 - mae: 26.9871\n",
      "Epoch 3/20\n",
      "118/118 - 0s - 1ms/step - loss: 324.3625 - mae: 14.9055\n",
      "Epoch 4/20\n",
      "118/118 - 0s - 1ms/step - loss: 156.6213 - mae: 9.2664\n",
      "Epoch 5/20\n",
      "118/118 - 0s - 1ms/step - loss: 134.7834 - mae: 8.3077\n",
      "Epoch 6/20\n",
      "118/118 - 0s - 1ms/step - loss: 128.6117 - mae: 8.0658\n",
      "Epoch 7/20\n",
      "118/118 - 0s - 1ms/step - loss: 124.8235 - mae: 7.9103\n",
      "Epoch 8/20\n",
      "118/118 - 0s - 1ms/step - loss: 122.2887 - mae: 7.8030\n",
      "Epoch 9/20\n",
      "118/118 - 0s - 1ms/step - loss: 120.3209 - mae: 7.7234\n",
      "Epoch 10/20\n",
      "118/118 - 0s - 1ms/step - loss: 118.9250 - mae: 7.6485\n",
      "Epoch 11/20\n",
      "118/118 - 0s - 1ms/step - loss: 117.6626 - mae: 7.6076\n",
      "Epoch 12/20\n",
      "118/118 - 0s - 1ms/step - loss: 116.6822 - mae: 7.5427\n",
      "Epoch 13/20\n",
      "118/118 - 0s - 1ms/step - loss: 115.8525 - mae: 7.5212\n",
      "Epoch 14/20\n",
      "118/118 - 0s - 1ms/step - loss: 115.0490 - mae: 7.4694\n",
      "Epoch 15/20\n",
      "118/118 - 0s - 1ms/step - loss: 114.2253 - mae: 7.4383\n",
      "Epoch 16/20\n",
      "118/118 - 0s - 1ms/step - loss: 113.5169 - mae: 7.4012\n",
      "Epoch 17/20\n",
      "118/118 - 0s - 1ms/step - loss: 112.9590 - mae: 7.3761\n",
      "Epoch 18/20\n",
      "118/118 - 0s - 1ms/step - loss: 112.1997 - mae: 7.3491\n",
      "Epoch 19/20\n",
      "118/118 - 0s - 1ms/step - loss: 111.6978 - mae: 7.3186\n",
      "Epoch 20/20\n",
      "118/118 - 0s - 1ms/step - loss: 111.1419 - mae: 7.2978\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 106.9938 - mae: 7.2128\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step  \n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點64, epoch20, batch256 訓練集績效:\n",
      "MAE score: 7.290943145751953\n",
      "MAPE score: 26.922112703323364\n",
      "RMSE score: 10.502598395591543\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點64, epoch20, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.56104576587677\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "943/943 - 2s - 2ms/step - loss: 343.5610 - mae: 13.1647\n",
      "Epoch 2/5\n",
      "943/943 - 1s - 1ms/step - loss: 118.1168 - mae: 7.5659\n",
      "Epoch 3/5\n",
      "943/943 - 1s - 1ms/step - loss: 114.6732 - mae: 7.4041\n",
      "Epoch 4/5\n",
      "943/943 - 1s - 961us/step - loss: 112.5609 - mae: 7.3140\n",
      "Epoch 5/5\n",
      "943/943 - 1s - 980us/step - loss: 110.2939 - mae: 7.2239\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 104.8578 - mae: 6.9778\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點128, epoch5, batch32 訓練集績效:\n",
      "MAE score: 7.064770698547363\n",
      "MAPE score: 26.30406618118286\n",
      "RMSE score: 10.402760330092757\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點128, epoch5, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.524481296539307\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "472/472 - 1s - 3ms/step - loss: 557.6339 - mae: 18.2622\n",
      "Epoch 2/5\n",
      "472/472 - 1s - 1ms/step - loss: 123.0988 - mae: 7.8149\n",
      "Epoch 3/5\n",
      "472/472 - 1s - 1ms/step - loss: 117.5442 - mae: 7.5793\n",
      "Epoch 4/5\n",
      "472/472 - 1s - 1ms/step - loss: 114.8470 - mae: 7.4358\n",
      "Epoch 5/5\n",
      "472/472 - 1s - 1ms/step - loss: 112.8585 - mae: 7.3393\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 939us/step - loss: 107.8714 - mae: 7.1524\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step  \n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點128, epoch5, batch64 訓練集績效:\n",
      "MAE score: 7.220568656921387\n",
      "MAPE score: 26.94985568523407\n",
      "RMSE score: 10.534756492693676\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點128, epoch5, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 30.033284425735474\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "236/236 - 1s - 4ms/step - loss: 1093.8511 - mae: 30.0413\n",
      "Epoch 2/5\n",
      "236/236 - 0s - 1ms/step - loss: 159.5790 - mae: 9.3551\n",
      "Epoch 3/5\n",
      "236/236 - 0s - 1ms/step - loss: 124.6792 - mae: 7.9146\n",
      "Epoch 4/5\n",
      "236/236 - 0s - 1ms/step - loss: 119.8706 - mae: 7.6892\n",
      "Epoch 5/5\n",
      "236/236 - 0s - 1ms/step - loss: 117.0934 - mae: 7.5536\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 939us/step - loss: 112.1525 - mae: 7.4201\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點128, epoch5, batch128 訓練集績效:\n",
      "MAE score: 7.490508556365967\n",
      "MAPE score: 27.925828099250793\n",
      "RMSE score: 10.742990026840612\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點128, epoch5, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 30.72434365749359\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "118/118 - 1s - 7ms/step - loss: 1484.4546 - mae: 36.5810\n",
      "Epoch 2/5\n",
      "118/118 - 0s - 2ms/step - loss: 599.8375 - mae: 21.5131\n",
      "Epoch 3/5\n",
      "118/118 - 0s - 3ms/step - loss: 163.3813 - mae: 9.5321\n",
      "Epoch 4/5\n",
      "118/118 - 0s - 3ms/step - loss: 128.3985 - mae: 8.0677\n",
      "Epoch 5/5\n",
      "118/118 - 0s - 2ms/step - loss: 123.6741 - mae: 7.8705\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 926us/step - loss: 118.0389 - mae: 7.7194\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點128, epoch5, batch256 訓練集績效:\n",
      "MAE score: 7.786827564239502\n",
      "MAPE score: 28.723829984664917\n",
      "RMSE score: 11.022013744652321\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點128, epoch5, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 31.582802534103394\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "943/943 - 2s - 2ms/step - loss: 366.7170 - mae: 13.6574\n",
      "Epoch 2/10\n",
      "943/943 - 1s - 1ms/step - loss: 117.6863 - mae: 7.5581\n",
      "Epoch 3/10\n",
      "943/943 - 1s - 1ms/step - loss: 114.6614 - mae: 7.3919\n",
      "Epoch 4/10\n",
      "943/943 - 1s - 1ms/step - loss: 112.7575 - mae: 7.3133\n",
      "Epoch 5/10\n",
      "943/943 - 1s - 1ms/step - loss: 110.9299 - mae: 7.2431\n",
      "Epoch 6/10\n",
      "943/943 - 1s - 1ms/step - loss: 109.0624 - mae: 7.1883\n",
      "Epoch 7/10\n",
      "943/943 - 1s - 1ms/step - loss: 107.7665 - mae: 7.1490\n",
      "Epoch 8/10\n",
      "943/943 - 1s - 1ms/step - loss: 106.8462 - mae: 7.1009\n",
      "Epoch 9/10\n",
      "943/943 - 1s - 999us/step - loss: 105.9381 - mae: 7.0964\n",
      "Epoch 10/10\n",
      "943/943 - 1s - 1ms/step - loss: 105.5618 - mae: 7.0765\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 100.8775 - mae: 7.0190\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step  \n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點128, epoch10, batch32 訓練集績效:\n",
      "MAE score: 7.095277786254883\n",
      "MAPE score: 25.828048586845398\n",
      "RMSE score: 10.193871874989942\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點128, epoch10, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.000866413116455\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "472/472 - 1s - 2ms/step - loss: 588.9354 - mae: 18.9189\n",
      "Epoch 2/10\n",
      "472/472 - 1s - 1ms/step - loss: 121.8893 - mae: 7.7757\n",
      "Epoch 3/10\n",
      "472/472 - 1s - 1ms/step - loss: 117.4615 - mae: 7.5550\n",
      "Epoch 4/10\n",
      "472/472 - 1s - 1ms/step - loss: 115.0346 - mae: 7.4486\n",
      "Epoch 5/10\n",
      "472/472 - 1s - 1ms/step - loss: 113.1366 - mae: 7.3609\n",
      "Epoch 6/10\n",
      "472/472 - 1s - 1ms/step - loss: 111.5989 - mae: 7.2834\n",
      "Epoch 7/10\n",
      "472/472 - 1s - 1ms/step - loss: 110.0555 - mae: 7.2315\n",
      "Epoch 8/10\n",
      "472/472 - 1s - 1ms/step - loss: 108.5185 - mae: 7.1803\n",
      "Epoch 9/10\n",
      "472/472 - 1s - 1ms/step - loss: 107.5292 - mae: 7.1493\n",
      "Epoch 10/10\n",
      "472/472 - 1s - 1ms/step - loss: 106.5769 - mae: 7.1239\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 917us/step - loss: 101.5706 - mae: 6.9520\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點128, epoch10, batch64 訓練集績效:\n",
      "MAE score: 7.043642044067383\n",
      "MAPE score: 25.845202803611755\n",
      "RMSE score: 10.253259652232247\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點128, epoch10, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.823009133338928\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "236/236 - 1s - 4ms/step - loss: 1014.5576 - mae: 28.5176\n",
      "Epoch 2/10\n",
      "236/236 - 0s - 1ms/step - loss: 145.2345 - mae: 8.7750\n",
      "Epoch 3/10\n",
      "236/236 - 0s - 1ms/step - loss: 123.8194 - mae: 7.8464\n",
      "Epoch 4/10\n",
      "236/236 - 0s - 1ms/step - loss: 119.4546 - mae: 7.6610\n",
      "Epoch 5/10\n",
      "236/236 - 0s - 1ms/step - loss: 116.9095 - mae: 7.5384\n",
      "Epoch 6/10\n",
      "236/236 - 0s - 2ms/step - loss: 115.2160 - mae: 7.4557\n",
      "Epoch 7/10\n",
      "236/236 - 0s - 2ms/step - loss: 113.9036 - mae: 7.3914\n",
      "Epoch 8/10\n",
      "236/236 - 0s - 1ms/step - loss: 112.6044 - mae: 7.3321\n",
      "Epoch 9/10\n",
      "236/236 - 0s - 1ms/step - loss: 111.5310 - mae: 7.2874\n",
      "Epoch 10/10\n",
      "236/236 - 0s - 1ms/step - loss: 110.3640 - mae: 7.2523\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 105.8168 - mae: 7.0876\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 989us/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點128, epoch10, batch128 訓練集績效:\n",
      "MAE score: 7.164577960968018\n",
      "MAPE score: 26.71564221382141\n",
      "RMSE score: 10.44126120772343\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點128, epoch10, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.501613974571228\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "118/118 - 1s - 9ms/step - loss: 1400.5771 - mae: 35.3692\n",
      "Epoch 2/10\n",
      "118/118 - 0s - 2ms/step - loss: 498.8857 - mae: 19.2673\n",
      "Epoch 3/10\n",
      "118/118 - 0s - 2ms/step - loss: 148.9360 - mae: 9.0045\n",
      "Epoch 4/10\n",
      "118/118 - 0s - 2ms/step - loss: 126.7316 - mae: 7.9723\n",
      "Epoch 5/10\n",
      "118/118 - 0s - 2ms/step - loss: 122.7925 - mae: 7.8250\n",
      "Epoch 6/10\n",
      "118/118 - 0s - 3ms/step - loss: 120.2428 - mae: 7.6923\n",
      "Epoch 7/10\n",
      "118/118 - 0s - 2ms/step - loss: 118.3848 - mae: 7.6299\n",
      "Epoch 8/10\n",
      "118/118 - 0s - 3ms/step - loss: 116.9581 - mae: 7.5452\n",
      "Epoch 9/10\n",
      "118/118 - 0s - 2ms/step - loss: 115.6730 - mae: 7.4879\n",
      "Epoch 10/10\n",
      "118/118 - 0s - 2ms/step - loss: 114.7474 - mae: 7.4398\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 918us/step - loss: 110.4139 - mae: 7.3354\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 983us/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點128, epoch10, batch256 訓練集績效:\n",
      "MAE score: 7.4119181632995605\n",
      "MAPE score: 27.51193940639496\n",
      "RMSE score: 10.663534857024318\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點128, epoch10, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 30.415084958076477\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "943/943 - 2s - 2ms/step - loss: 346.6845 - mae: 13.1893\n",
      "Epoch 2/20\n",
      "943/943 - 1s - 1ms/step - loss: 118.1435 - mae: 7.5970\n",
      "Epoch 3/20\n",
      "943/943 - 1s - 1ms/step - loss: 114.4744 - mae: 7.4043\n",
      "Epoch 4/20\n",
      "943/943 - 1s - 1ms/step - loss: 112.3846 - mae: 7.3116\n",
      "Epoch 5/20\n",
      "943/943 - 1s - 992us/step - loss: 110.5419 - mae: 7.2442\n",
      "Epoch 6/20\n",
      "943/943 - 1s - 2ms/step - loss: 108.7809 - mae: 7.1883\n",
      "Epoch 7/20\n",
      "943/943 - 1s - 1ms/step - loss: 107.6321 - mae: 7.1481\n",
      "Epoch 8/20\n",
      "943/943 - 1s - 1ms/step - loss: 106.8146 - mae: 7.1321\n",
      "Epoch 9/20\n",
      "943/943 - 1s - 1ms/step - loss: 106.1558 - mae: 7.1114\n",
      "Epoch 10/20\n",
      "943/943 - 1s - 1ms/step - loss: 105.5812 - mae: 7.0872\n",
      "Epoch 11/20\n",
      "943/943 - 1s - 1ms/step - loss: 105.0116 - mae: 7.0593\n",
      "Epoch 12/20\n",
      "943/943 - 1s - 1ms/step - loss: 104.6063 - mae: 7.0502\n",
      "Epoch 13/20\n",
      "943/943 - 1s - 1ms/step - loss: 104.2889 - mae: 7.0390\n",
      "Epoch 14/20\n",
      "943/943 - 1s - 990us/step - loss: 103.8838 - mae: 7.0254\n",
      "Epoch 15/20\n",
      "943/943 - 1s - 1ms/step - loss: 103.4786 - mae: 6.9969\n",
      "Epoch 16/20\n",
      "943/943 - 1s - 999us/step - loss: 103.3399 - mae: 7.0092\n",
      "Epoch 17/20\n",
      "943/943 - 1s - 1ms/step - loss: 103.0987 - mae: 6.9954\n",
      "Epoch 18/20\n",
      "943/943 - 1s - 1ms/step - loss: 102.7712 - mae: 6.9857\n",
      "Epoch 19/20\n",
      "943/943 - 1s - 1ms/step - loss: 102.6610 - mae: 6.9844\n",
      "Epoch 20/20\n",
      "943/943 - 1s - 1ms/step - loss: 102.4005 - mae: 6.9707\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 929us/step - loss: 97.6856 - mae: 6.8186\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 967us/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點128, epoch20, batch32 訓練集績效:\n",
      "MAE score: 6.895312309265137\n",
      "MAPE score: 25.157254934310913\n",
      "RMSE score: 10.040301555953022\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點128, epoch20, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.29425036907196\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "472/472 - 1s - 3ms/step - loss: 593.4358 - mae: 18.8875\n",
      "Epoch 2/20\n",
      "472/472 - 1s - 1ms/step - loss: 121.6843 - mae: 7.7304\n",
      "Epoch 3/20\n",
      "472/472 - 1s - 2ms/step - loss: 116.8167 - mae: 7.5058\n",
      "Epoch 4/20\n",
      "472/472 - 1s - 1ms/step - loss: 114.4774 - mae: 7.4123\n",
      "Epoch 5/20\n",
      "472/472 - 1s - 1ms/step - loss: 112.9764 - mae: 7.3251\n",
      "Epoch 6/20\n",
      "472/472 - 1s - 1ms/step - loss: 111.3315 - mae: 7.2677\n",
      "Epoch 7/20\n",
      "472/472 - 1s - 1ms/step - loss: 109.9835 - mae: 7.2150\n",
      "Epoch 8/20\n",
      "472/472 - 1s - 1ms/step - loss: 108.4634 - mae: 7.1631\n",
      "Epoch 9/20\n",
      "472/472 - 0s - 1ms/step - loss: 107.4871 - mae: 7.1471\n",
      "Epoch 10/20\n",
      "472/472 - 0s - 1ms/step - loss: 106.6379 - mae: 7.1193\n",
      "Epoch 11/20\n",
      "472/472 - 1s - 1ms/step - loss: 105.9434 - mae: 7.0964\n",
      "Epoch 12/20\n",
      "472/472 - 1s - 1ms/step - loss: 105.5353 - mae: 7.0820\n",
      "Epoch 13/20\n",
      "472/472 - 1s - 2ms/step - loss: 104.9987 - mae: 7.0637\n",
      "Epoch 14/20\n",
      "472/472 - 1s - 1ms/step - loss: 104.7290 - mae: 7.0558\n",
      "Epoch 15/20\n",
      "472/472 - 1s - 1ms/step - loss: 104.2413 - mae: 7.0392\n",
      "Epoch 16/20\n",
      "472/472 - 0s - 1ms/step - loss: 104.0720 - mae: 7.0267\n",
      "Epoch 17/20\n",
      "472/472 - 1s - 1ms/step - loss: 103.6366 - mae: 7.0165\n",
      "Epoch 18/20\n",
      "472/472 - 0s - 1ms/step - loss: 103.5853 - mae: 7.0138\n",
      "Epoch 19/20\n",
      "472/472 - 1s - 1ms/step - loss: 103.1545 - mae: 6.9986\n",
      "Epoch 20/20\n",
      "472/472 - 1s - 1ms/step - loss: 102.7926 - mae: 6.9894\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 910us/step - loss: 98.4713 - mae: 6.8848\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點128, epoch20, batch64 訓練集績效:\n",
      "MAE score: 6.963493824005127\n",
      "MAPE score: 25.177636742591858\n",
      "RMSE score: 10.078141276028523\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點128, epoch20, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 27.83121168613434\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "236/236 - 1s - 4ms/step - loss: 961.8956 - mae: 27.5689\n",
      "Epoch 2/20\n",
      "236/236 - 0s - 1ms/step - loss: 139.7616 - mae: 8.5171\n",
      "Epoch 3/20\n",
      "236/236 - 0s - 1ms/step - loss: 122.6939 - mae: 7.8101\n",
      "Epoch 4/20\n",
      "236/236 - 0s - 1ms/step - loss: 118.9642 - mae: 7.6494\n",
      "Epoch 5/20\n",
      "236/236 - 0s - 1ms/step - loss: 116.6820 - mae: 7.5302\n",
      "Epoch 6/20\n",
      "236/236 - 0s - 1ms/step - loss: 115.0067 - mae: 7.4578\n",
      "Epoch 7/20\n",
      "236/236 - 0s - 1ms/step - loss: 113.7837 - mae: 7.3930\n",
      "Epoch 8/20\n",
      "236/236 - 0s - 1ms/step - loss: 112.5572 - mae: 7.3355\n",
      "Epoch 9/20\n",
      "236/236 - 0s - 1ms/step - loss: 111.4212 - mae: 7.2853\n",
      "Epoch 10/20\n",
      "236/236 - 0s - 1ms/step - loss: 110.3107 - mae: 7.2455\n",
      "Epoch 11/20\n",
      "236/236 - 0s - 1ms/step - loss: 109.2417 - mae: 7.2136\n",
      "Epoch 12/20\n",
      "236/236 - 0s - 1ms/step - loss: 108.2659 - mae: 7.1655\n",
      "Epoch 13/20\n",
      "236/236 - 0s - 1ms/step - loss: 107.4613 - mae: 7.1508\n",
      "Epoch 14/20\n",
      "236/236 - 0s - 1ms/step - loss: 106.7936 - mae: 7.1176\n",
      "Epoch 15/20\n",
      "236/236 - 0s - 2ms/step - loss: 106.1965 - mae: 7.1072\n",
      "Epoch 16/20\n",
      "236/236 - 0s - 1ms/step - loss: 105.7123 - mae: 7.0868\n",
      "Epoch 17/20\n",
      "236/236 - 0s - 1ms/step - loss: 105.1814 - mae: 7.0717\n",
      "Epoch 18/20\n",
      "236/236 - 0s - 1ms/step - loss: 104.8791 - mae: 7.0527\n",
      "Epoch 19/20\n",
      "236/236 - 0s - 1ms/step - loss: 104.4232 - mae: 7.0417\n",
      "Epoch 20/20\n",
      "236/236 - 0s - 1ms/step - loss: 104.0560 - mae: 7.0343\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 99.7446 - mae: 6.8967\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 964us/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點128, epoch20, batch128 訓練集績效:\n",
      "MAE score: 6.979163646697998\n",
      "MAPE score: 25.66448748111725\n",
      "RMSE score: 10.148163848312043\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點128, epoch20, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.52734625339508\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "118/118 - 1s - 7ms/step - loss: 1304.4886 - mae: 33.9398\n",
      "Epoch 2/20\n",
      "118/118 - 0s - 2ms/step - loss: 392.9923 - mae: 16.5835\n",
      "Epoch 3/20\n",
      "118/118 - 0s - 1ms/step - loss: 137.3463 - mae: 8.4508\n",
      "Epoch 4/20\n",
      "118/118 - 0s - 1ms/step - loss: 125.4283 - mae: 7.9247\n",
      "Epoch 5/20\n",
      "118/118 - 0s - 1ms/step - loss: 121.5714 - mae: 7.7597\n",
      "Epoch 6/20\n",
      "118/118 - 0s - 1ms/step - loss: 119.1199 - mae: 7.6499\n",
      "Epoch 7/20\n",
      "118/118 - 0s - 1ms/step - loss: 117.4728 - mae: 7.5560\n",
      "Epoch 8/20\n",
      "118/118 - 0s - 1ms/step - loss: 116.1535 - mae: 7.5117\n",
      "Epoch 9/20\n",
      "118/118 - 0s - 1ms/step - loss: 115.0218 - mae: 7.4466\n",
      "Epoch 10/20\n",
      "118/118 - 0s - 1ms/step - loss: 114.2369 - mae: 7.3988\n",
      "Epoch 11/20\n",
      "118/118 - 0s - 1ms/step - loss: 113.4171 - mae: 7.3711\n",
      "Epoch 12/20\n",
      "118/118 - 0s - 1ms/step - loss: 112.6877 - mae: 7.3327\n",
      "Epoch 13/20\n",
      "118/118 - 0s - 1ms/step - loss: 111.9974 - mae: 7.3016\n",
      "Epoch 14/20\n",
      "118/118 - 0s - 1ms/step - loss: 111.2495 - mae: 7.2752\n",
      "Epoch 15/20\n",
      "118/118 - 0s - 1ms/step - loss: 110.5533 - mae: 7.2466\n",
      "Epoch 16/20\n",
      "118/118 - 0s - 1ms/step - loss: 109.8238 - mae: 7.2074\n",
      "Epoch 17/20\n",
      "118/118 - 0s - 2ms/step - loss: 109.0605 - mae: 7.1906\n",
      "Epoch 18/20\n",
      "118/118 - 0s - 3ms/step - loss: 108.4392 - mae: 7.1610\n",
      "Epoch 19/20\n",
      "118/118 - 0s - 2ms/step - loss: 107.8430 - mae: 7.1464\n",
      "Epoch 20/20\n",
      "118/118 - 0s - 2ms/step - loss: 107.2030 - mae: 7.1328\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 917us/step - loss: 103.2691 - mae: 6.9843\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點128, epoch20, batch256 訓練集績效:\n",
      "MAE score: 7.054036617279053\n",
      "MAPE score: 26.108813285827637\n",
      "RMSE score: 10.313966958872369\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點128, epoch20, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.813469409942627\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "943/943 - 2s - 2ms/step - loss: 278.5018 - mae: 11.5571\n",
      "Epoch 2/5\n",
      "943/943 - 1s - 1ms/step - loss: 115.9807 - mae: 7.4590\n",
      "Epoch 3/5\n",
      "943/943 - 1s - 1ms/step - loss: 113.1827 - mae: 7.3394\n",
      "Epoch 4/5\n",
      "943/943 - 1s - 1ms/step - loss: 110.8925 - mae: 7.2498\n",
      "Epoch 5/5\n",
      "943/943 - 1s - 1ms/step - loss: 109.2566 - mae: 7.1952\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 979us/step - loss: 103.4444 - mae: 7.0602\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點256, epoch5, batch32 訓練集績效:\n",
      "MAE score: 7.139409065246582\n",
      "MAPE score: 26.3208270072937\n",
      "RMSE score: 10.334130369231909\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點256, epoch5, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.44004237651825\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "472/472 - 1s - 3ms/step - loss: 424.4472 - mae: 15.0605\n",
      "Epoch 2/5\n",
      "472/472 - 1s - 1ms/step - loss: 118.3792 - mae: 7.5844\n",
      "Epoch 3/5\n",
      "472/472 - 1s - 1ms/step - loss: 114.8634 - mae: 7.4211\n",
      "Epoch 4/5\n",
      "472/472 - 1s - 1ms/step - loss: 112.7392 - mae: 7.3212\n",
      "Epoch 5/5\n",
      "472/472 - 1s - 1ms/step - loss: 110.8105 - mae: 7.2377\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 999us/step - loss: 105.2798 - mae: 7.1426\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點256, epoch5, batch64 訓練集績效:\n",
      "MAE score: 7.224432468414307\n",
      "MAPE score: 26.961377263069153\n",
      "RMSE score: 10.429957788515486\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點256, epoch5, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.834452271461487\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "236/236 - 1s - 4ms/step - loss: 765.9369 - mae: 23.0593\n",
      "Epoch 2/5\n",
      "236/236 - 0s - 1ms/step - loss: 125.3762 - mae: 7.9074\n",
      "Epoch 3/5\n",
      "236/236 - 0s - 2ms/step - loss: 118.9774 - mae: 7.6143\n",
      "Epoch 4/5\n",
      "236/236 - 1s - 3ms/step - loss: 115.9049 - mae: 7.4718\n",
      "Epoch 5/5\n",
      "236/236 - 0s - 1ms/step - loss: 113.8328 - mae: 7.3699\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 978us/step - loss: 109.3305 - mae: 7.2525\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點256, epoch5, batch128 訓練集績效:\n",
      "MAE score: 7.33009672164917\n",
      "MAPE score: 27.419084310531616\n",
      "RMSE score: 10.610794803860308\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點256, epoch5, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 30.28758466243744\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "118/118 - 1s - 10ms/step - loss: 1179.6217 - mae: 31.8125\n",
      "Epoch 2/5\n",
      "118/118 - 0s - 2ms/step - loss: 219.4840 - mae: 11.4028\n",
      "Epoch 3/5\n",
      "118/118 - 0s - 2ms/step - loss: 125.2843 - mae: 7.8802\n",
      "Epoch 4/5\n",
      "118/118 - 0s - 2ms/step - loss: 120.5985 - mae: 7.6946\n",
      "Epoch 5/5\n",
      "118/118 - 0s - 2ms/step - loss: 117.9760 - mae: 7.5810\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 950us/step - loss: 113.0502 - mae: 7.4427\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 990us/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點256, epoch5, batch256 訓練集績效:\n",
      "MAE score: 7.517463207244873\n",
      "MAPE score: 27.96047031879425\n",
      "RMSE score: 10.789132506787718\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點256, epoch5, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 30.792030692100525\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "943/943 - 2s - 2ms/step - loss: 270.6580 - mae: 11.3559\n",
      "Epoch 2/10\n",
      "943/943 - 1s - 1ms/step - loss: 116.9665 - mae: 7.4851\n",
      "Epoch 3/10\n",
      "943/943 - 1s - 1ms/step - loss: 113.5584 - mae: 7.3385\n",
      "Epoch 4/10\n",
      "943/943 - 1s - 1ms/step - loss: 111.4445 - mae: 7.2675\n",
      "Epoch 5/10\n",
      "943/943 - 1s - 1ms/step - loss: 109.0387 - mae: 7.1868\n",
      "Epoch 6/10\n",
      "943/943 - 1s - 1ms/step - loss: 108.0853 - mae: 7.1618\n",
      "Epoch 7/10\n",
      "943/943 - 1s - 1ms/step - loss: 107.0692 - mae: 7.1431\n",
      "Epoch 8/10\n",
      "943/943 - 1s - 1ms/step - loss: 106.2396 - mae: 7.1204\n",
      "Epoch 9/10\n",
      "943/943 - 1s - 1ms/step - loss: 105.5652 - mae: 7.0961\n",
      "Epoch 10/10\n",
      "943/943 - 1s - 1ms/step - loss: 105.1401 - mae: 7.0684\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 100.1564 - mae: 6.9580\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點256, epoch10, batch32 訓練集績效:\n",
      "MAE score: 7.047982215881348\n",
      "MAPE score: 25.101807713508606\n",
      "RMSE score: 10.180927051834013\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點256, epoch10, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 27.764949202537537\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "472/472 - 1s - 3ms/step - loss: 420.9455 - mae: 14.9988\n",
      "Epoch 2/10\n",
      "472/472 - 1s - 1ms/step - loss: 118.1753 - mae: 7.5828\n",
      "Epoch 3/10\n",
      "472/472 - 1s - 1ms/step - loss: 114.5684 - mae: 7.4103\n",
      "Epoch 4/10\n",
      "472/472 - 1s - 1ms/step - loss: 112.9914 - mae: 7.3178\n",
      "Epoch 5/10\n",
      "472/472 - 1s - 1ms/step - loss: 111.1750 - mae: 7.2666\n",
      "Epoch 6/10\n",
      "472/472 - 1s - 1ms/step - loss: 109.6196 - mae: 7.1923\n",
      "Epoch 7/10\n",
      "472/472 - 1s - 1ms/step - loss: 107.9897 - mae: 7.1438\n",
      "Epoch 8/10\n",
      "472/472 - 1s - 1ms/step - loss: 106.7330 - mae: 7.1208\n",
      "Epoch 9/10\n",
      "472/472 - 1s - 1ms/step - loss: 106.2102 - mae: 7.0949\n",
      "Epoch 10/10\n",
      "472/472 - 1s - 1ms/step - loss: 105.2897 - mae: 7.0726\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 100.6762 - mae: 6.9251\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 966us/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點256, epoch10, batch64 訓練集績效:\n",
      "MAE score: 7.012208461761475\n",
      "MAPE score: 25.496739149093628\n",
      "RMSE score: 10.194585103361858\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點256, epoch10, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.342685103416443\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "236/236 - 1s - 4ms/step - loss: 749.9272 - mae: 22.7521\n",
      "Epoch 2/10\n",
      "236/236 - 0s - 1ms/step - loss: 125.3092 - mae: 7.9003\n",
      "Epoch 3/10\n",
      "236/236 - 0s - 1ms/step - loss: 118.9114 - mae: 7.6208\n",
      "Epoch 4/10\n",
      "236/236 - 0s - 1ms/step - loss: 115.7439 - mae: 7.4799\n",
      "Epoch 5/10\n",
      "236/236 - 0s - 1ms/step - loss: 113.9739 - mae: 7.3874\n",
      "Epoch 6/10\n",
      "236/236 - 0s - 1ms/step - loss: 112.4961 - mae: 7.3233\n",
      "Epoch 7/10\n",
      "236/236 - 0s - 1ms/step - loss: 110.8793 - mae: 7.2466\n",
      "Epoch 8/10\n",
      "236/236 - 0s - 1ms/step - loss: 109.6106 - mae: 7.2040\n",
      "Epoch 9/10\n",
      "236/236 - 0s - 1ms/step - loss: 108.0975 - mae: 7.1555\n",
      "Epoch 10/10\n",
      "236/236 - 0s - 2ms/step - loss: 107.2930 - mae: 7.1256\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 103.3003 - mae: 6.9765\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點256, epoch10, batch128 訓練集績效:\n",
      "MAE score: 7.042294979095459\n",
      "MAPE score: 26.16422474384308\n",
      "RMSE score: 10.299470195292132\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點256, epoch10, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.782758116722107\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "118/118 - 1s - 8ms/step - loss: 1226.2643 - mae: 32.5906\n",
      "Epoch 2/10\n",
      "118/118 - 0s - 2ms/step - loss: 235.2361 - mae: 11.9212\n",
      "Epoch 3/10\n",
      "118/118 - 0s - 2ms/step - loss: 127.1527 - mae: 8.0128\n",
      "Epoch 4/10\n",
      "118/118 - 0s - 2ms/step - loss: 121.5412 - mae: 7.7672\n",
      "Epoch 5/10\n",
      "118/118 - 0s - 2ms/step - loss: 118.4546 - mae: 7.6178\n",
      "Epoch 6/10\n",
      "118/118 - 0s - 2ms/step - loss: 116.5435 - mae: 7.5317\n",
      "Epoch 7/10\n",
      "118/118 - 0s - 2ms/step - loss: 115.0712 - mae: 7.4508\n",
      "Epoch 8/10\n",
      "118/118 - 0s - 2ms/step - loss: 113.9540 - mae: 7.3984\n",
      "Epoch 9/10\n",
      "118/118 - 0s - 2ms/step - loss: 112.9765 - mae: 7.3534\n",
      "Epoch 10/10\n",
      "118/118 - 0s - 2ms/step - loss: 112.1153 - mae: 7.3083\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 107.5915 - mae: 7.2134 \n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 988us/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點256, epoch10, batch256 訓練集績效:\n",
      "MAE score: 7.2950119972229\n",
      "MAPE score: 27.344664931297302\n",
      "RMSE score: 10.537040046979994\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點256, epoch10, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 30.035483837127686\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "943/943 - 2s - 2ms/step - loss: 273.3001 - mae: 11.4141\n",
      "Epoch 2/20\n",
      "943/943 - 1s - 1ms/step - loss: 116.1480 - mae: 7.4597\n",
      "Epoch 3/20\n",
      "943/943 - 1s - 1ms/step - loss: 113.7337 - mae: 7.3498\n",
      "Epoch 4/20\n",
      "943/943 - 1s - 1ms/step - loss: 111.9318 - mae: 7.2794\n",
      "Epoch 5/20\n",
      "943/943 - 1s - 1ms/step - loss: 109.7501 - mae: 7.2102\n",
      "Epoch 6/20\n",
      "943/943 - 1s - 1ms/step - loss: 108.1728 - mae: 7.1674\n",
      "Epoch 7/20\n",
      "943/943 - 1s - 1ms/step - loss: 107.4321 - mae: 7.1390\n",
      "Epoch 8/20\n",
      "943/943 - 1s - 1ms/step - loss: 106.5090 - mae: 7.1101\n",
      "Epoch 9/20\n",
      "943/943 - 1s - 1ms/step - loss: 105.8924 - mae: 7.1005\n",
      "Epoch 10/20\n",
      "943/943 - 1s - 1ms/step - loss: 105.3810 - mae: 7.0764\n",
      "Epoch 11/20\n",
      "943/943 - 1s - 1ms/step - loss: 104.9135 - mae: 7.0625\n",
      "Epoch 12/20\n",
      "943/943 - 1s - 1ms/step - loss: 104.4366 - mae: 7.0572\n",
      "Epoch 13/20\n",
      "943/943 - 1s - 1ms/step - loss: 104.0329 - mae: 7.0415\n",
      "Epoch 14/20\n",
      "943/943 - 1s - 1ms/step - loss: 103.7062 - mae: 7.0274\n",
      "Epoch 15/20\n",
      "943/943 - 1s - 1ms/step - loss: 103.4308 - mae: 7.0242\n",
      "Epoch 16/20\n",
      "943/943 - 1s - 1ms/step - loss: 103.2648 - mae: 7.0120\n",
      "Epoch 17/20\n",
      "943/943 - 1s - 1ms/step - loss: 102.8132 - mae: 6.9930\n",
      "Epoch 18/20\n",
      "943/943 - 1s - 1ms/step - loss: 102.5659 - mae: 6.9870\n",
      "Epoch 19/20\n",
      "943/943 - 1s - 1ms/step - loss: 102.3929 - mae: 6.9682\n",
      "Epoch 20/20\n",
      "943/943 - 1s - 1ms/step - loss: 102.1233 - mae: 6.9747\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 920us/step - loss: 97.0500 - mae: 6.7879\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點256, epoch20, batch32 訓練集績效:\n",
      "MAE score: 6.861979007720947\n",
      "MAPE score: 24.91055130958557\n",
      "RMSE score: 10.001296531550883\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點256, epoch20, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.15156579017639\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "472/472 - 1s - 3ms/step - loss: 437.0225 - mae: 15.2876\n",
      "Epoch 2/20\n",
      "472/472 - 1s - 1ms/step - loss: 118.8822 - mae: 7.6162\n",
      "Epoch 3/20\n",
      "472/472 - 1s - 1ms/step - loss: 114.8913 - mae: 7.4270\n",
      "Epoch 4/20\n",
      "472/472 - 1s - 1ms/step - loss: 112.7724 - mae: 7.3201\n",
      "Epoch 5/20\n",
      "472/472 - 1s - 1ms/step - loss: 110.6263 - mae: 7.2360\n",
      "Epoch 6/20\n",
      "472/472 - 1s - 1ms/step - loss: 109.0187 - mae: 7.1910\n",
      "Epoch 7/20\n",
      "472/472 - 1s - 1ms/step - loss: 107.7724 - mae: 7.1438\n",
      "Epoch 8/20\n",
      "472/472 - 1s - 1ms/step - loss: 106.8163 - mae: 7.1128\n",
      "Epoch 9/20\n",
      "472/472 - 1s - 1ms/step - loss: 106.0717 - mae: 7.0893\n",
      "Epoch 10/20\n",
      "472/472 - 1s - 1ms/step - loss: 105.3575 - mae: 7.0764\n",
      "Epoch 11/20\n",
      "472/472 - 1s - 1ms/step - loss: 104.9158 - mae: 7.0551\n",
      "Epoch 12/20\n",
      "472/472 - 1s - 1ms/step - loss: 104.2458 - mae: 7.0288\n",
      "Epoch 13/20\n",
      "472/472 - 1s - 1ms/step - loss: 103.8077 - mae: 7.0331\n",
      "Epoch 14/20\n",
      "472/472 - 1s - 1ms/step - loss: 103.5431 - mae: 7.0040\n",
      "Epoch 15/20\n",
      "472/472 - 1s - 1ms/step - loss: 103.2434 - mae: 6.9975\n",
      "Epoch 16/20\n",
      "472/472 - 1s - 1ms/step - loss: 102.8273 - mae: 6.9884\n",
      "Epoch 17/20\n",
      "472/472 - 1s - 1ms/step - loss: 102.4647 - mae: 6.9710\n",
      "Epoch 18/20\n",
      "472/472 - 1s - 1ms/step - loss: 102.2633 - mae: 6.9683\n",
      "Epoch 19/20\n",
      "472/472 - 1s - 1ms/step - loss: 101.8906 - mae: 6.9633\n",
      "Epoch 20/20\n",
      "472/472 - 1s - 1ms/step - loss: 101.8875 - mae: 6.9545\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 97.4361 - mae: 6.8258\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點256, epoch20, batch64 訓練集績效:\n",
      "MAE score: 6.901322841644287\n",
      "MAPE score: 25.18732249736786\n",
      "RMSE score: 10.020196356457925\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點256, epoch20, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.56670320034027\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "236/236 - 1s - 5ms/step - loss: 717.8735 - mae: 22.0774\n",
      "Epoch 2/20\n",
      "236/236 - 0s - 1ms/step - loss: 125.0132 - mae: 7.8794\n",
      "Epoch 3/20\n",
      "236/236 - 0s - 1ms/step - loss: 118.7108 - mae: 7.6189\n",
      "Epoch 4/20\n",
      "236/236 - 0s - 1ms/step - loss: 115.6001 - mae: 7.4713\n",
      "Epoch 5/20\n",
      "236/236 - 0s - 1ms/step - loss: 113.8793 - mae: 7.3707\n",
      "Epoch 6/20\n",
      "236/236 - 0s - 1ms/step - loss: 112.3649 - mae: 7.3074\n",
      "Epoch 7/20\n",
      "236/236 - 0s - 1ms/step - loss: 110.9995 - mae: 7.2575\n",
      "Epoch 8/20\n",
      "236/236 - 0s - 1ms/step - loss: 109.6640 - mae: 7.2012\n",
      "Epoch 9/20\n",
      "236/236 - 0s - 1ms/step - loss: 108.5286 - mae: 7.1674\n",
      "Epoch 10/20\n",
      "236/236 - 0s - 1ms/step - loss: 107.6920 - mae: 7.1298\n",
      "Epoch 11/20\n",
      "236/236 - 0s - 1ms/step - loss: 106.4624 - mae: 7.0965\n",
      "Epoch 12/20\n",
      "236/236 - 0s - 2ms/step - loss: 105.8876 - mae: 7.0934\n",
      "Epoch 13/20\n",
      "236/236 - 0s - 1ms/step - loss: 105.5057 - mae: 7.0692\n",
      "Epoch 14/20\n",
      "236/236 - 0s - 1ms/step - loss: 104.9601 - mae: 7.0525\n",
      "Epoch 15/20\n",
      "236/236 - 0s - 1ms/step - loss: 104.5093 - mae: 7.0351\n",
      "Epoch 16/20\n",
      "236/236 - 0s - 1ms/step - loss: 104.2540 - mae: 7.0327\n",
      "Epoch 17/20\n",
      "236/236 - 0s - 1ms/step - loss: 103.8157 - mae: 7.0197\n",
      "Epoch 18/20\n",
      "236/236 - 0s - 1ms/step - loss: 103.3771 - mae: 6.9955\n",
      "Epoch 19/20\n",
      "236/236 - 0s - 1ms/step - loss: 103.1507 - mae: 6.9914\n",
      "Epoch 20/20\n",
      "236/236 - 0s - 1ms/step - loss: 102.9805 - mae: 6.9945\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 98.6118 - mae: 6.8522\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點256, epoch20, batch128 訓練集績效:\n",
      "MAE score: 6.938536643981934\n",
      "MAPE score: 25.27083456516266\n",
      "RMSE score: 10.085078527157128\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點256, epoch20, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.478631377220154\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "118/118 - 1s - 8ms/step - loss: 1201.3519 - mae: 32.1383\n",
      "Epoch 2/20\n",
      "118/118 - 0s - 2ms/step - loss: 220.1610 - mae: 11.4770\n",
      "Epoch 3/20\n",
      "118/118 - 0s - 2ms/step - loss: 126.4866 - mae: 7.9456\n",
      "Epoch 4/20\n",
      "118/118 - 0s - 2ms/step - loss: 121.2837 - mae: 7.7351\n",
      "Epoch 5/20\n",
      "118/118 - 0s - 3ms/step - loss: 118.4858 - mae: 7.6119\n",
      "Epoch 6/20\n",
      "118/118 - 0s - 2ms/step - loss: 116.4698 - mae: 7.5208\n",
      "Epoch 7/20\n",
      "118/118 - 0s - 2ms/step - loss: 115.0387 - mae: 7.4439\n",
      "Epoch 8/20\n",
      "118/118 - 0s - 2ms/step - loss: 113.8508 - mae: 7.3859\n",
      "Epoch 9/20\n",
      "118/118 - 0s - 2ms/step - loss: 112.7894 - mae: 7.3318\n",
      "Epoch 10/20\n",
      "118/118 - 0s - 2ms/step - loss: 111.7135 - mae: 7.2953\n",
      "Epoch 11/20\n",
      "118/118 - 0s - 2ms/step - loss: 110.8060 - mae: 7.2519\n",
      "Epoch 12/20\n",
      "118/118 - 0s - 2ms/step - loss: 109.9827 - mae: 7.2201\n",
      "Epoch 13/20\n",
      "118/118 - 0s - 2ms/step - loss: 108.9123 - mae: 7.1858\n",
      "Epoch 14/20\n",
      "118/118 - 0s - 2ms/step - loss: 108.1235 - mae: 7.1547\n",
      "Epoch 15/20\n",
      "118/118 - 0s - 3ms/step - loss: 107.4694 - mae: 7.1337\n",
      "Epoch 16/20\n",
      "118/118 - 0s - 2ms/step - loss: 106.7082 - mae: 7.1075\n",
      "Epoch 17/20\n",
      "118/118 - 0s - 2ms/step - loss: 106.1907 - mae: 7.0815\n",
      "Epoch 18/20\n",
      "118/118 - 0s - 2ms/step - loss: 105.7933 - mae: 7.0775\n",
      "Epoch 19/20\n",
      "118/118 - 0s - 2ms/step - loss: 105.2429 - mae: 7.0636\n",
      "Epoch 20/20\n",
      "118/118 - 0s - 2ms/step - loss: 104.8327 - mae: 7.0451\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 100.5886 - mae: 6.9825\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點256, epoch20, batch256 訓練集績效:\n",
      "MAE score: 7.070056438446045\n",
      "MAPE score: 26.046672463417053\n",
      "RMSE score: 10.196155825992935\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點256, epoch20, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.750687837600708\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "943/943 - 2s - 2ms/step - loss: 245.0557 - mae: 10.6191\n",
      "Epoch 2/5\n",
      "943/943 - 1s - 1ms/step - loss: 115.5041 - mae: 7.4313\n",
      "Epoch 3/5\n",
      "943/943 - 1s - 1ms/step - loss: 112.8778 - mae: 7.3186\n",
      "Epoch 4/5\n",
      "943/943 - 1s - 1ms/step - loss: 110.3721 - mae: 7.2358\n",
      "Epoch 5/5\n",
      "943/943 - 1s - 1ms/step - loss: 108.7285 - mae: 7.1940\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 103.3219 - mae: 7.0520\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點512, epoch5, batch32 訓練集績效:\n",
      "MAE score: 7.128464221954346\n",
      "MAPE score: 26.534143090248108\n",
      "RMSE score: 10.315096441604867\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點512, epoch5, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.697805643081665\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "472/472 - 1s - 3ms/step - loss: 347.4395 - mae: 13.1698\n",
      "Epoch 2/5\n",
      "472/472 - 1s - 1ms/step - loss: 116.7770 - mae: 7.4927\n",
      "Epoch 3/5\n",
      "472/472 - 1s - 3ms/step - loss: 113.4921 - mae: 7.3299\n",
      "Epoch 4/5\n",
      "472/472 - 1s - 1ms/step - loss: 111.6029 - mae: 7.2590\n",
      "Epoch 5/5\n",
      "472/472 - 1s - 1ms/step - loss: 109.5254 - mae: 7.2045\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 104.6512 - mae: 7.1175\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點512, epoch5, batch64 訓練集績效:\n",
      "MAE score: 7.1969499588012695\n",
      "MAPE score: 27.091798186302185\n",
      "RMSE score: 10.385954806900354\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點512, epoch5, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.63515818119049\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "236/236 - 1s - 5ms/step - loss: 554.3646 - mae: 18.0925\n",
      "Epoch 2/5\n",
      "236/236 - 0s - 2ms/step - loss: 120.0213 - mae: 7.6557\n",
      "Epoch 3/5\n",
      "236/236 - 0s - 2ms/step - loss: 115.8249 - mae: 7.4520\n",
      "Epoch 4/5\n",
      "236/236 - 0s - 2ms/step - loss: 113.6793 - mae: 7.3569\n",
      "Epoch 5/5\n",
      "236/236 - 0s - 2ms/step - loss: 112.1274 - mae: 7.2782\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 106.6786 - mae: 7.1276\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點512, epoch5, batch128 訓練集績效:\n",
      "MAE score: 7.210919380187988\n",
      "MAPE score: 26.81327760219574\n",
      "RMSE score: 10.492344563232459\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點512, epoch5, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.94937002658844\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "118/118 - 1s - 8ms/step - loss: 941.8567 - mae: 27.1718\n",
      "Epoch 2/5\n",
      "118/118 - 0s - 2ms/step - loss: 133.8267 - mae: 8.2735\n",
      "Epoch 3/5\n",
      "118/118 - 0s - 2ms/step - loss: 120.3592 - mae: 7.6805\n",
      "Epoch 4/5\n",
      "118/118 - 0s - 3ms/step - loss: 116.8616 - mae: 7.5137\n",
      "Epoch 5/5\n",
      "118/118 - 0s - 2ms/step - loss: 114.9334 - mae: 7.4244\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 110.1261 - mae: 7.2581\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點512, epoch5, batch256 訓練集績效:\n",
      "MAE score: 7.330744743347168\n",
      "MAPE score: 27.468600869178772\n",
      "RMSE score: 10.64775646380036\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點512, epoch5, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 30.483970046043396\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "943/943 - 2s - 2ms/step - loss: 233.0543 - mae: 10.3501\n",
      "Epoch 2/10\n",
      "943/943 - 1s - 1ms/step - loss: 115.4755 - mae: 7.4193\n",
      "Epoch 3/10\n",
      "943/943 - 1s - 1ms/step - loss: 113.0114 - mae: 7.3331\n",
      "Epoch 4/10\n",
      "943/943 - 1s - 1ms/step - loss: 111.0264 - mae: 7.2566\n",
      "Epoch 5/10\n",
      "943/943 - 1s - 1ms/step - loss: 109.0788 - mae: 7.2003\n",
      "Epoch 6/10\n",
      "943/943 - 1s - 1ms/step - loss: 107.8446 - mae: 7.1693\n",
      "Epoch 7/10\n",
      "943/943 - 1s - 1ms/step - loss: 106.7684 - mae: 7.1370\n",
      "Epoch 8/10\n",
      "943/943 - 1s - 1ms/step - loss: 106.2547 - mae: 7.1255\n",
      "Epoch 9/10\n",
      "943/943 - 1s - 1ms/step - loss: 105.6446 - mae: 7.1105\n",
      "Epoch 10/10\n",
      "943/943 - 1s - 1ms/step - loss: 105.1440 - mae: 7.0945\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 100.1243 - mae: 6.9883\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點512, epoch10, batch32 訓練集績效:\n",
      "MAE score: 7.0675458908081055\n",
      "MAPE score: 26.003101468086243\n",
      "RMSE score: 10.16571373981403\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點512, epoch10, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.685715794563293\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "472/472 - 1s - 3ms/step - loss: 355.9982 - mae: 13.3053\n",
      "Epoch 2/10\n",
      "472/472 - 1s - 1ms/step - loss: 117.0301 - mae: 7.5185\n",
      "Epoch 3/10\n",
      "472/472 - 1s - 1ms/step - loss: 113.5723 - mae: 7.3666\n",
      "Epoch 4/10\n",
      "472/472 - 1s - 1ms/step - loss: 111.2179 - mae: 7.2634\n",
      "Epoch 5/10\n",
      "472/472 - 1s - 1ms/step - loss: 109.0417 - mae: 7.2026\n",
      "Epoch 6/10\n",
      "472/472 - 1s - 1ms/step - loss: 107.4923 - mae: 7.1440\n",
      "Epoch 7/10\n",
      "472/472 - 1s - 1ms/step - loss: 106.4684 - mae: 7.1173\n",
      "Epoch 8/10\n",
      "472/472 - 1s - 1ms/step - loss: 106.0281 - mae: 7.1013\n",
      "Epoch 9/10\n",
      "472/472 - 1s - 2ms/step - loss: 105.1321 - mae: 7.0774\n",
      "Epoch 10/10\n",
      "472/472 - 1s - 1ms/step - loss: 104.4551 - mae: 7.0492\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 99.9291 - mae: 6.8343\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點512, epoch10, batch64 訓練集績效:\n",
      "MAE score: 6.907339572906494\n",
      "MAPE score: 24.757401645183563\n",
      "RMSE score: 10.150599013819601\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點512, epoch10, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.07656228542328\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "236/236 - 1s - 5ms/step - loss: 553.1754 - mae: 18.1548\n",
      "Epoch 2/10\n",
      "236/236 - 0s - 2ms/step - loss: 120.4365 - mae: 7.6845\n",
      "Epoch 3/10\n",
      "236/236 - 0s - 2ms/step - loss: 116.2185 - mae: 7.4797\n",
      "Epoch 4/10\n",
      "236/236 - 0s - 2ms/step - loss: 113.7067 - mae: 7.3553\n",
      "Epoch 5/10\n",
      "236/236 - 0s - 2ms/step - loss: 112.0652 - mae: 7.2920\n",
      "Epoch 6/10\n",
      "236/236 - 0s - 2ms/step - loss: 110.3940 - mae: 7.2141\n",
      "Epoch 7/10\n",
      "236/236 - 0s - 2ms/step - loss: 108.9073 - mae: 7.1779\n",
      "Epoch 8/10\n",
      "236/236 - 0s - 2ms/step - loss: 107.6847 - mae: 7.1357\n",
      "Epoch 9/10\n",
      "236/236 - 0s - 2ms/step - loss: 106.4185 - mae: 7.1057\n",
      "Epoch 10/10\n",
      "236/236 - 0s - 2ms/step - loss: 105.7351 - mae: 7.0695\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 101.0952 - mae: 6.9396\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點512, epoch10, batch128 訓練集績效:\n",
      "MAE score: 7.013269424438477\n",
      "MAPE score: 25.38980543613434\n",
      "RMSE score: 10.214761217998326\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點512, epoch10, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.609350323677063\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "118/118 - 1s - 8ms/step - loss: 930.2756 - mae: 26.9742\n",
      "Epoch 2/10\n",
      "118/118 - 0s - 2ms/step - loss: 134.1071 - mae: 8.2905\n",
      "Epoch 3/10\n",
      "118/118 - 0s - 2ms/step - loss: 120.6572 - mae: 7.6909\n",
      "Epoch 4/10\n",
      "118/118 - 0s - 2ms/step - loss: 117.0902 - mae: 7.5333\n",
      "Epoch 5/10\n",
      "118/118 - 0s - 2ms/step - loss: 115.1700 - mae: 7.4433\n",
      "Epoch 6/10\n",
      "118/118 - 0s - 2ms/step - loss: 113.6567 - mae: 7.3831\n",
      "Epoch 7/10\n",
      "118/118 - 0s - 3ms/step - loss: 112.5150 - mae: 7.3103\n",
      "Epoch 8/10\n",
      "118/118 - 0s - 2ms/step - loss: 111.4986 - mae: 7.2719\n",
      "Epoch 9/10\n",
      "118/118 - 0s - 2ms/step - loss: 110.5426 - mae: 7.2221\n",
      "Epoch 10/10\n",
      "118/118 - 0s - 2ms/step - loss: 109.4023 - mae: 7.1947\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 104.9035 - mae: 7.0495\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點512, epoch10, batch256 訓練集績效:\n",
      "MAE score: 7.121380805969238\n",
      "MAPE score: 26.45319104194641\n",
      "RMSE score: 10.397882436702218\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點512, epoch10, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.55872416496277\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "943/943 - 2s - 2ms/step - loss: 243.1151 - mae: 10.5864\n",
      "Epoch 2/20\n",
      "943/943 - 1s - 1ms/step - loss: 115.6183 - mae: 7.4347\n",
      "Epoch 3/20\n",
      "943/943 - 1s - 1ms/step - loss: 113.3833 - mae: 7.3249\n",
      "Epoch 4/20\n",
      "943/943 - 1s - 1ms/step - loss: 111.0584 - mae: 7.2578\n",
      "Epoch 5/20\n",
      "943/943 - 1s - 1ms/step - loss: 109.0892 - mae: 7.1902\n",
      "Epoch 6/20\n",
      "943/943 - 1s - 1ms/step - loss: 108.0343 - mae: 7.1713\n",
      "Epoch 7/20\n",
      "943/943 - 1s - 1ms/step - loss: 106.8437 - mae: 7.1325\n",
      "Epoch 8/20\n",
      "943/943 - 1s - 1ms/step - loss: 106.2997 - mae: 7.1184\n",
      "Epoch 9/20\n",
      "943/943 - 1s - 1ms/step - loss: 105.6600 - mae: 7.0989\n",
      "Epoch 10/20\n",
      "943/943 - 1s - 1ms/step - loss: 105.1102 - mae: 7.0808\n",
      "Epoch 11/20\n",
      "943/943 - 1s - 1ms/step - loss: 104.5123 - mae: 7.0640\n",
      "Epoch 12/20\n",
      "943/943 - 1s - 1ms/step - loss: 104.1920 - mae: 7.0487\n",
      "Epoch 13/20\n",
      "943/943 - 1s - 1ms/step - loss: 103.9849 - mae: 7.0361\n",
      "Epoch 14/20\n",
      "943/943 - 1s - 1ms/step - loss: 103.5635 - mae: 7.0291\n",
      "Epoch 15/20\n",
      "943/943 - 1s - 1ms/step - loss: 103.4049 - mae: 7.0065\n",
      "Epoch 16/20\n",
      "943/943 - 1s - 1ms/step - loss: 103.1283 - mae: 7.0081\n",
      "Epoch 17/20\n",
      "943/943 - 1s - 1ms/step - loss: 102.7153 - mae: 7.0002\n",
      "Epoch 18/20\n",
      "943/943 - 1s - 1ms/step - loss: 102.2833 - mae: 6.9842\n",
      "Epoch 19/20\n",
      "943/943 - 1s - 1ms/step - loss: 102.1460 - mae: 6.9746\n",
      "Epoch 20/20\n",
      "943/943 - 1s - 1ms/step - loss: 101.8215 - mae: 6.9607\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 96.4720 - mae: 6.7358\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點512, epoch20, batch32 訓練集績效:\n",
      "MAE score: 6.818526744842529\n",
      "MAPE score: 24.616242945194244\n",
      "RMSE score: 9.984856774492506\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點512, epoch20, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 27.575653791427612\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "472/472 - 1s - 3ms/step - loss: 351.7668 - mae: 13.2717\n",
      "Epoch 2/20\n",
      "472/472 - 1s - 1ms/step - loss: 117.4764 - mae: 7.5161\n",
      "Epoch 3/20\n",
      "472/472 - 1s - 2ms/step - loss: 113.7537 - mae: 7.3634\n",
      "Epoch 4/20\n",
      "472/472 - 1s - 1ms/step - loss: 111.5155 - mae: 7.2727\n",
      "Epoch 5/20\n",
      "472/472 - 1s - 1ms/step - loss: 109.3459 - mae: 7.2071\n",
      "Epoch 6/20\n",
      "472/472 - 1s - 1ms/step - loss: 107.8924 - mae: 7.1502\n",
      "Epoch 7/20\n",
      "472/472 - 1s - 1ms/step - loss: 106.7558 - mae: 7.1223\n",
      "Epoch 8/20\n",
      "472/472 - 1s - 1ms/step - loss: 105.9575 - mae: 7.1006\n",
      "Epoch 9/20\n",
      "472/472 - 1s - 1ms/step - loss: 105.4228 - mae: 7.0801\n",
      "Epoch 10/20\n",
      "472/472 - 1s - 1ms/step - loss: 104.7210 - mae: 7.0599\n",
      "Epoch 11/20\n",
      "472/472 - 1s - 2ms/step - loss: 103.8884 - mae: 7.0260\n",
      "Epoch 12/20\n",
      "472/472 - 1s - 1ms/step - loss: 103.8268 - mae: 7.0284\n",
      "Epoch 13/20\n",
      "472/472 - 1s - 1ms/step - loss: 103.6249 - mae: 7.0116\n",
      "Epoch 14/20\n",
      "472/472 - 1s - 1ms/step - loss: 103.0466 - mae: 7.0052\n",
      "Epoch 15/20\n",
      "472/472 - 1s - 1ms/step - loss: 102.5418 - mae: 6.9797\n",
      "Epoch 16/20\n",
      "472/472 - 1s - 1ms/step - loss: 102.3105 - mae: 6.9824\n",
      "Epoch 17/20\n",
      "472/472 - 1s - 1ms/step - loss: 102.0916 - mae: 6.9574\n",
      "Epoch 18/20\n",
      "472/472 - 1s - 1ms/step - loss: 102.1442 - mae: 6.9665\n",
      "Epoch 19/20\n",
      "472/472 - 1s - 2ms/step - loss: 101.3065 - mae: 6.9387\n",
      "Epoch 20/20\n",
      "472/472 - 1s - 1ms/step - loss: 101.1861 - mae: 6.9349\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 96.6079 - mae: 6.8771\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點512, epoch20, batch64 訓練集績效:\n",
      "MAE score: 6.961170673370361\n",
      "MAPE score: 25.484171509742737\n",
      "RMSE score: 9.988876641303355\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點512, epoch20, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 27.950018644332886\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "236/236 - 1s - 5ms/step - loss: 552.2280 - mae: 18.0680\n",
      "Epoch 2/20\n",
      "236/236 - 0s - 2ms/step - loss: 120.3940 - mae: 7.6817\n",
      "Epoch 3/20\n",
      "236/236 - 0s - 2ms/step - loss: 115.9697 - mae: 7.4734\n",
      "Epoch 4/20\n",
      "236/236 - 0s - 2ms/step - loss: 113.8621 - mae: 7.3639\n",
      "Epoch 5/20\n",
      "236/236 - 0s - 2ms/step - loss: 112.2903 - mae: 7.2867\n",
      "Epoch 6/20\n",
      "236/236 - 0s - 2ms/step - loss: 110.6497 - mae: 7.2252\n",
      "Epoch 7/20\n",
      "236/236 - 0s - 2ms/step - loss: 109.1152 - mae: 7.1777\n",
      "Epoch 8/20\n",
      "236/236 - 0s - 2ms/step - loss: 107.6515 - mae: 7.1342\n",
      "Epoch 9/20\n",
      "236/236 - 0s - 2ms/step - loss: 106.8206 - mae: 7.1049\n",
      "Epoch 10/20\n",
      "236/236 - 0s - 2ms/step - loss: 105.8937 - mae: 7.1017\n",
      "Epoch 11/20\n",
      "236/236 - 0s - 2ms/step - loss: 105.2382 - mae: 7.0659\n",
      "Epoch 12/20\n",
      "236/236 - 0s - 2ms/step - loss: 104.5132 - mae: 7.0496\n",
      "Epoch 13/20\n",
      "236/236 - 0s - 2ms/step - loss: 104.0536 - mae: 7.0441\n",
      "Epoch 14/20\n",
      "236/236 - 0s - 2ms/step - loss: 103.8260 - mae: 7.0307\n",
      "Epoch 15/20\n",
      "236/236 - 0s - 2ms/step - loss: 103.1665 - mae: 6.9951\n",
      "Epoch 16/20\n",
      "236/236 - 0s - 2ms/step - loss: 103.0940 - mae: 6.9961\n",
      "Epoch 17/20\n",
      "236/236 - 0s - 2ms/step - loss: 102.5091 - mae: 6.9804\n",
      "Epoch 18/20\n",
      "236/236 - 0s - 2ms/step - loss: 102.3386 - mae: 6.9777\n",
      "Epoch 19/20\n",
      "236/236 - 0s - 2ms/step - loss: 102.1706 - mae: 6.9599\n",
      "Epoch 20/20\n",
      "236/236 - 0s - 2ms/step - loss: 101.6636 - mae: 6.9455\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 97.2623 - mae: 6.8233\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點512, epoch20, batch128 訓練集績效:\n",
      "MAE score: 6.902624607086182\n",
      "MAPE score: 25.52625834941864\n",
      "RMSE score: 10.017165900138544\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點512, epoch20, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.48295569419861\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "118/118 - 1s - 8ms/step - loss: 965.3906 - mae: 27.6187\n",
      "Epoch 2/20\n",
      "118/118 - 0s - 2ms/step - loss: 135.9456 - mae: 8.3804\n",
      "Epoch 3/20\n",
      "118/118 - 0s - 2ms/step - loss: 121.2845 - mae: 7.7241\n",
      "Epoch 4/20\n",
      "118/118 - 0s - 2ms/step - loss: 117.7570 - mae: 7.5692\n",
      "Epoch 5/20\n",
      "118/118 - 0s - 2ms/step - loss: 115.4857 - mae: 7.4616\n",
      "Epoch 6/20\n",
      "118/118 - 0s - 2ms/step - loss: 113.9040 - mae: 7.3768\n",
      "Epoch 7/20\n",
      "118/118 - 0s - 3ms/step - loss: 112.7296 - mae: 7.3182\n",
      "Epoch 8/20\n",
      "118/118 - 0s - 2ms/step - loss: 111.5271 - mae: 7.2769\n",
      "Epoch 9/20\n",
      "118/118 - 0s - 2ms/step - loss: 110.3884 - mae: 7.2250\n",
      "Epoch 10/20\n",
      "118/118 - 0s - 2ms/step - loss: 109.3607 - mae: 7.1891\n",
      "Epoch 11/20\n",
      "118/118 - 0s - 2ms/step - loss: 108.3809 - mae: 7.1516\n",
      "Epoch 12/20\n",
      "118/118 - 0s - 2ms/step - loss: 107.4810 - mae: 7.1353\n",
      "Epoch 13/20\n",
      "118/118 - 0s - 2ms/step - loss: 106.6952 - mae: 7.0932\n",
      "Epoch 14/20\n",
      "118/118 - 0s - 2ms/step - loss: 106.1104 - mae: 7.0817\n",
      "Epoch 15/20\n",
      "118/118 - 0s - 2ms/step - loss: 105.5055 - mae: 7.0705\n",
      "Epoch 16/20\n",
      "118/118 - 0s - 3ms/step - loss: 105.0263 - mae: 7.0515\n",
      "Epoch 17/20\n",
      "118/118 - 0s - 2ms/step - loss: 104.5828 - mae: 7.0420\n",
      "Epoch 18/20\n",
      "118/118 - 0s - 3ms/step - loss: 104.2380 - mae: 7.0241\n",
      "Epoch 19/20\n",
      "118/118 - 0s - 2ms/step - loss: 103.8442 - mae: 7.0127\n",
      "Epoch 20/20\n",
      "118/118 - 0s - 2ms/step - loss: 103.5903 - mae: 7.0070\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 99.1098 - mae: 6.8604\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點512, epoch20, batch256 訓練集績效:\n",
      "MAE score: 6.939386367797852\n",
      "MAPE score: 25.498291850090027\n",
      "RMSE score: 10.11187873506869\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點512, epoch20, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.883644938468933\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "943/943 - 2s - 2ms/step - loss: 202.9210 - mae: 9.6323\n",
      "Epoch 2/5\n",
      "943/943 - 1s - 2ms/step - loss: 115.4925 - mae: 7.4240\n",
      "Epoch 3/5\n",
      "943/943 - 1s - 2ms/step - loss: 113.7440 - mae: 7.3464\n",
      "Epoch 4/5\n",
      "943/943 - 1s - 2ms/step - loss: 112.0768 - mae: 7.2976\n",
      "Epoch 5/5\n",
      "943/943 - 2s - 2ms/step - loss: 110.1684 - mae: 7.2396\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 104.8206 - mae: 6.9482\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點1024, epoch5, batch32 訓練集績效:\n",
      "MAE score: 7.035341739654541\n",
      "MAPE score: 25.87983012199402\n",
      "RMSE score: 10.403912439220582\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點1024, epoch5, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.411974549293518\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "472/472 - 2s - 3ms/step - loss: 279.0382 - mae: 11.4798\n",
      "Epoch 2/5\n",
      "472/472 - 1s - 2ms/step - loss: 115.5981 - mae: 7.4467\n",
      "Epoch 3/5\n",
      "472/472 - 1s - 2ms/step - loss: 112.9649 - mae: 7.3112\n",
      "Epoch 4/5\n",
      "472/472 - 1s - 2ms/step - loss: 110.8436 - mae: 7.2363\n",
      "Epoch 5/5\n",
      "472/472 - 1s - 2ms/step - loss: 108.7825 - mae: 7.1945\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 102.9348 - mae: 7.0969\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點1024, epoch5, batch64 訓練集績效:\n",
      "MAE score: 7.179378986358643\n",
      "MAPE score: 26.392674446105957\n",
      "RMSE score: 10.306542727706846\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點1024, epoch5, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.787818551063538\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "236/236 - 1s - 5ms/step - loss: 426.4070 - mae: 15.0626\n",
      "Epoch 2/5\n",
      "236/236 - 1s - 2ms/step - loss: 117.8850 - mae: 7.5556\n",
      "Epoch 3/5\n",
      "236/236 - 0s - 2ms/step - loss: 114.1139 - mae: 7.3840\n",
      "Epoch 4/5\n",
      "236/236 - 0s - 2ms/step - loss: 112.2002 - mae: 7.2830\n",
      "Epoch 5/5\n",
      "236/236 - 0s - 2ms/step - loss: 110.4008 - mae: 7.2287\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 104.6840 - mae: 7.0681\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點1024, epoch5, batch128 訓練集績效:\n",
      "MAE score: 7.155813217163086\n",
      "MAPE score: 26.7225980758667\n",
      "RMSE score: 10.397544174742546\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點1024, epoch5, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.574838280677795\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "118/118 - 1s - 9ms/step - loss: 718.3508 - mae: 22.0236\n",
      "Epoch 2/5\n",
      "118/118 - 0s - 3ms/step - loss: 123.3836 - mae: 7.8029\n",
      "Epoch 3/5\n",
      "118/118 - 0s - 4ms/step - loss: 117.2708 - mae: 7.5380\n",
      "Epoch 4/5\n",
      "118/118 - 0s - 3ms/step - loss: 114.8724 - mae: 7.4144\n",
      "Epoch 5/5\n",
      "118/118 - 0s - 3ms/step - loss: 113.0120 - mae: 7.3270\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 108.0954 - mae: 7.1920\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點1024, epoch5, batch256 訓練集績效:\n",
      "MAE score: 7.264667987823486\n",
      "MAPE score: 27.147620916366577\n",
      "RMSE score: 10.553978004581563\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點1024, epoch5, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 30.13041615486145\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "943/943 - 2s - 2ms/step - loss: 203.3100 - mae: 9.6774\n",
      "Epoch 2/10\n",
      "943/943 - 2s - 2ms/step - loss: 115.4181 - mae: 7.4222\n",
      "Epoch 3/10\n",
      "943/943 - 1s - 2ms/step - loss: 113.1450 - mae: 7.3280\n",
      "Epoch 4/10\n",
      "943/943 - 1s - 2ms/step - loss: 111.1084 - mae: 7.2645\n",
      "Epoch 5/10\n",
      "943/943 - 1s - 2ms/step - loss: 109.0564 - mae: 7.2256\n",
      "Epoch 6/10\n",
      "943/943 - 1s - 2ms/step - loss: 107.9115 - mae: 7.1918\n",
      "Epoch 7/10\n",
      "943/943 - 1s - 2ms/step - loss: 106.8788 - mae: 7.1579\n",
      "Epoch 8/10\n",
      "943/943 - 1s - 2ms/step - loss: 106.5469 - mae: 7.1261\n",
      "Epoch 9/10\n",
      "943/943 - 2s - 2ms/step - loss: 105.8261 - mae: 7.1222\n",
      "Epoch 10/10\n",
      "943/943 - 1s - 2ms/step - loss: 105.0864 - mae: 7.0889\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 101.7141 - mae: 7.0106\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點1024, epoch10, batch32 訓練集績效:\n",
      "MAE score: 7.083189487457275\n",
      "MAPE score: 25.010675191879272\n",
      "RMSE score: 10.235290765922983\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點1024, epoch10, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.36005389690399\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "472/472 - 2s - 3ms/step - loss: 279.4502 - mae: 11.4985\n",
      "Epoch 2/10\n",
      "472/472 - 1s - 2ms/step - loss: 115.7830 - mae: 7.4395\n",
      "Epoch 3/10\n",
      "472/472 - 1s - 2ms/step - loss: 112.8775 - mae: 7.3235\n",
      "Epoch 4/10\n",
      "472/472 - 1s - 2ms/step - loss: 111.0010 - mae: 7.2397\n",
      "Epoch 5/10\n",
      "472/472 - 1s - 2ms/step - loss: 108.6418 - mae: 7.1828\n",
      "Epoch 6/10\n",
      "472/472 - 1s - 2ms/step - loss: 107.1832 - mae: 7.1507\n",
      "Epoch 7/10\n",
      "472/472 - 1s - 2ms/step - loss: 106.3733 - mae: 7.1228\n",
      "Epoch 8/10\n",
      "472/472 - 1s - 2ms/step - loss: 105.7406 - mae: 7.1177\n",
      "Epoch 9/10\n",
      "472/472 - 1s - 2ms/step - loss: 105.0451 - mae: 7.0890\n",
      "Epoch 10/10\n",
      "472/472 - 1s - 2ms/step - loss: 104.6908 - mae: 7.0481\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 100.1805 - mae: 7.0419\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點1024, epoch10, batch64 訓練集績效:\n",
      "MAE score: 7.117006778717041\n",
      "MAPE score: 26.321572065353394\n",
      "RMSE score: 10.163582464283978\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點1024, epoch10, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.46217453479767\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "236/236 - 1s - 5ms/step - loss: 423.6870 - mae: 15.0196\n",
      "Epoch 2/10\n",
      "236/236 - 0s - 2ms/step - loss: 117.6159 - mae: 7.5446\n",
      "Epoch 3/10\n",
      "236/236 - 1s - 2ms/step - loss: 114.1902 - mae: 7.3751\n",
      "Epoch 4/10\n",
      "236/236 - 0s - 2ms/step - loss: 112.3464 - mae: 7.3047\n",
      "Epoch 5/10\n",
      "236/236 - 0s - 2ms/step - loss: 110.2953 - mae: 7.2256\n",
      "Epoch 6/10\n",
      "236/236 - 1s - 3ms/step - loss: 108.6656 - mae: 7.1755\n",
      "Epoch 7/10\n",
      "236/236 - 0s - 2ms/step - loss: 107.3763 - mae: 7.1421\n",
      "Epoch 8/10\n",
      "236/236 - 1s - 3ms/step - loss: 106.2694 - mae: 7.0996\n",
      "Epoch 9/10\n",
      "236/236 - 0s - 2ms/step - loss: 105.5663 - mae: 7.0778\n",
      "Epoch 10/10\n",
      "236/236 - 1s - 2ms/step - loss: 105.1559 - mae: 7.0717\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 100.4100 - mae: 6.9029\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點1024, epoch10, batch128 訓練集績效:\n",
      "MAE score: 6.973602771759033\n",
      "MAPE score: 25.512436032295227\n",
      "RMSE score: 10.161572373436403\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點1024, epoch10, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.437641263008118\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "118/118 - 1s - 9ms/step - loss: 732.1277 - mae: 22.2736\n",
      "Epoch 2/10\n",
      "118/118 - 0s - 4ms/step - loss: 123.2395 - mae: 7.7809\n",
      "Epoch 3/10\n",
      "118/118 - 0s - 3ms/step - loss: 117.4596 - mae: 7.5404\n",
      "Epoch 4/10\n",
      "118/118 - 0s - 3ms/step - loss: 115.0427 - mae: 7.4171\n",
      "Epoch 5/10\n",
      "118/118 - 0s - 3ms/step - loss: 113.1624 - mae: 7.3345\n",
      "Epoch 6/10\n",
      "118/118 - 0s - 3ms/step - loss: 111.7736 - mae: 7.2667\n",
      "Epoch 7/10\n",
      "118/118 - 0s - 3ms/step - loss: 110.5370 - mae: 7.2220\n",
      "Epoch 8/10\n",
      "118/118 - 0s - 3ms/step - loss: 109.2593 - mae: 7.1793\n",
      "Epoch 9/10\n",
      "118/118 - 0s - 3ms/step - loss: 108.0014 - mae: 7.1384\n",
      "Epoch 10/10\n",
      "118/118 - 0s - 4ms/step - loss: 107.0437 - mae: 7.1053\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 102.3296 - mae: 6.9460\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點1024, epoch10, batch256 訓練集績效:\n",
      "MAE score: 7.02797794342041\n",
      "MAPE score: 26.10924541950226\n",
      "RMSE score: 10.272085447508601\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點1024, epoch10, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.191669821739197\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "943/943 - 2s - 2ms/step - loss: 204.3238 - mae: 9.6646\n",
      "Epoch 2/20\n",
      "943/943 - 1s - 2ms/step - loss: 115.3623 - mae: 7.4216\n",
      "Epoch 3/20\n",
      "943/943 - 2s - 2ms/step - loss: 113.0028 - mae: 7.3293\n",
      "Epoch 4/20\n",
      "943/943 - 1s - 2ms/step - loss: 110.5960 - mae: 7.2599\n",
      "Epoch 5/20\n",
      "943/943 - 1s - 2ms/step - loss: 109.0262 - mae: 7.2109\n",
      "Epoch 6/20\n",
      "943/943 - 1s - 2ms/step - loss: 107.9997 - mae: 7.1828\n",
      "Epoch 7/20\n",
      "943/943 - 1s - 2ms/step - loss: 107.1480 - mae: 7.1656\n",
      "Epoch 8/20\n",
      "943/943 - 1s - 2ms/step - loss: 106.0383 - mae: 7.1223\n",
      "Epoch 9/20\n",
      "943/943 - 1s - 2ms/step - loss: 105.8311 - mae: 7.1142\n",
      "Epoch 10/20\n",
      "943/943 - 3s - 3ms/step - loss: 105.1399 - mae: 7.0914\n",
      "Epoch 11/20\n",
      "943/943 - 1s - 2ms/step - loss: 104.7078 - mae: 7.0802\n",
      "Epoch 12/20\n",
      "943/943 - 3s - 3ms/step - loss: 104.3328 - mae: 7.0714\n",
      "Epoch 13/20\n",
      "943/943 - 1s - 2ms/step - loss: 103.9848 - mae: 7.0496\n",
      "Epoch 14/20\n",
      "943/943 - 1s - 1ms/step - loss: 103.6114 - mae: 7.0385\n",
      "Epoch 15/20\n",
      "943/943 - 1s - 2ms/step - loss: 103.0992 - mae: 7.0193\n",
      "Epoch 16/20\n",
      "943/943 - 1s - 2ms/step - loss: 102.8420 - mae: 7.0214\n",
      "Epoch 17/20\n",
      "943/943 - 1s - 1ms/step - loss: 102.7225 - mae: 7.0055\n",
      "Epoch 18/20\n",
      "943/943 - 1s - 2ms/step - loss: 102.4421 - mae: 6.9809\n",
      "Epoch 19/20\n",
      "943/943 - 2s - 2ms/step - loss: 102.3399 - mae: 6.9953\n",
      "Epoch 20/20\n",
      "943/943 - 2s - 2ms/step - loss: 102.0983 - mae: 6.9829\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 96.3334 - mae: 6.7481\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點1024, epoch20, batch32 訓練集績效:\n",
      "MAE score: 6.817963123321533\n",
      "MAPE score: 24.844667315483093\n",
      "RMSE score: 9.965610882858847\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點1024, epoch20, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 27.620825171470642\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "472/472 - 2s - 4ms/step - loss: 276.2953 - mae: 11.4119\n",
      "Epoch 2/20\n",
      "472/472 - 1s - 2ms/step - loss: 115.4954 - mae: 7.4402\n",
      "Epoch 3/20\n",
      "472/472 - 1s - 2ms/step - loss: 113.0488 - mae: 7.3145\n",
      "Epoch 4/20\n",
      "472/472 - 1s - 2ms/step - loss: 111.2393 - mae: 7.2538\n",
      "Epoch 5/20\n",
      "472/472 - 1s - 2ms/step - loss: 109.5645 - mae: 7.1950\n",
      "Epoch 6/20\n",
      "472/472 - 1s - 2ms/step - loss: 107.7663 - mae: 7.1480\n",
      "Epoch 7/20\n",
      "472/472 - 1s - 2ms/step - loss: 106.9331 - mae: 7.1318\n",
      "Epoch 8/20\n",
      "472/472 - 1s - 2ms/step - loss: 105.9042 - mae: 7.1156\n",
      "Epoch 9/20\n",
      "472/472 - 1s - 2ms/step - loss: 105.6090 - mae: 7.1060\n",
      "Epoch 10/20\n",
      "472/472 - 1s - 2ms/step - loss: 104.9372 - mae: 7.0735\n",
      "Epoch 11/20\n",
      "472/472 - 1s - 2ms/step - loss: 104.1013 - mae: 7.0431\n",
      "Epoch 12/20\n",
      "472/472 - 1s - 2ms/step - loss: 103.6844 - mae: 7.0410\n",
      "Epoch 13/20\n",
      "472/472 - 1s - 2ms/step - loss: 103.3298 - mae: 7.0218\n",
      "Epoch 14/20\n",
      "472/472 - 1s - 2ms/step - loss: 103.2820 - mae: 7.0104\n",
      "Epoch 15/20\n",
      "472/472 - 1s - 2ms/step - loss: 102.9657 - mae: 7.0054\n",
      "Epoch 16/20\n",
      "472/472 - 1s - 2ms/step - loss: 102.3423 - mae: 6.9797\n",
      "Epoch 17/20\n",
      "472/472 - 1s - 2ms/step - loss: 102.0436 - mae: 6.9689\n",
      "Epoch 18/20\n",
      "472/472 - 1s - 2ms/step - loss: 101.9254 - mae: 6.9714\n",
      "Epoch 19/20\n",
      "472/472 - 1s - 2ms/step - loss: 101.3763 - mae: 6.9420\n",
      "Epoch 20/20\n",
      "472/472 - 1s - 2ms/step - loss: 101.3511 - mae: 6.9544\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 97.2829 - mae: 6.8055\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點1024, epoch20, batch64 訓練集績效:\n",
      "MAE score: 6.868446350097656\n",
      "MAPE score: 24.699674546718597\n",
      "RMSE score: 9.996110922831088\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點1024, epoch20, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 27.43844985961914\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "236/236 - 1s - 5ms/step - loss: 419.1847 - mae: 14.9540\n",
      "Epoch 2/20\n",
      "236/236 - 0s - 2ms/step - loss: 119.0025 - mae: 7.5546\n",
      "Epoch 3/20\n",
      "236/236 - 0s - 2ms/step - loss: 114.5494 - mae: 7.3923\n",
      "Epoch 4/20\n",
      "236/236 - 0s - 2ms/step - loss: 111.8147 - mae: 7.2814\n",
      "Epoch 5/20\n",
      "236/236 - 0s - 2ms/step - loss: 110.0265 - mae: 7.2183\n",
      "Epoch 6/20\n",
      "236/236 - 0s - 2ms/step - loss: 108.5132 - mae: 7.1723\n",
      "Epoch 7/20\n",
      "236/236 - 0s - 2ms/step - loss: 107.2736 - mae: 7.1394\n",
      "Epoch 8/20\n",
      "236/236 - 1s - 2ms/step - loss: 106.1945 - mae: 7.1154\n",
      "Epoch 9/20\n",
      "236/236 - 0s - 2ms/step - loss: 105.3743 - mae: 7.0628\n",
      "Epoch 10/20\n",
      "236/236 - 0s - 2ms/step - loss: 105.0643 - mae: 7.0634\n",
      "Epoch 11/20\n",
      "236/236 - 0s - 2ms/step - loss: 104.8543 - mae: 7.0574\n",
      "Epoch 12/20\n",
      "236/236 - 0s - 2ms/step - loss: 104.0520 - mae: 7.0404\n",
      "Epoch 13/20\n",
      "236/236 - 0s - 2ms/step - loss: 103.3191 - mae: 7.0037\n",
      "Epoch 14/20\n",
      "236/236 - 1s - 2ms/step - loss: 102.9386 - mae: 7.0096\n",
      "Epoch 15/20\n",
      "236/236 - 0s - 2ms/step - loss: 102.6928 - mae: 6.9919\n",
      "Epoch 16/20\n",
      "236/236 - 0s - 2ms/step - loss: 102.5471 - mae: 6.9837\n",
      "Epoch 17/20\n",
      "236/236 - 0s - 2ms/step - loss: 102.0608 - mae: 6.9472\n",
      "Epoch 18/20\n",
      "236/236 - 1s - 2ms/step - loss: 101.8552 - mae: 6.9651\n",
      "Epoch 19/20\n",
      "236/236 - 0s - 2ms/step - loss: 101.6389 - mae: 6.9524\n",
      "Epoch 20/20\n",
      "236/236 - 0s - 2ms/step - loss: 101.1625 - mae: 6.9395\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 96.0113 - mae: 6.7566\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點1024, epoch20, batch128 訓練集績效:\n",
      "MAE score: 6.838010311126709\n",
      "MAPE score: 25.042825937271118\n",
      "RMSE score: 9.951021028972\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點1024, epoch20, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 27.915215492248535\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "118/118 - 1s - 9ms/step - loss: 706.1982 - mae: 21.7002\n",
      "Epoch 2/20\n",
      "118/118 - 0s - 3ms/step - loss: 123.0593 - mae: 7.7904\n",
      "Epoch 3/20\n",
      "118/118 - 0s - 3ms/step - loss: 117.6079 - mae: 7.5445\n",
      "Epoch 4/20\n",
      "118/118 - 0s - 3ms/step - loss: 114.9342 - mae: 7.4151\n",
      "Epoch 5/20\n",
      "118/118 - 0s - 3ms/step - loss: 113.2406 - mae: 7.3374\n",
      "Epoch 6/20\n",
      "118/118 - 0s - 3ms/step - loss: 111.7055 - mae: 7.2744\n",
      "Epoch 7/20\n",
      "118/118 - 0s - 4ms/step - loss: 110.6479 - mae: 7.2160\n",
      "Epoch 8/20\n",
      "118/118 - 0s - 3ms/step - loss: 109.3234 - mae: 7.1810\n",
      "Epoch 9/20\n",
      "118/118 - 0s - 3ms/step - loss: 108.2806 - mae: 7.1378\n",
      "Epoch 10/20\n",
      "118/118 - 0s - 3ms/step - loss: 107.0184 - mae: 7.1166\n",
      "Epoch 11/20\n",
      "118/118 - 0s - 3ms/step - loss: 106.2807 - mae: 7.0877\n",
      "Epoch 12/20\n",
      "118/118 - 0s - 3ms/step - loss: 105.7610 - mae: 7.0656\n",
      "Epoch 13/20\n",
      "118/118 - 0s - 4ms/step - loss: 105.2795 - mae: 7.0618\n",
      "Epoch 14/20\n",
      "118/118 - 0s - 3ms/step - loss: 104.6244 - mae: 7.0419\n",
      "Epoch 15/20\n",
      "118/118 - 0s - 3ms/step - loss: 104.0974 - mae: 7.0200\n",
      "Epoch 16/20\n",
      "118/118 - 0s - 3ms/step - loss: 103.6539 - mae: 7.0029\n",
      "Epoch 17/20\n",
      "118/118 - 0s - 3ms/step - loss: 103.2559 - mae: 6.9872\n",
      "Epoch 18/20\n",
      "118/118 - 0s - 3ms/step - loss: 103.2534 - mae: 6.9890\n",
      "Epoch 19/20\n",
      "118/118 - 0s - 4ms/step - loss: 102.6559 - mae: 6.9863\n",
      "Epoch 20/20\n",
      "118/118 - 0s - 3ms/step - loss: 102.1719 - mae: 6.9542\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 97.5885 - mae: 6.8202\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點1024, epoch20, batch256 訓練集績效:\n",
      "MAE score: 6.903898239135742\n",
      "MAPE score: 25.416848063468933\n",
      "RMSE score: 10.038055108137428\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層1, 節點1024, epoch20, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.417304158210754\n",
      "RMSE score: 14.235763666311897\n",
      "==================================================\n",
      "Completed batch for layer 1\n",
      "==================================================\n",
      "Epoch 1/5\n",
      "943/943 - 2s - 2ms/step - loss: 232.8463 - mae: 10.2651\n",
      "Epoch 2/5\n",
      "943/943 - 1s - 1ms/step - loss: 116.5986 - mae: 7.4756\n",
      "Epoch 3/5\n",
      "943/943 - 1s - 1ms/step - loss: 114.4998 - mae: 7.3905\n",
      "Epoch 4/5\n",
      "943/943 - 1s - 1ms/step - loss: 113.1060 - mae: 7.3368\n",
      "Epoch 5/5\n",
      "943/943 - 1s - 1ms/step - loss: 112.0048 - mae: 7.2897\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 986us/step - loss: 107.2346 - mae: 7.2376\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點64, epoch5, batch32 訓練集績效:\n",
      "MAE score: 7.32235050201416\n",
      "MAPE score: 27.779439091682434\n",
      "RMSE score: 10.522661368813255\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點64, epoch5, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 31.095123291015625\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "472/472 - 1s - 3ms/step - loss: 343.2280 - mae: 12.6215\n",
      "Epoch 2/5\n",
      "472/472 - 1s - 1ms/step - loss: 118.1770 - mae: 7.5428\n",
      "Epoch 3/5\n",
      "472/472 - 1s - 1ms/step - loss: 115.4101 - mae: 7.4133\n",
      "Epoch 4/5\n",
      "472/472 - 1s - 1ms/step - loss: 113.8575 - mae: 7.3445\n",
      "Epoch 5/5\n",
      "472/472 - 1s - 1ms/step - loss: 112.9461 - mae: 7.3018\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 989us/step - loss: 107.6797 - mae: 7.1536\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step  \n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點64, epoch5, batch64 訓練集績效:\n",
      "MAE score: 7.237822532653809\n",
      "MAPE score: 27.277424931526184\n",
      "RMSE score: 10.52887062790776\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點64, epoch5, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 31.02101981639862\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "236/236 - 1s - 5ms/step - loss: 540.0153 - mae: 17.1961\n",
      "Epoch 2/5\n",
      "236/236 - 0s - 2ms/step - loss: 121.8338 - mae: 7.6996\n",
      "Epoch 3/5\n",
      "236/236 - 0s - 1ms/step - loss: 117.0102 - mae: 7.5183\n",
      "Epoch 4/5\n",
      "236/236 - 0s - 1ms/step - loss: 114.8122 - mae: 7.4127\n",
      "Epoch 5/5\n",
      "236/236 - 0s - 1ms/step - loss: 113.6867 - mae: 7.3609\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 975us/step - loss: 109.0692 - mae: 7.1957\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step  \n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點64, epoch5, batch128 訓練集績效:\n",
      "MAE score: 7.272233009338379\n",
      "MAPE score: 27.055230736732483\n",
      "RMSE score: 10.599527859519336\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點64, epoch5, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 31.213131546974182\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "118/118 - 1s - 9ms/step - loss: 959.1693 - mae: 26.6173\n",
      "Epoch 2/5\n",
      "118/118 - 0s - 2ms/step - loss: 129.8075 - mae: 7.9765\n",
      "Epoch 3/5\n",
      "118/118 - 0s - 2ms/step - loss: 120.6254 - mae: 7.6874\n",
      "Epoch 4/5\n",
      "118/118 - 0s - 2ms/step - loss: 117.4347 - mae: 7.5449\n",
      "Epoch 5/5\n",
      "118/118 - 0s - 1ms/step - loss: 115.7419 - mae: 7.4563\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 984us/step - loss: 110.6823 - mae: 7.3194\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點64, epoch5, batch256 訓練集績效:\n",
      "MAE score: 7.392140865325928\n",
      "MAPE score: 27.74980664253235\n",
      "RMSE score: 10.680265063593378\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點64, epoch5, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 31.11148476600647\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "943/943 - 2s - 2ms/step - loss: 223.0017 - mae: 10.0599\n",
      "Epoch 2/10\n",
      "943/943 - 1s - 1ms/step - loss: 116.6755 - mae: 7.4949\n",
      "Epoch 3/10\n",
      "943/943 - 1s - 1ms/step - loss: 114.1174 - mae: 7.3890\n",
      "Epoch 4/10\n",
      "943/943 - 1s - 1ms/step - loss: 112.6515 - mae: 7.3386\n",
      "Epoch 5/10\n",
      "943/943 - 1s - 1ms/step - loss: 110.8104 - mae: 7.2743\n",
      "Epoch 6/10\n",
      "943/943 - 1s - 1ms/step - loss: 109.6898 - mae: 7.2435\n",
      "Epoch 7/10\n",
      "943/943 - 1s - 1ms/step - loss: 108.1074 - mae: 7.2047\n",
      "Epoch 8/10\n",
      "943/943 - 1s - 1ms/step - loss: 107.6532 - mae: 7.1783\n",
      "Epoch 9/10\n",
      "943/943 - 1s - 1ms/step - loss: 107.0811 - mae: 7.1643\n",
      "Epoch 10/10\n",
      "943/943 - 1s - 1ms/step - loss: 106.4838 - mae: 7.1391\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 983us/step - loss: 100.8645 - mae: 6.9324\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step  \n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點64, epoch10, batch32 訓練集績效:\n",
      "MAE score: 7.018354415893555\n",
      "MAPE score: 25.579825043678284\n",
      "RMSE score: 10.216838879609217\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點64, epoch10, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.487508535385132\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "472/472 - 1s - 3ms/step - loss: 318.9536 - mae: 12.2255\n",
      "Epoch 2/10\n",
      "472/472 - 0s - 1ms/step - loss: 117.7099 - mae: 7.5594\n",
      "Epoch 3/10\n",
      "472/472 - 1s - 1ms/step - loss: 114.9090 - mae: 7.4100\n",
      "Epoch 4/10\n",
      "472/472 - 0s - 1ms/step - loss: 113.1294 - mae: 7.3454\n",
      "Epoch 5/10\n",
      "472/472 - 1s - 2ms/step - loss: 111.9254 - mae: 7.3046\n",
      "Epoch 6/10\n",
      "472/472 - 1s - 1ms/step - loss: 110.7579 - mae: 7.2502\n",
      "Epoch 7/10\n",
      "472/472 - 0s - 1ms/step - loss: 109.6255 - mae: 7.2226\n",
      "Epoch 8/10\n",
      "472/472 - 1s - 1ms/step - loss: 108.6481 - mae: 7.1788\n",
      "Epoch 9/10\n",
      "472/472 - 1s - 1ms/step - loss: 107.6203 - mae: 7.1500\n",
      "Epoch 10/10\n",
      "472/472 - 0s - 1ms/step - loss: 106.9635 - mae: 7.1345\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 979us/step - loss: 104.5471 - mae: 7.0674\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點64, epoch10, batch64 訓練集績效:\n",
      "MAE score: 7.145233154296875\n",
      "MAPE score: 25.219255685806274\n",
      "RMSE score: 10.379192194734346\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點64, epoch10, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 30.55315613746643\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "236/236 - 1s - 5ms/step - loss: 464.6506 - mae: 15.6750\n",
      "Epoch 2/10\n",
      "236/236 - 0s - 2ms/step - loss: 121.0180 - mae: 7.6823\n",
      "Epoch 3/10\n",
      "236/236 - 0s - 1ms/step - loss: 117.0348 - mae: 7.5026\n",
      "Epoch 4/10\n",
      "236/236 - 0s - 1ms/step - loss: 115.0839 - mae: 7.3951\n",
      "Epoch 5/10\n",
      "236/236 - 0s - 1ms/step - loss: 113.6101 - mae: 7.3510\n",
      "Epoch 6/10\n",
      "236/236 - 0s - 1ms/step - loss: 112.6515 - mae: 7.3026\n",
      "Epoch 7/10\n",
      "236/236 - 0s - 1ms/step - loss: 111.9537 - mae: 7.2687\n",
      "Epoch 8/10\n",
      "236/236 - 0s - 2ms/step - loss: 111.2632 - mae: 7.2367\n",
      "Epoch 9/10\n",
      "236/236 - 0s - 1ms/step - loss: 110.6344 - mae: 7.2185\n",
      "Epoch 10/10\n",
      "236/236 - 0s - 1ms/step - loss: 109.9537 - mae: 7.2057\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 976us/step - loss: 105.0782 - mae: 7.0334\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點64, epoch10, batch128 訓練集績效:\n",
      "MAE score: 7.116014003753662\n",
      "MAPE score: 26.275604963302612\n",
      "RMSE score: 10.413264296234042\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點64, epoch10, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 30.223822593688965\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "118/118 - 1s - 9ms/step - loss: 871.7353 - mae: 24.7155\n",
      "Epoch 2/10\n",
      "118/118 - 0s - 2ms/step - loss: 130.6135 - mae: 7.9711\n",
      "Epoch 3/10\n",
      "118/118 - 0s - 2ms/step - loss: 120.6977 - mae: 7.6655\n",
      "Epoch 4/10\n",
      "118/118 - 0s - 1ms/step - loss: 117.4647 - mae: 7.5300\n",
      "Epoch 5/10\n",
      "118/118 - 0s - 2ms/step - loss: 115.5905 - mae: 7.4541\n",
      "Epoch 6/10\n",
      "118/118 - 0s - 2ms/step - loss: 114.1510 - mae: 7.3789\n",
      "Epoch 7/10\n",
      "118/118 - 0s - 2ms/step - loss: 113.1021 - mae: 7.3364\n",
      "Epoch 8/10\n",
      "118/118 - 0s - 1ms/step - loss: 111.9635 - mae: 7.2844\n",
      "Epoch 9/10\n",
      "118/118 - 0s - 1ms/step - loss: 111.0138 - mae: 7.2458\n",
      "Epoch 10/10\n",
      "118/118 - 0s - 1ms/step - loss: 110.1769 - mae: 7.2188\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 105.3588 - mae: 7.1004\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點64, epoch10, batch256 訓練集績效:\n",
      "MAE score: 7.180125713348389\n",
      "MAPE score: 26.79232954978943\n",
      "RMSE score: 10.429299793823798\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點64, epoch10, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 30.47488033771515\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "943/943 - 2s - 2ms/step - loss: 237.3696 - mae: 10.3019\n",
      "Epoch 2/20\n",
      "943/943 - 1s - 1ms/step - loss: 116.2311 - mae: 7.4639\n",
      "Epoch 3/20\n",
      "943/943 - 1s - 1ms/step - loss: 114.3671 - mae: 7.3877\n",
      "Epoch 4/20\n",
      "943/943 - 1s - 1ms/step - loss: 113.3184 - mae: 7.3426\n",
      "Epoch 5/20\n",
      "943/943 - 1s - 1ms/step - loss: 112.3832 - mae: 7.3141\n",
      "Epoch 6/20\n",
      "943/943 - 1s - 1ms/step - loss: 111.6307 - mae: 7.2690\n",
      "Epoch 7/20\n",
      "943/943 - 1s - 1ms/step - loss: 111.3365 - mae: 7.2775\n",
      "Epoch 8/20\n",
      "943/943 - 1s - 1ms/step - loss: 110.9086 - mae: 7.2573\n",
      "Epoch 9/20\n",
      "943/943 - 1s - 1ms/step - loss: 110.6411 - mae: 7.2378\n",
      "Epoch 10/20\n",
      "943/943 - 1s - 1ms/step - loss: 109.8131 - mae: 7.2102\n",
      "Epoch 11/20\n",
      "943/943 - 1s - 1ms/step - loss: 109.5591 - mae: 7.2141\n",
      "Epoch 12/20\n",
      "943/943 - 1s - 1ms/step - loss: 108.9346 - mae: 7.1854\n",
      "Epoch 13/20\n",
      "943/943 - 1s - 1ms/step - loss: 108.4357 - mae: 7.1741\n",
      "Epoch 14/20\n",
      "943/943 - 1s - 1ms/step - loss: 107.5103 - mae: 7.1396\n",
      "Epoch 15/20\n",
      "943/943 - 1s - 1ms/step - loss: 106.9930 - mae: 7.1139\n",
      "Epoch 16/20\n",
      "943/943 - 1s - 1ms/step - loss: 106.1670 - mae: 7.1055\n",
      "Epoch 17/20\n",
      "943/943 - 1s - 1ms/step - loss: 105.6178 - mae: 7.0813\n",
      "Epoch 18/20\n",
      "943/943 - 1s - 1ms/step - loss: 104.7732 - mae: 7.0646\n",
      "Epoch 19/20\n",
      "943/943 - 1s - 1ms/step - loss: 104.1321 - mae: 7.0438\n",
      "Epoch 20/20\n",
      "943/943 - 1s - 1ms/step - loss: 103.4800 - mae: 7.0053\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 987us/step - loss: 99.6431 - mae: 6.8103\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點64, epoch20, batch32 訓練集績效:\n",
      "MAE score: 6.863498687744141\n",
      "MAPE score: 24.32691901922226\n",
      "RMSE score: 10.10774172954047\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點64, epoch20, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.35676872730255\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "472/472 - 1s - 3ms/step - loss: 296.5801 - mae: 11.8050\n",
      "Epoch 2/20\n",
      "472/472 - 1s - 1ms/step - loss: 117.5184 - mae: 7.5268\n",
      "Epoch 3/20\n",
      "472/472 - 0s - 1ms/step - loss: 114.9042 - mae: 7.4139\n",
      "Epoch 4/20\n",
      "472/472 - 1s - 1ms/step - loss: 113.3575 - mae: 7.3433\n",
      "Epoch 5/20\n",
      "472/472 - 1s - 1ms/step - loss: 112.3852 - mae: 7.2981\n",
      "Epoch 6/20\n",
      "472/472 - 1s - 1ms/step - loss: 111.7357 - mae: 7.2818\n",
      "Epoch 7/20\n",
      "472/472 - 1s - 1ms/step - loss: 111.1491 - mae: 7.2517\n",
      "Epoch 8/20\n",
      "472/472 - 1s - 1ms/step - loss: 110.5807 - mae: 7.2299\n",
      "Epoch 9/20\n",
      "472/472 - 1s - 1ms/step - loss: 110.5196 - mae: 7.2366\n",
      "Epoch 10/20\n",
      "472/472 - 1s - 1ms/step - loss: 109.6682 - mae: 7.2034\n",
      "Epoch 11/20\n",
      "472/472 - 0s - 1ms/step - loss: 109.1754 - mae: 7.1887\n",
      "Epoch 12/20\n",
      "472/472 - 1s - 1ms/step - loss: 108.7699 - mae: 7.1684\n",
      "Epoch 13/20\n",
      "472/472 - 1s - 1ms/step - loss: 107.6063 - mae: 7.1406\n",
      "Epoch 14/20\n",
      "472/472 - 1s - 1ms/step - loss: 106.6428 - mae: 7.1022\n",
      "Epoch 15/20\n",
      "472/472 - 1s - 1ms/step - loss: 105.8419 - mae: 7.0787\n",
      "Epoch 16/20\n",
      "472/472 - 1s - 1ms/step - loss: 105.3991 - mae: 7.0761\n",
      "Epoch 17/20\n",
      "472/472 - 1s - 1ms/step - loss: 104.8508 - mae: 7.0518\n",
      "Epoch 18/20\n",
      "472/472 - 1s - 2ms/step - loss: 104.0070 - mae: 7.0220\n",
      "Epoch 19/20\n",
      "472/472 - 1s - 1ms/step - loss: 103.8853 - mae: 7.0126\n",
      "Epoch 20/20\n",
      "472/472 - 1s - 1ms/step - loss: 103.3593 - mae: 6.9978\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 906us/step - loss: 99.3361 - mae: 6.9308\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點64, epoch20, batch64 訓練集績效:\n",
      "MAE score: 6.987977981567383\n",
      "MAPE score: 25.99422335624695\n",
      "RMSE score: 10.097106564462965\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點64, epoch20, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.735705256462097\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "236/236 - 1s - 5ms/step - loss: 466.8225 - mae: 15.7954\n",
      "Epoch 2/20\n",
      "236/236 - 0s - 1ms/step - loss: 121.4372 - mae: 7.6780\n",
      "Epoch 3/20\n",
      "236/236 - 0s - 1ms/step - loss: 117.0472 - mae: 7.4881\n",
      "Epoch 4/20\n",
      "236/236 - 0s - 1ms/step - loss: 114.7379 - mae: 7.3943\n",
      "Epoch 5/20\n",
      "236/236 - 0s - 1ms/step - loss: 113.4728 - mae: 7.3335\n",
      "Epoch 6/20\n",
      "236/236 - 0s - 1ms/step - loss: 112.3433 - mae: 7.2981\n",
      "Epoch 7/20\n",
      "236/236 - 0s - 2ms/step - loss: 111.2904 - mae: 7.2327\n",
      "Epoch 8/20\n",
      "236/236 - 0s - 1ms/step - loss: 110.5298 - mae: 7.2295\n",
      "Epoch 9/20\n",
      "236/236 - 0s - 1ms/step - loss: 109.6244 - mae: 7.1884\n",
      "Epoch 10/20\n",
      "236/236 - 0s - 1ms/step - loss: 108.6282 - mae: 7.1604\n",
      "Epoch 11/20\n",
      "236/236 - 0s - 1ms/step - loss: 107.9629 - mae: 7.1420\n",
      "Epoch 12/20\n",
      "236/236 - 0s - 1ms/step - loss: 107.3645 - mae: 7.1259\n",
      "Epoch 13/20\n",
      "236/236 - 0s - 2ms/step - loss: 106.9242 - mae: 7.0974\n",
      "Epoch 14/20\n",
      "236/236 - 0s - 1ms/step - loss: 106.3699 - mae: 7.0948\n",
      "Epoch 15/20\n",
      "236/236 - 0s - 1ms/step - loss: 105.9399 - mae: 7.0782\n",
      "Epoch 16/20\n",
      "236/236 - 0s - 1ms/step - loss: 105.4379 - mae: 7.0620\n",
      "Epoch 17/20\n",
      "236/236 - 0s - 1ms/step - loss: 105.4080 - mae: 7.0675\n",
      "Epoch 18/20\n",
      "236/236 - 0s - 1ms/step - loss: 104.9886 - mae: 7.0500\n",
      "Epoch 19/20\n",
      "236/236 - 0s - 2ms/step - loss: 104.6648 - mae: 7.0432\n",
      "Epoch 20/20\n",
      "236/236 - 0s - 1ms/step - loss: 104.3951 - mae: 7.0231\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 965us/step - loss: 99.7225 - mae: 6.8773\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step  \n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點64, epoch20, batch128 訓練集績效:\n",
      "MAE score: 6.962857723236084\n",
      "MAPE score: 25.747737288475037\n",
      "RMSE score: 10.14360465781773\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點64, epoch20, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.797476530075073\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "118/118 - 1s - 10ms/step - loss: 755.0831 - mae: 22.3342\n",
      "Epoch 2/20\n",
      "118/118 - 0s - 2ms/step - loss: 131.4122 - mae: 7.9383\n",
      "Epoch 3/20\n",
      "118/118 - 0s - 2ms/step - loss: 121.7388 - mae: 7.6584\n",
      "Epoch 4/20\n",
      "118/118 - 0s - 3ms/step - loss: 118.2588 - mae: 7.5247\n",
      "Epoch 5/20\n",
      "118/118 - 0s - 2ms/step - loss: 116.1819 - mae: 7.4441\n",
      "Epoch 6/20\n",
      "118/118 - 0s - 1ms/step - loss: 114.6443 - mae: 7.3747\n",
      "Epoch 7/20\n",
      "118/118 - 0s - 1ms/step - loss: 113.7306 - mae: 7.3298\n",
      "Epoch 8/20\n",
      "118/118 - 0s - 2ms/step - loss: 112.9941 - mae: 7.3051\n",
      "Epoch 9/20\n",
      "118/118 - 0s - 2ms/step - loss: 112.3334 - mae: 7.2894\n",
      "Epoch 10/20\n",
      "118/118 - 0s - 1ms/step - loss: 111.7629 - mae: 7.2640\n",
      "Epoch 11/20\n",
      "118/118 - 0s - 1ms/step - loss: 111.3777 - mae: 7.2419\n",
      "Epoch 12/20\n",
      "118/118 - 0s - 1ms/step - loss: 110.9761 - mae: 7.2249\n",
      "Epoch 13/20\n",
      "118/118 - 0s - 2ms/step - loss: 110.5911 - mae: 7.2169\n",
      "Epoch 14/20\n",
      "118/118 - 0s - 2ms/step - loss: 110.2652 - mae: 7.1992\n",
      "Epoch 15/20\n",
      "118/118 - 0s - 1ms/step - loss: 110.1111 - mae: 7.1913\n",
      "Epoch 16/20\n",
      "118/118 - 0s - 1ms/step - loss: 109.5976 - mae: 7.1740\n",
      "Epoch 17/20\n",
      "118/118 - 0s - 1ms/step - loss: 109.4013 - mae: 7.1713\n",
      "Epoch 18/20\n",
      "118/118 - 0s - 2ms/step - loss: 109.3781 - mae: 7.1760\n",
      "Epoch 19/20\n",
      "118/118 - 0s - 1ms/step - loss: 109.1113 - mae: 7.1493\n",
      "Epoch 20/20\n",
      "118/118 - 0s - 2ms/step - loss: 108.9492 - mae: 7.1537\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 966us/step - loss: 104.8492 - mae: 7.0934\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點64, epoch20, batch256 訓練集績效:\n",
      "MAE score: 7.176427364349365\n",
      "MAPE score: 26.888245344161987\n",
      "RMSE score: 10.400427853513182\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點64, epoch20, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 30.111393332481384\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "943/943 - 2s - 2ms/step - loss: 179.2020 - mae: 9.0258\n",
      "Epoch 2/5\n",
      "943/943 - 1s - 1ms/step - loss: 115.5261 - mae: 7.4500\n",
      "Epoch 3/5\n",
      "943/943 - 1s - 1ms/step - loss: 112.9308 - mae: 7.3453\n",
      "Epoch 4/5\n",
      "943/943 - 1s - 1ms/step - loss: 110.4195 - mae: 7.2467\n",
      "Epoch 5/5\n",
      "943/943 - 1s - 1ms/step - loss: 108.7539 - mae: 7.2235\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 102.5425 - mae: 7.0138\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點128, epoch5, batch32 訓練集績效:\n",
      "MAE score: 7.087594032287598\n",
      "MAPE score: 25.63776671886444\n",
      "RMSE score: 10.283868427255454\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點128, epoch5, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.350942373275757\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "472/472 - 2s - 3ms/step - loss: 239.2725 - mae: 10.4120\n",
      "Epoch 2/5\n",
      "472/472 - 1s - 1ms/step - loss: 116.3066 - mae: 7.4652\n",
      "Epoch 3/5\n",
      "472/472 - 1s - 1ms/step - loss: 113.9110 - mae: 7.3667\n",
      "Epoch 4/5\n",
      "472/472 - 1s - 1ms/step - loss: 112.4630 - mae: 7.3141\n",
      "Epoch 5/5\n",
      "472/472 - 1s - 1ms/step - loss: 110.4191 - mae: 7.2378\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 984us/step - loss: 104.8318 - mae: 7.1072\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點128, epoch5, batch64 訓練集績效:\n",
      "MAE score: 7.197141647338867\n",
      "MAPE score: 27.096331119537354\n",
      "RMSE score: 10.404792752344386\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點128, epoch5, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 30.219757556915283\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "236/236 - 1s - 5ms/step - loss: 345.8389 - mae: 12.8558\n",
      "Epoch 2/5\n",
      "236/236 - 0s - 1ms/step - loss: 118.6421 - mae: 7.5472\n",
      "Epoch 3/5\n",
      "236/236 - 0s - 1ms/step - loss: 114.9604 - mae: 7.3826\n",
      "Epoch 4/5\n",
      "236/236 - 0s - 1ms/step - loss: 113.1629 - mae: 7.3250\n",
      "Epoch 5/5\n",
      "236/236 - 0s - 1ms/step - loss: 111.8683 - mae: 7.2724\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 969us/step - loss: 106.8937 - mae: 7.1058\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點128, epoch5, batch128 訓練集績效:\n",
      "MAE score: 7.1921000480651855\n",
      "MAPE score: 27.52949893474579\n",
      "RMSE score: 10.500988868288266\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點128, epoch5, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 31.47982954978943\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "118/118 - 1s - 11ms/step - loss: 532.9597 - mae: 17.2174\n",
      "Epoch 2/5\n",
      "118/118 - 0s - 2ms/step - loss: 126.3979 - mae: 7.7711\n",
      "Epoch 3/5\n",
      "118/118 - 0s - 2ms/step - loss: 117.9483 - mae: 7.5184\n",
      "Epoch 4/5\n",
      "118/118 - 0s - 2ms/step - loss: 114.8056 - mae: 7.4066\n",
      "Epoch 5/5\n",
      "118/118 - 0s - 2ms/step - loss: 112.7875 - mae: 7.3049\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 972us/step - loss: 107.7371 - mae: 7.1886\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step  \n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點128, epoch5, batch256 訓練集績效:\n",
      "MAE score: 7.259960651397705\n",
      "MAPE score: 27.40527093410492\n",
      "RMSE score: 10.537172910200018\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點128, epoch5, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 30.765551328659058\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "943/943 - 2s - 2ms/step - loss: 181.1591 - mae: 9.0706\n",
      "Epoch 2/10\n",
      "943/943 - 1s - 1ms/step - loss: 115.4018 - mae: 7.4246\n",
      "Epoch 3/10\n",
      "943/943 - 1s - 1ms/step - loss: 112.4088 - mae: 7.3360\n",
      "Epoch 4/10\n",
      "943/943 - 1s - 1ms/step - loss: 110.6238 - mae: 7.2936\n",
      "Epoch 5/10\n",
      "943/943 - 1s - 1ms/step - loss: 109.3343 - mae: 7.2482\n",
      "Epoch 6/10\n",
      "943/943 - 1s - 1ms/step - loss: 108.3633 - mae: 7.1907\n",
      "Epoch 7/10\n",
      "943/943 - 1s - 1ms/step - loss: 107.2780 - mae: 7.1632\n",
      "Epoch 8/10\n",
      "943/943 - 1s - 1ms/step - loss: 106.6051 - mae: 7.1470\n",
      "Epoch 9/10\n",
      "943/943 - 1s - 1ms/step - loss: 105.5481 - mae: 7.1099\n",
      "Epoch 10/10\n",
      "943/943 - 1s - 1ms/step - loss: 105.3789 - mae: 7.1111\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 994us/step - loss: 100.4173 - mae: 6.8912\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點128, epoch10, batch32 訓練集績效:\n",
      "MAE score: 6.962782859802246\n",
      "MAPE score: 24.59862530231476\n",
      "RMSE score: 10.166634189574685\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點128, epoch10, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.267248511314392\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "472/472 - 1s - 3ms/step - loss: 226.3172 - mae: 10.0876\n",
      "Epoch 2/10\n",
      "472/472 - 1s - 1ms/step - loss: 115.4627 - mae: 7.4231\n",
      "Epoch 3/10\n",
      "472/472 - 1s - 1ms/step - loss: 113.4688 - mae: 7.3461\n",
      "Epoch 4/10\n",
      "472/472 - 1s - 1ms/step - loss: 111.3581 - mae: 7.2884\n",
      "Epoch 5/10\n",
      "472/472 - 1s - 1ms/step - loss: 109.8679 - mae: 7.2372\n",
      "Epoch 6/10\n",
      "472/472 - 1s - 1ms/step - loss: 108.9960 - mae: 7.2124\n",
      "Epoch 7/10\n",
      "472/472 - 1s - 1ms/step - loss: 107.3202 - mae: 7.1714\n",
      "Epoch 8/10\n",
      "472/472 - 1s - 1ms/step - loss: 107.2253 - mae: 7.1480\n",
      "Epoch 9/10\n",
      "472/472 - 1s - 1ms/step - loss: 106.2408 - mae: 7.1396\n",
      "Epoch 10/10\n",
      "472/472 - 1s - 1ms/step - loss: 105.3147 - mae: 7.1037\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 963us/step - loss: 102.3381 - mae: 7.0245\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點128, epoch10, batch64 訓練集績效:\n",
      "MAE score: 7.09232759475708\n",
      "MAPE score: 25.130698084831238\n",
      "RMSE score: 10.253815103761571\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 960us/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點128, epoch10, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.503411054611206\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "236/236 - 1s - 5ms/step - loss: 331.7849 - mae: 12.5874\n",
      "Epoch 2/10\n",
      "236/236 - 0s - 1ms/step - loss: 119.8096 - mae: 7.5031\n",
      "Epoch 3/10\n",
      "236/236 - 0s - 1ms/step - loss: 115.0568 - mae: 7.3825\n",
      "Epoch 4/10\n",
      "236/236 - 0s - 1ms/step - loss: 113.2090 - mae: 7.3239\n",
      "Epoch 5/10\n",
      "236/236 - 0s - 1ms/step - loss: 111.6042 - mae: 7.2673\n",
      "Epoch 6/10\n",
      "236/236 - 0s - 2ms/step - loss: 110.8294 - mae: 7.2457\n",
      "Epoch 7/10\n",
      "236/236 - 0s - 1ms/step - loss: 109.2841 - mae: 7.1894\n",
      "Epoch 8/10\n",
      "236/236 - 0s - 1ms/step - loss: 108.1505 - mae: 7.1525\n",
      "Epoch 9/10\n",
      "236/236 - 0s - 1ms/step - loss: 107.1064 - mae: 7.1252\n",
      "Epoch 10/10\n",
      "236/236 - 0s - 1ms/step - loss: 106.3434 - mae: 7.1021\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 978us/step - loss: 101.8640 - mae: 7.0629\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點128, epoch10, batch128 訓練集績效:\n",
      "MAE score: 7.148702144622803\n",
      "MAPE score: 26.7958402633667\n",
      "RMSE score: 10.25944493270218\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點128, epoch10, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 30.185553431510925\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "118/118 - 1s - 12ms/step - loss: 547.1964 - mae: 17.5289\n",
      "Epoch 2/10\n",
      "118/118 - 0s - 2ms/step - loss: 123.1264 - mae: 7.6745\n",
      "Epoch 3/10\n",
      "118/118 - 0s - 2ms/step - loss: 117.0964 - mae: 7.4840\n",
      "Epoch 4/10\n",
      "118/118 - 0s - 2ms/step - loss: 114.7950 - mae: 7.3818\n",
      "Epoch 5/10\n",
      "118/118 - 0s - 2ms/step - loss: 113.3660 - mae: 7.3318\n",
      "Epoch 6/10\n",
      "118/118 - 0s - 3ms/step - loss: 112.4987 - mae: 7.2694\n",
      "Epoch 7/10\n",
      "118/118 - 0s - 2ms/step - loss: 111.4629 - mae: 7.2510\n",
      "Epoch 8/10\n",
      "118/118 - 0s - 2ms/step - loss: 110.6198 - mae: 7.2095\n",
      "Epoch 9/10\n",
      "118/118 - 0s - 2ms/step - loss: 109.7608 - mae: 7.1828\n",
      "Epoch 10/10\n",
      "118/118 - 0s - 2ms/step - loss: 109.0443 - mae: 7.1648\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 942us/step - loss: 104.3287 - mae: 7.0125\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step  \n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點128, epoch10, batch256 訓練集績效:\n",
      "MAE score: 7.083693981170654\n",
      "MAPE score: 26.455870270729065\n",
      "RMSE score: 10.361026039717453\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點128, epoch10, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 30.73960542678833\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "943/943 - 2s - 2ms/step - loss: 188.4063 - mae: 9.1703\n",
      "Epoch 2/20\n",
      "943/943 - 1s - 1ms/step - loss: 115.3109 - mae: 7.4258\n",
      "Epoch 3/20\n",
      "943/943 - 1s - 1ms/step - loss: 112.7155 - mae: 7.3288\n",
      "Epoch 4/20\n",
      "943/943 - 1s - 1ms/step - loss: 110.5018 - mae: 7.2908\n",
      "Epoch 5/20\n",
      "943/943 - 1s - 1ms/step - loss: 108.6253 - mae: 7.2233\n",
      "Epoch 6/20\n",
      "943/943 - 1s - 1ms/step - loss: 107.5921 - mae: 7.1863\n",
      "Epoch 7/20\n",
      "943/943 - 1s - 1ms/step - loss: 106.3530 - mae: 7.1364\n",
      "Epoch 8/20\n",
      "943/943 - 1s - 1ms/step - loss: 105.9285 - mae: 7.1215\n",
      "Epoch 9/20\n",
      "943/943 - 1s - 1ms/step - loss: 105.2470 - mae: 7.0855\n",
      "Epoch 10/20\n",
      "943/943 - 1s - 1ms/step - loss: 104.8508 - mae: 7.0762\n",
      "Epoch 11/20\n",
      "943/943 - 1s - 1ms/step - loss: 104.5683 - mae: 7.0666\n",
      "Epoch 12/20\n",
      "943/943 - 1s - 1ms/step - loss: 103.6742 - mae: 7.0292\n",
      "Epoch 13/20\n",
      "943/943 - 1s - 1ms/step - loss: 103.3050 - mae: 7.0143\n",
      "Epoch 14/20\n",
      "943/943 - 1s - 1ms/step - loss: 102.9150 - mae: 6.9960\n",
      "Epoch 15/20\n",
      "943/943 - 1s - 2ms/step - loss: 102.4010 - mae: 6.9819\n",
      "Epoch 16/20\n",
      "943/943 - 1s - 1ms/step - loss: 101.9084 - mae: 6.9597\n",
      "Epoch 17/20\n",
      "943/943 - 1s - 1ms/step - loss: 101.7174 - mae: 6.9542\n",
      "Epoch 18/20\n",
      "943/943 - 1s - 1ms/step - loss: 100.8724 - mae: 6.9257\n",
      "Epoch 19/20\n",
      "943/943 - 1s - 1ms/step - loss: 100.6223 - mae: 6.9189\n",
      "Epoch 20/20\n",
      "943/943 - 1s - 1ms/step - loss: 100.0773 - mae: 6.9153\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 981us/step - loss: 94.9326 - mae: 6.7525\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step  \n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點128, epoch20, batch32 訓練集績效:\n",
      "MAE score: 6.80300235748291\n",
      "MAPE score: 23.949241638183594\n",
      "RMSE score: 9.878315043227854\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點128, epoch20, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.027009963989258\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "472/472 - 2s - 3ms/step - loss: 243.6209 - mae: 10.5206\n",
      "Epoch 2/20\n",
      "472/472 - 1s - 1ms/step - loss: 116.1624 - mae: 7.4482\n",
      "Epoch 3/20\n",
      "472/472 - 1s - 1ms/step - loss: 113.3123 - mae: 7.3356\n",
      "Epoch 4/20\n",
      "472/472 - 1s - 1ms/step - loss: 110.9986 - mae: 7.2628\n",
      "Epoch 5/20\n",
      "472/472 - 1s - 1ms/step - loss: 108.7226 - mae: 7.1936\n",
      "Epoch 6/20\n",
      "472/472 - 1s - 1ms/step - loss: 107.7685 - mae: 7.1727\n",
      "Epoch 7/20\n",
      "472/472 - 1s - 2ms/step - loss: 106.4984 - mae: 7.1501\n",
      "Epoch 8/20\n",
      "472/472 - 1s - 1ms/step - loss: 106.4743 - mae: 7.1347\n",
      "Epoch 9/20\n",
      "472/472 - 1s - 1ms/step - loss: 105.5179 - mae: 7.1145\n",
      "Epoch 10/20\n",
      "472/472 - 1s - 1ms/step - loss: 104.5753 - mae: 7.0618\n",
      "Epoch 11/20\n",
      "472/472 - 1s - 1ms/step - loss: 103.9545 - mae: 7.0414\n",
      "Epoch 12/20\n",
      "472/472 - 1s - 1ms/step - loss: 103.1858 - mae: 7.0321\n",
      "Epoch 13/20\n",
      "472/472 - 1s - 1ms/step - loss: 102.8778 - mae: 7.0183\n",
      "Epoch 14/20\n",
      "472/472 - 1s - 1ms/step - loss: 102.7315 - mae: 6.9875\n",
      "Epoch 15/20\n",
      "472/472 - 1s - 1ms/step - loss: 102.4537 - mae: 6.9893\n",
      "Epoch 16/20\n",
      "472/472 - 1s - 1ms/step - loss: 101.8428 - mae: 6.9810\n",
      "Epoch 17/20\n",
      "472/472 - 1s - 1ms/step - loss: 100.9893 - mae: 6.9408\n",
      "Epoch 18/20\n",
      "472/472 - 1s - 1ms/step - loss: 100.7321 - mae: 6.9450\n",
      "Epoch 19/20\n",
      "472/472 - 1s - 1ms/step - loss: 100.3827 - mae: 6.9199\n",
      "Epoch 20/20\n",
      "472/472 - 1s - 1ms/step - loss: 100.2242 - mae: 6.9191\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 988us/step - loss: 96.6467 - mae: 6.9729\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點128, epoch20, batch64 訓練集績效:\n",
      "MAE score: 7.019326686859131\n",
      "MAPE score: 25.728413462638855\n",
      "RMSE score: 9.945126084515675\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點128, epoch20, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.34548258781433\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "236/236 - 1s - 6ms/step - loss: 321.8276 - mae: 12.3726\n",
      "Epoch 2/20\n",
      "236/236 - 0s - 1ms/step - loss: 117.9616 - mae: 7.5207\n",
      "Epoch 3/20\n",
      "236/236 - 0s - 1ms/step - loss: 114.1901 - mae: 7.3680\n",
      "Epoch 4/20\n",
      "236/236 - 0s - 1ms/step - loss: 112.5298 - mae: 7.2979\n",
      "Epoch 5/20\n",
      "236/236 - 0s - 1ms/step - loss: 110.8082 - mae: 7.2430\n",
      "Epoch 6/20\n",
      "236/236 - 0s - 2ms/step - loss: 109.4172 - mae: 7.1946\n",
      "Epoch 7/20\n",
      "236/236 - 0s - 1ms/step - loss: 108.1075 - mae: 7.1524\n",
      "Epoch 8/20\n",
      "236/236 - 0s - 1ms/step - loss: 107.0998 - mae: 7.1201\n",
      "Epoch 9/20\n",
      "236/236 - 0s - 1ms/step - loss: 106.4625 - mae: 7.1067\n",
      "Epoch 10/20\n",
      "236/236 - 0s - 1ms/step - loss: 106.0414 - mae: 7.1059\n",
      "Epoch 11/20\n",
      "236/236 - 0s - 2ms/step - loss: 105.3265 - mae: 7.0846\n",
      "Epoch 12/20\n",
      "236/236 - 0s - 1ms/step - loss: 104.9014 - mae: 7.0612\n",
      "Epoch 13/20\n",
      "236/236 - 0s - 1ms/step - loss: 104.3991 - mae: 7.0529\n",
      "Epoch 14/20\n",
      "236/236 - 0s - 1ms/step - loss: 104.4598 - mae: 7.0620\n",
      "Epoch 15/20\n",
      "236/236 - 0s - 1ms/step - loss: 103.7878 - mae: 7.0402\n",
      "Epoch 16/20\n",
      "236/236 - 0s - 2ms/step - loss: 103.3037 - mae: 7.0232\n",
      "Epoch 17/20\n",
      "236/236 - 0s - 1ms/step - loss: 102.7854 - mae: 6.9905\n",
      "Epoch 18/20\n",
      "236/236 - 0s - 1ms/step - loss: 102.4323 - mae: 6.9790\n",
      "Epoch 19/20\n",
      "236/236 - 0s - 1ms/step - loss: 102.2130 - mae: 6.9773\n",
      "Epoch 20/20\n",
      "236/236 - 0s - 1ms/step - loss: 101.7524 - mae: 6.9541\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 928us/step - loss: 97.3632 - mae: 6.8807\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step  \n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點128, epoch20, batch128 訓練集績效:\n",
      "MAE score: 6.964567184448242\n",
      "MAPE score: 25.64721703529358\n",
      "RMSE score: 10.02410919721817\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點128, epoch20, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.39588725566864\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "118/118 - 1s - 10ms/step - loss: 527.7919 - mae: 17.0419\n",
      "Epoch 2/20\n",
      "118/118 - 0s - 2ms/step - loss: 124.8052 - mae: 7.7224\n",
      "Epoch 3/20\n",
      "118/118 - 0s - 2ms/step - loss: 117.5567 - mae: 7.5157\n",
      "Epoch 4/20\n",
      "118/118 - 0s - 3ms/step - loss: 114.8774 - mae: 7.4034\n",
      "Epoch 5/20\n",
      "118/118 - 0s - 2ms/step - loss: 113.3395 - mae: 7.3316\n",
      "Epoch 6/20\n",
      "118/118 - 0s - 2ms/step - loss: 112.3335 - mae: 7.2834\n",
      "Epoch 7/20\n",
      "118/118 - 0s - 2ms/step - loss: 111.3548 - mae: 7.2462\n",
      "Epoch 8/20\n",
      "118/118 - 0s - 2ms/step - loss: 110.5751 - mae: 7.2116\n",
      "Epoch 9/20\n",
      "118/118 - 0s - 2ms/step - loss: 109.8928 - mae: 7.1848\n",
      "Epoch 10/20\n",
      "118/118 - 0s - 2ms/step - loss: 109.1069 - mae: 7.1612\n",
      "Epoch 11/20\n",
      "118/118 - 0s - 2ms/step - loss: 108.1615 - mae: 7.1355\n",
      "Epoch 12/20\n",
      "118/118 - 0s - 2ms/step - loss: 107.5989 - mae: 7.1077\n",
      "Epoch 13/20\n",
      "118/118 - 0s - 2ms/step - loss: 106.9155 - mae: 7.0859\n",
      "Epoch 14/20\n",
      "118/118 - 0s - 3ms/step - loss: 106.4487 - mae: 7.0618\n",
      "Epoch 15/20\n",
      "118/118 - 0s - 2ms/step - loss: 105.8174 - mae: 7.0711\n",
      "Epoch 16/20\n",
      "118/118 - 0s - 2ms/step - loss: 105.4632 - mae: 7.0478\n",
      "Epoch 17/20\n",
      "118/118 - 0s - 2ms/step - loss: 105.0776 - mae: 7.0440\n",
      "Epoch 18/20\n",
      "118/118 - 0s - 2ms/step - loss: 104.6548 - mae: 7.0330\n",
      "Epoch 19/20\n",
      "118/118 - 0s - 3ms/step - loss: 104.3988 - mae: 7.0294\n",
      "Epoch 20/20\n",
      "118/118 - 0s - 2ms/step - loss: 103.9464 - mae: 7.0256\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 979us/step - loss: 99.4701 - mae: 6.8797\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點128, epoch20, batch256 訓練集績效:\n",
      "MAE score: 6.967438220977783\n",
      "MAPE score: 25.911349058151245\n",
      "RMSE score: 10.135960427439578\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點128, epoch20, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 30.28523325920105\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "943/943 - 2s - 3ms/step - loss: 162.3068 - mae: 8.6102\n",
      "Epoch 2/5\n",
      "943/943 - 1s - 2ms/step - loss: 115.6111 - mae: 7.4436\n",
      "Epoch 3/5\n",
      "943/943 - 1s - 1ms/step - loss: 112.9841 - mae: 7.3775\n",
      "Epoch 4/5\n",
      "943/943 - 1s - 1ms/step - loss: 110.7048 - mae: 7.2976\n",
      "Epoch 5/5\n",
      "943/943 - 1s - 1ms/step - loss: 109.3836 - mae: 7.2737\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 106.6165 - mae: 7.1895\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點256, epoch5, batch32 訓練集績效:\n",
      "MAE score: 7.2522664070129395\n",
      "MAPE score: 25.033852458000183\n",
      "RMSE score: 10.467559473466888\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點256, epoch5, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.266971349716187\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "472/472 - 2s - 4ms/step - loss: 200.9276 - mae: 9.4485\n",
      "Epoch 2/5\n",
      "472/472 - 1s - 2ms/step - loss: 115.4461 - mae: 7.4469\n",
      "Epoch 3/5\n",
      "472/472 - 1s - 2ms/step - loss: 112.5164 - mae: 7.3256\n",
      "Epoch 4/5\n",
      "472/472 - 1s - 2ms/step - loss: 110.7693 - mae: 7.2826\n",
      "Epoch 5/5\n",
      "472/472 - 1s - 2ms/step - loss: 108.7683 - mae: 7.2105\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 102.1383 - mae: 7.0084\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點256, epoch5, batch64 訓練集績效:\n",
      "MAE score: 7.09694766998291\n",
      "MAPE score: 26.304274797439575\n",
      "RMSE score: 10.276247981778555\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點256, epoch5, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.66170608997345\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "236/236 - 2s - 7ms/step - loss: 262.0401 - mae: 10.8867\n",
      "Epoch 2/5\n",
      "236/236 - 0s - 2ms/step - loss: 116.2198 - mae: 7.4764\n",
      "Epoch 3/5\n",
      "236/236 - 0s - 2ms/step - loss: 113.2391 - mae: 7.3391\n",
      "Epoch 4/5\n",
      "236/236 - 0s - 2ms/step - loss: 110.8486 - mae: 7.2433\n",
      "Epoch 5/5\n",
      "236/236 - 0s - 2ms/step - loss: 109.3641 - mae: 7.1974\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 103.1357 - mae: 6.9829\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點256, epoch5, batch128 訓練集績效:\n",
      "MAE score: 7.052067279815674\n",
      "MAPE score: 26.007530093193054\n",
      "RMSE score: 10.312517755666534\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點256, epoch5, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 30.02755641937256\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "118/118 - 1s - 10ms/step - loss: 410.0382 - mae: 14.2556\n",
      "Epoch 2/5\n",
      "118/118 - 0s - 3ms/step - loss: 123.4709 - mae: 7.5905\n",
      "Epoch 3/5\n",
      "118/118 - 0s - 2ms/step - loss: 115.4793 - mae: 7.3791\n",
      "Epoch 4/5\n",
      "118/118 - 0s - 3ms/step - loss: 113.0545 - mae: 7.3099\n",
      "Epoch 5/5\n",
      "118/118 - 0s - 2ms/step - loss: 111.2115 - mae: 7.2417\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 106.2252 - mae: 7.1047\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點256, epoch5, batch256 訓練集績效:\n",
      "MAE score: 7.18557596206665\n",
      "MAPE score: 26.908156275749207\n",
      "RMSE score: 10.462467141595468\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點256, epoch5, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 30.513480305671692\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "943/943 - 3s - 3ms/step - loss: 162.8515 - mae: 8.6229\n",
      "Epoch 2/10\n",
      "943/943 - 1s - 1ms/step - loss: 115.2290 - mae: 7.4277\n",
      "Epoch 3/10\n",
      "943/943 - 1s - 1ms/step - loss: 112.2318 - mae: 7.3547\n",
      "Epoch 4/10\n",
      "943/943 - 1s - 1ms/step - loss: 110.0577 - mae: 7.2933\n",
      "Epoch 5/10\n",
      "943/943 - 1s - 2ms/step - loss: 109.2237 - mae: 7.2663\n",
      "Epoch 6/10\n",
      "943/943 - 1s - 2ms/step - loss: 108.2138 - mae: 7.2264\n",
      "Epoch 7/10\n",
      "943/943 - 1s - 1ms/step - loss: 107.5437 - mae: 7.1975\n",
      "Epoch 8/10\n",
      "943/943 - 1s - 1ms/step - loss: 107.1099 - mae: 7.1897\n",
      "Epoch 9/10\n",
      "943/943 - 1s - 1ms/step - loss: 106.1373 - mae: 7.1291\n",
      "Epoch 10/10\n",
      "943/943 - 1s - 2ms/step - loss: 105.7884 - mae: 7.1440\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 100.5813 - mae: 6.8464\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點256, epoch10, batch32 訓練集績效:\n",
      "MAE score: 6.939159870147705\n",
      "MAPE score: 24.286068975925446\n",
      "RMSE score: 10.18737493332932\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點256, epoch10, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.533196449279785\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "472/472 - 2s - 4ms/step - loss: 201.3307 - mae: 9.4522\n",
      "Epoch 2/10\n",
      "472/472 - 1s - 2ms/step - loss: 115.2349 - mae: 7.4255\n",
      "Epoch 3/10\n",
      "472/472 - 1s - 2ms/step - loss: 112.6320 - mae: 7.3104\n",
      "Epoch 4/10\n",
      "472/472 - 1s - 2ms/step - loss: 110.0238 - mae: 7.2390\n",
      "Epoch 5/10\n",
      "472/472 - 1s - 2ms/step - loss: 109.1715 - mae: 7.2251\n",
      "Epoch 6/10\n",
      "472/472 - 1s - 2ms/step - loss: 107.9235 - mae: 7.1829\n",
      "Epoch 7/10\n",
      "472/472 - 1s - 2ms/step - loss: 107.3135 - mae: 7.1701\n",
      "Epoch 8/10\n",
      "472/472 - 1s - 2ms/step - loss: 106.5914 - mae: 7.1429\n",
      "Epoch 9/10\n",
      "472/472 - 1s - 2ms/step - loss: 105.6689 - mae: 7.1165\n",
      "Epoch 10/10\n",
      "472/472 - 1s - 2ms/step - loss: 104.9930 - mae: 7.1001\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 100.0214 - mae: 6.9910\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點256, epoch10, batch64 訓練集績效:\n",
      "MAE score: 7.0725932121276855\n",
      "MAPE score: 26.0715514421463\n",
      "RMSE score: 10.163736348413343\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點256, epoch10, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.202759265899658\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "236/236 - 2s - 6ms/step - loss: 269.6537 - mae: 11.0517\n",
      "Epoch 2/10\n",
      "236/236 - 0s - 2ms/step - loss: 116.4057 - mae: 7.4390\n",
      "Epoch 3/10\n",
      "236/236 - 0s - 2ms/step - loss: 113.1632 - mae: 7.3230\n",
      "Epoch 4/10\n",
      "236/236 - 0s - 2ms/step - loss: 111.4241 - mae: 7.2560\n",
      "Epoch 5/10\n",
      "236/236 - 0s - 2ms/step - loss: 109.7671 - mae: 7.2184\n",
      "Epoch 6/10\n",
      "236/236 - 1s - 2ms/step - loss: 107.6677 - mae: 7.1443\n",
      "Epoch 7/10\n",
      "236/236 - 0s - 2ms/step - loss: 106.4950 - mae: 7.1316\n",
      "Epoch 8/10\n",
      "236/236 - 0s - 2ms/step - loss: 105.9483 - mae: 7.1126\n",
      "Epoch 9/10\n",
      "236/236 - 0s - 2ms/step - loss: 105.4244 - mae: 7.1003\n",
      "Epoch 10/10\n",
      "236/236 - 0s - 2ms/step - loss: 104.5998 - mae: 7.0593\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 99.0385 - mae: 6.9206\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點256, epoch10, batch128 訓練集績效:\n",
      "MAE score: 6.990258693695068\n",
      "MAPE score: 25.78336000442505\n",
      "RMSE score: 10.104159535408781\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點256, epoch10, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.269951581954956\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "118/118 - 1s - 12ms/step - loss: 412.2604 - mae: 14.4153\n",
      "Epoch 2/10\n",
      "118/118 - 0s - 4ms/step - loss: 126.7081 - mae: 7.6380\n",
      "Epoch 3/10\n",
      "118/118 - 0s - 3ms/step - loss: 116.8990 - mae: 7.3963\n",
      "Epoch 4/10\n",
      "118/118 - 0s - 3ms/step - loss: 113.3876 - mae: 7.3067\n",
      "Epoch 5/10\n",
      "118/118 - 0s - 3ms/step - loss: 111.4557 - mae: 7.2428\n",
      "Epoch 6/10\n",
      "118/118 - 0s - 3ms/step - loss: 109.7554 - mae: 7.1957\n",
      "Epoch 7/10\n",
      "118/118 - 0s - 3ms/step - loss: 108.2078 - mae: 7.1449\n",
      "Epoch 8/10\n",
      "118/118 - 0s - 3ms/step - loss: 107.4093 - mae: 7.1318\n",
      "Epoch 9/10\n",
      "118/118 - 0s - 3ms/step - loss: 106.4340 - mae: 7.1055\n",
      "Epoch 10/10\n",
      "118/118 - 0s - 3ms/step - loss: 105.6683 - mae: 7.0860\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 100.4597 - mae: 6.9116\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點256, epoch10, batch256 訓練集績效:\n",
      "MAE score: 6.992161750793457\n",
      "MAPE score: 25.799766182899475\n",
      "RMSE score: 10.172763018073065\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點256, epoch10, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.562243819236755\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "943/943 - 3s - 3ms/step - loss: 160.8092 - mae: 8.5764\n",
      "Epoch 2/20\n",
      "943/943 - 1s - 1ms/step - loss: 116.1070 - mae: 7.4712\n",
      "Epoch 3/20\n",
      "943/943 - 1s - 1ms/step - loss: 112.5911 - mae: 7.3492\n",
      "Epoch 4/20\n",
      "943/943 - 1s - 1ms/step - loss: 111.1996 - mae: 7.3212\n",
      "Epoch 5/20\n",
      "943/943 - 1s - 2ms/step - loss: 109.8277 - mae: 7.2672\n",
      "Epoch 6/20\n",
      "943/943 - 1s - 1ms/step - loss: 108.6794 - mae: 7.2392\n",
      "Epoch 7/20\n",
      "943/943 - 1s - 1ms/step - loss: 107.2038 - mae: 7.1735\n",
      "Epoch 8/20\n",
      "943/943 - 1s - 1ms/step - loss: 106.7547 - mae: 7.1463\n",
      "Epoch 9/20\n",
      "943/943 - 1s - 1ms/step - loss: 106.4554 - mae: 7.1365\n",
      "Epoch 10/20\n",
      "943/943 - 1s - 2ms/step - loss: 105.6312 - mae: 7.1187\n",
      "Epoch 11/20\n",
      "943/943 - 1s - 1ms/step - loss: 104.9285 - mae: 7.0880\n",
      "Epoch 12/20\n",
      "943/943 - 1s - 1ms/step - loss: 104.5982 - mae: 7.0851\n",
      "Epoch 13/20\n",
      "943/943 - 1s - 1ms/step - loss: 104.0221 - mae: 7.0616\n",
      "Epoch 14/20\n",
      "943/943 - 1s - 1ms/step - loss: 103.4905 - mae: 7.0562\n",
      "Epoch 15/20\n",
      "943/943 - 1s - 2ms/step - loss: 103.0044 - mae: 7.0171\n",
      "Epoch 16/20\n",
      "943/943 - 1s - 1ms/step - loss: 102.6252 - mae: 7.0107\n",
      "Epoch 17/20\n",
      "943/943 - 1s - 1ms/step - loss: 102.3475 - mae: 6.9938\n",
      "Epoch 18/20\n",
      "943/943 - 1s - 1ms/step - loss: 101.9393 - mae: 6.9790\n",
      "Epoch 19/20\n",
      "943/943 - 1s - 1ms/step - loss: 100.9138 - mae: 6.9345\n",
      "Epoch 20/20\n",
      "943/943 - 1s - 2ms/step - loss: 100.3057 - mae: 6.9301\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 96.6480 - mae: 6.7040\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點256, epoch20, batch32 訓練集績效:\n",
      "MAE score: 6.765221118927002\n",
      "MAPE score: 23.7109512090683\n",
      "RMSE score: 9.957310920699642\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點256, epoch20, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 27.35360562801361\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "472/472 - 2s - 4ms/step - loss: 191.5854 - mae: 9.2662\n",
      "Epoch 2/20\n",
      "472/472 - 1s - 2ms/step - loss: 115.2787 - mae: 7.4257\n",
      "Epoch 3/20\n",
      "472/472 - 1s - 2ms/step - loss: 112.0411 - mae: 7.3015\n",
      "Epoch 4/20\n",
      "472/472 - 1s - 2ms/step - loss: 110.4202 - mae: 7.2809\n",
      "Epoch 5/20\n",
      "472/472 - 1s - 2ms/step - loss: 108.6255 - mae: 7.2219\n",
      "Epoch 6/20\n",
      "472/472 - 1s - 2ms/step - loss: 107.5709 - mae: 7.1788\n",
      "Epoch 7/20\n",
      "472/472 - 1s - 2ms/step - loss: 106.3064 - mae: 7.1452\n",
      "Epoch 8/20\n",
      "472/472 - 1s - 2ms/step - loss: 106.2870 - mae: 7.1520\n",
      "Epoch 9/20\n",
      "472/472 - 1s - 2ms/step - loss: 105.4803 - mae: 7.1051\n",
      "Epoch 10/20\n",
      "472/472 - 1s - 2ms/step - loss: 104.9338 - mae: 7.0917\n",
      "Epoch 11/20\n",
      "472/472 - 1s - 2ms/step - loss: 104.3466 - mae: 7.0599\n",
      "Epoch 12/20\n",
      "472/472 - 1s - 2ms/step - loss: 103.8575 - mae: 7.0492\n",
      "Epoch 13/20\n",
      "472/472 - 1s - 2ms/step - loss: 103.3119 - mae: 7.0258\n",
      "Epoch 14/20\n",
      "472/472 - 1s - 2ms/step - loss: 102.8187 - mae: 7.0105\n",
      "Epoch 15/20\n",
      "472/472 - 1s - 2ms/step - loss: 102.1919 - mae: 6.9943\n",
      "Epoch 16/20\n",
      "472/472 - 1s - 2ms/step - loss: 102.1540 - mae: 6.9908\n",
      "Epoch 17/20\n",
      "472/472 - 1s - 2ms/step - loss: 101.6078 - mae: 6.9677\n",
      "Epoch 18/20\n",
      "472/472 - 1s - 2ms/step - loss: 101.3003 - mae: 6.9493\n",
      "Epoch 19/20\n",
      "472/472 - 1s - 2ms/step - loss: 100.9092 - mae: 6.9254\n",
      "Epoch 20/20\n",
      "472/472 - 1s - 2ms/step - loss: 100.7330 - mae: 6.9190\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 95.6891 - mae: 6.8623\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點256, epoch20, batch64 訓練集績效:\n",
      "MAE score: 6.922616004943848\n",
      "MAPE score: 24.780629575252533\n",
      "RMSE score: 9.915363343661008\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點256, epoch20, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.495889902114868\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "236/236 - 2s - 7ms/step - loss: 272.3676 - mae: 11.1360\n",
      "Epoch 2/20\n",
      "236/236 - 0s - 2ms/step - loss: 119.3570 - mae: 7.4631\n",
      "Epoch 3/20\n",
      "236/236 - 0s - 2ms/step - loss: 112.9637 - mae: 7.3138\n",
      "Epoch 4/20\n",
      "236/236 - 0s - 2ms/step - loss: 111.2434 - mae: 7.2634\n",
      "Epoch 5/20\n",
      "236/236 - 0s - 2ms/step - loss: 109.2708 - mae: 7.2004\n",
      "Epoch 6/20\n",
      "236/236 - 1s - 2ms/step - loss: 107.9487 - mae: 7.1638\n",
      "Epoch 7/20\n",
      "236/236 - 0s - 2ms/step - loss: 107.1255 - mae: 7.1536\n",
      "Epoch 8/20\n",
      "236/236 - 0s - 2ms/step - loss: 106.4489 - mae: 7.1353\n",
      "Epoch 9/20\n",
      "236/236 - 0s - 2ms/step - loss: 105.6587 - mae: 7.0970\n",
      "Epoch 10/20\n",
      "236/236 - 1s - 2ms/step - loss: 105.3123 - mae: 7.0939\n",
      "Epoch 11/20\n",
      "236/236 - 0s - 2ms/step - loss: 104.5596 - mae: 7.0655\n",
      "Epoch 12/20\n",
      "236/236 - 0s - 2ms/step - loss: 104.5613 - mae: 7.0764\n",
      "Epoch 13/20\n",
      "236/236 - 0s - 2ms/step - loss: 103.6150 - mae: 7.0383\n",
      "Epoch 14/20\n",
      "236/236 - 1s - 2ms/step - loss: 103.2678 - mae: 7.0323\n",
      "Epoch 15/20\n",
      "236/236 - 0s - 2ms/step - loss: 102.7732 - mae: 7.0083\n",
      "Epoch 16/20\n",
      "236/236 - 0s - 2ms/step - loss: 102.4214 - mae: 6.9999\n",
      "Epoch 17/20\n",
      "236/236 - 0s - 2ms/step - loss: 101.9989 - mae: 6.9756\n",
      "Epoch 18/20\n",
      "236/236 - 1s - 2ms/step - loss: 101.4276 - mae: 6.9557\n",
      "Epoch 19/20\n",
      "236/236 - 0s - 2ms/step - loss: 101.0999 - mae: 6.9277\n",
      "Epoch 20/20\n",
      "236/236 - 0s - 2ms/step - loss: 100.8702 - mae: 6.9380\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 96.3569 - mae: 6.7457\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點256, epoch20, batch128 訓練集績效:\n",
      "MAE score: 6.813763618469238\n",
      "MAPE score: 24.194246530532837\n",
      "RMSE score: 9.953150678808123\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點256, epoch20, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.07421886920929\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "118/118 - 2s - 13ms/step - loss: 407.7509 - mae: 14.1606\n",
      "Epoch 2/20\n",
      "118/118 - 0s - 3ms/step - loss: 126.5605 - mae: 7.6549\n",
      "Epoch 3/20\n",
      "118/118 - 0s - 2ms/step - loss: 116.9304 - mae: 7.4111\n",
      "Epoch 4/20\n",
      "118/118 - 0s - 3ms/step - loss: 113.6247 - mae: 7.3257\n",
      "Epoch 5/20\n",
      "118/118 - 0s - 3ms/step - loss: 111.8716 - mae: 7.2620\n",
      "Epoch 6/20\n",
      "118/118 - 0s - 3ms/step - loss: 110.4687 - mae: 7.2170\n",
      "Epoch 7/20\n",
      "118/118 - 0s - 3ms/step - loss: 108.9609 - mae: 7.1671\n",
      "Epoch 8/20\n",
      "118/118 - 0s - 3ms/step - loss: 107.7642 - mae: 7.1379\n",
      "Epoch 9/20\n",
      "118/118 - 0s - 2ms/step - loss: 107.0168 - mae: 7.1153\n",
      "Epoch 10/20\n",
      "118/118 - 0s - 3ms/step - loss: 105.9816 - mae: 7.0943\n",
      "Epoch 11/20\n",
      "118/118 - 0s - 2ms/step - loss: 105.4832 - mae: 7.0842\n",
      "Epoch 12/20\n",
      "118/118 - 0s - 2ms/step - loss: 105.0965 - mae: 7.0945\n",
      "Epoch 13/20\n",
      "118/118 - 0s - 2ms/step - loss: 104.9804 - mae: 7.0968\n",
      "Epoch 14/20\n",
      "118/118 - 0s - 3ms/step - loss: 104.0253 - mae: 7.0435\n",
      "Epoch 15/20\n",
      "118/118 - 0s - 2ms/step - loss: 103.6492 - mae: 7.0310\n",
      "Epoch 16/20\n",
      "118/118 - 0s - 3ms/step - loss: 103.3976 - mae: 7.0182\n",
      "Epoch 17/20\n",
      "118/118 - 0s - 2ms/step - loss: 102.9196 - mae: 7.0055\n",
      "Epoch 18/20\n",
      "118/118 - 0s - 3ms/step - loss: 103.0301 - mae: 7.0178\n",
      "Epoch 19/20\n",
      "118/118 - 1s - 5ms/step - loss: 102.5370 - mae: 7.0052\n",
      "Epoch 20/20\n",
      "118/118 - 0s - 3ms/step - loss: 102.1198 - mae: 6.9713\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 97.0805 - mae: 6.8349\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點256, epoch20, batch256 訓練集績效:\n",
      "MAE score: 6.914530277252197\n",
      "MAPE score: 25.120827555656433\n",
      "RMSE score: 10.012788606025062\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點256, epoch20, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.227861762046814\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "943/943 - 4s - 4ms/step - loss: 146.3247 - mae: 8.3114\n",
      "Epoch 2/5\n",
      "943/943 - 3s - 3ms/step - loss: 116.8236 - mae: 7.5221\n",
      "Epoch 3/5\n",
      "943/943 - 3s - 3ms/step - loss: 113.3643 - mae: 7.4195\n",
      "Epoch 4/5\n",
      "943/943 - 3s - 3ms/step - loss: 111.7618 - mae: 7.3731\n",
      "Epoch 5/5\n",
      "943/943 - 3s - 3ms/step - loss: 110.0383 - mae: 7.3119\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 109.0465 - mae: 7.3213\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點512, epoch5, batch32 訓練集績效:\n",
      "MAE score: 7.388790130615234\n",
      "MAPE score: 25.04643201828003\n",
      "RMSE score: 10.583961848621996\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點512, epoch5, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.229119420051575\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "472/472 - 3s - 7ms/step - loss: 168.9698 - mae: 8.7492\n",
      "Epoch 2/5\n",
      "472/472 - 2s - 4ms/step - loss: 115.0130 - mae: 7.4322\n",
      "Epoch 3/5\n",
      "472/472 - 3s - 5ms/step - loss: 112.0387 - mae: 7.3389\n",
      "Epoch 4/5\n",
      "472/472 - 2s - 4ms/step - loss: 110.1728 - mae: 7.2781\n",
      "Epoch 5/5\n",
      "472/472 - 2s - 4ms/step - loss: 109.1389 - mae: 7.2716\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 104.6551 - mae: 7.2462\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點512, epoch5, batch64 訓練集績效:\n",
      "MAE score: 7.324461936950684\n",
      "MAPE score: 25.750231742858887\n",
      "RMSE score: 10.385631583287992\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點512, epoch5, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.780974984169006\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "236/236 - 2s - 10ms/step - loss: 213.5075 - mae: 9.7809\n",
      "Epoch 2/5\n",
      "236/236 - 1s - 5ms/step - loss: 115.0446 - mae: 7.3941\n",
      "Epoch 3/5\n",
      "236/236 - 1s - 4ms/step - loss: 111.6208 - mae: 7.2846\n",
      "Epoch 4/5\n",
      "236/236 - 1s - 4ms/step - loss: 109.8253 - mae: 7.2366\n",
      "Epoch 5/5\n",
      "236/236 - 1s - 5ms/step - loss: 108.1719 - mae: 7.2044\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 103.8337 - mae: 7.0512\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點512, epoch5, batch128 訓練集績效:\n",
      "MAE score: 7.123043060302734\n",
      "MAPE score: 25.415977835655212\n",
      "RMSE score: 10.35058699707809\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點512, epoch5, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 30.050697922706604\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "118/118 - 2s - 17ms/step - loss: 307.5093 - mae: 11.8579\n",
      "Epoch 2/5\n",
      "118/118 - 1s - 6ms/step - loss: 116.8963 - mae: 7.4742\n",
      "Epoch 3/5\n",
      "118/118 - 1s - 6ms/step - loss: 113.2632 - mae: 7.3196\n",
      "Epoch 4/5\n",
      "118/118 - 1s - 6ms/step - loss: 111.3490 - mae: 7.2466\n",
      "Epoch 5/5\n",
      "118/118 - 1s - 7ms/step - loss: 109.8390 - mae: 7.2076\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 107.8174 - mae: 7.3658\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點512, epoch5, batch256 訓練集績效:\n",
      "MAE score: 7.462074279785156\n",
      "MAPE score: 28.652730584144592\n",
      "RMSE score: 10.554289566772239\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點512, epoch5, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 31.279179453849792\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "943/943 - 4s - 4ms/step - loss: 150.0421 - mae: 8.3229\n",
      "Epoch 2/10\n",
      "943/943 - 3s - 3ms/step - loss: 115.7892 - mae: 7.4733\n",
      "Epoch 3/10\n",
      "943/943 - 3s - 3ms/step - loss: 113.2825 - mae: 7.4079\n",
      "Epoch 4/10\n",
      "943/943 - 3s - 3ms/step - loss: 110.9247 - mae: 7.3382\n",
      "Epoch 5/10\n",
      "943/943 - 3s - 3ms/step - loss: 109.9165 - mae: 7.2996\n",
      "Epoch 6/10\n",
      "943/943 - 3s - 3ms/step - loss: 108.5435 - mae: 7.2324\n",
      "Epoch 7/10\n",
      "943/943 - 3s - 3ms/step - loss: 107.5017 - mae: 7.2077\n",
      "Epoch 8/10\n",
      "943/943 - 3s - 3ms/step - loss: 106.8383 - mae: 7.1846\n",
      "Epoch 9/10\n",
      "943/943 - 3s - 3ms/step - loss: 106.6574 - mae: 7.1785\n",
      "Epoch 10/10\n",
      "943/943 - 3s - 3ms/step - loss: 106.1503 - mae: 7.1447\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 100.9029 - mae: 7.0196\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點512, epoch10, batch32 訓練集績效:\n",
      "MAE score: 7.09377908706665\n",
      "MAPE score: 25.069046020507812\n",
      "RMSE score: 10.183952977817333\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點512, epoch10, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.01916003227234\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "472/472 - 3s - 6ms/step - loss: 171.1251 - mae: 8.7696\n",
      "Epoch 2/10\n",
      "472/472 - 2s - 4ms/step - loss: 115.2674 - mae: 7.4540\n",
      "Epoch 3/10\n",
      "472/472 - 2s - 4ms/step - loss: 111.8762 - mae: 7.3467\n",
      "Epoch 4/10\n",
      "472/472 - 2s - 3ms/step - loss: 109.9860 - mae: 7.2782\n",
      "Epoch 5/10\n",
      "472/472 - 2s - 3ms/step - loss: 109.2822 - mae: 7.2751\n",
      "Epoch 6/10\n",
      "472/472 - 2s - 3ms/step - loss: 108.4233 - mae: 7.2435\n",
      "Epoch 7/10\n",
      "472/472 - 2s - 4ms/step - loss: 107.1964 - mae: 7.1929\n",
      "Epoch 8/10\n",
      "472/472 - 2s - 3ms/step - loss: 106.1989 - mae: 7.1658\n",
      "Epoch 9/10\n",
      "472/472 - 2s - 4ms/step - loss: 105.7876 - mae: 7.1500\n",
      "Epoch 10/10\n",
      "472/472 - 2s - 4ms/step - loss: 105.0560 - mae: 7.1139\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 98.7778 - mae: 6.8682\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點512, epoch10, batch64 訓練集績效:\n",
      "MAE score: 6.935197353363037\n",
      "MAPE score: 25.2066433429718\n",
      "RMSE score: 10.07351744844767\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點512, epoch10, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.057204723358154\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "236/236 - 2s - 10ms/step - loss: 219.1949 - mae: 9.8724\n",
      "Epoch 2/10\n",
      "236/236 - 1s - 4ms/step - loss: 119.3830 - mae: 7.4259\n",
      "Epoch 3/10\n",
      "236/236 - 1s - 4ms/step - loss: 111.4482 - mae: 7.2757\n",
      "Epoch 4/10\n",
      "236/236 - 1s - 4ms/step - loss: 109.8650 - mae: 7.2397\n",
      "Epoch 5/10\n",
      "236/236 - 1s - 4ms/step - loss: 107.9465 - mae: 7.1943\n",
      "Epoch 6/10\n",
      "236/236 - 1s - 5ms/step - loss: 106.9886 - mae: 7.1502\n",
      "Epoch 7/10\n",
      "236/236 - 1s - 4ms/step - loss: 106.4062 - mae: 7.1509\n",
      "Epoch 8/10\n",
      "236/236 - 1s - 4ms/step - loss: 105.5665 - mae: 7.1281\n",
      "Epoch 9/10\n",
      "236/236 - 1s - 4ms/step - loss: 105.8380 - mae: 7.1399\n",
      "Epoch 10/10\n",
      "236/236 - 1s - 5ms/step - loss: 104.3356 - mae: 7.0711\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 100.6292 - mae: 6.9157\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點512, epoch10, batch128 訓練集績效:\n",
      "MAE score: 6.990810871124268\n",
      "MAPE score: 24.846187233924866\n",
      "RMSE score: 10.188416609454706\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點512, epoch10, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.814542293548584\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "118/118 - 2s - 17ms/step - loss: 308.7587 - mae: 11.8486\n",
      "Epoch 2/10\n",
      "118/118 - 1s - 6ms/step - loss: 116.7877 - mae: 7.4641\n",
      "Epoch 3/10\n",
      "118/118 - 1s - 7ms/step - loss: 113.0799 - mae: 7.3170\n",
      "Epoch 4/10\n",
      "118/118 - 1s - 6ms/step - loss: 110.8995 - mae: 7.2248\n",
      "Epoch 5/10\n",
      "118/118 - 1s - 5ms/step - loss: 109.5809 - mae: 7.2049\n",
      "Epoch 6/10\n",
      "118/118 - 1s - 6ms/step - loss: 107.9155 - mae: 7.1570\n",
      "Epoch 7/10\n",
      "118/118 - 1s - 7ms/step - loss: 106.5514 - mae: 7.1317\n",
      "Epoch 8/10\n",
      "118/118 - 1s - 6ms/step - loss: 105.9520 - mae: 7.0965\n",
      "Epoch 9/10\n",
      "118/118 - 1s - 6ms/step - loss: 105.4202 - mae: 7.0983\n",
      "Epoch 10/10\n",
      "118/118 - 1s - 6ms/step - loss: 104.8880 - mae: 7.0737\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 99.8397 - mae: 6.9141\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點512, epoch10, batch256 訓練集績效:\n",
      "MAE score: 7.0019426345825195\n",
      "MAPE score: 25.576677918434143\n",
      "RMSE score: 10.156598176123266\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點512, epoch10, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.533538222312927\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "943/943 - 4s - 5ms/step - loss: 146.7533 - mae: 8.2643\n",
      "Epoch 2/20\n",
      "943/943 - 3s - 3ms/step - loss: 116.3932 - mae: 7.5076\n",
      "Epoch 3/20\n",
      "943/943 - 3s - 3ms/step - loss: 112.9557 - mae: 7.4158\n",
      "Epoch 4/20\n",
      "943/943 - 3s - 3ms/step - loss: 111.0851 - mae: 7.3483\n",
      "Epoch 5/20\n",
      "943/943 - 3s - 3ms/step - loss: 109.6463 - mae: 7.2820\n",
      "Epoch 6/20\n",
      "943/943 - 3s - 3ms/step - loss: 108.4251 - mae: 7.2394\n",
      "Epoch 7/20\n",
      "943/943 - 3s - 3ms/step - loss: 107.9543 - mae: 7.2399\n",
      "Epoch 8/20\n",
      "943/943 - 3s - 3ms/step - loss: 106.8476 - mae: 7.1778\n",
      "Epoch 9/20\n",
      "943/943 - 3s - 3ms/step - loss: 106.6176 - mae: 7.1728\n",
      "Epoch 10/20\n",
      "943/943 - 3s - 3ms/step - loss: 106.2837 - mae: 7.1805\n",
      "Epoch 11/20\n",
      "943/943 - 5s - 5ms/step - loss: 105.0807 - mae: 7.1166\n",
      "Epoch 12/20\n",
      "943/943 - 3s - 3ms/step - loss: 104.6162 - mae: 7.1015\n",
      "Epoch 13/20\n",
      "943/943 - 3s - 3ms/step - loss: 104.4879 - mae: 7.0986\n",
      "Epoch 14/20\n",
      "943/943 - 3s - 3ms/step - loss: 103.9847 - mae: 7.0910\n",
      "Epoch 15/20\n",
      "943/943 - 3s - 3ms/step - loss: 103.6534 - mae: 7.0729\n",
      "Epoch 16/20\n",
      "943/943 - 3s - 3ms/step - loss: 102.9317 - mae: 7.0346\n",
      "Epoch 17/20\n",
      "943/943 - 3s - 3ms/step - loss: 102.3145 - mae: 7.0128\n",
      "Epoch 18/20\n",
      "943/943 - 3s - 3ms/step - loss: 102.2000 - mae: 7.0134\n",
      "Epoch 19/20\n",
      "943/943 - 5s - 5ms/step - loss: 101.5820 - mae: 6.9987\n",
      "Epoch 20/20\n",
      "943/943 - 3s - 3ms/step - loss: 101.1872 - mae: 6.9902\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 94.6738 - mae: 6.8222\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點512, epoch20, batch32 訓練集績效:\n",
      "MAE score: 6.89227294921875\n",
      "MAPE score: 24.63168352842331\n",
      "RMSE score: 9.881730502158272\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點512, epoch20, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 27.271482348442078\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "472/472 - 3s - 7ms/step - loss: 169.5081 - mae: 8.7453\n",
      "Epoch 2/20\n",
      "472/472 - 2s - 3ms/step - loss: 115.0731 - mae: 7.4168\n",
      "Epoch 3/20\n",
      "472/472 - 2s - 4ms/step - loss: 111.8508 - mae: 7.3339\n",
      "Epoch 4/20\n",
      "472/472 - 2s - 3ms/step - loss: 109.7837 - mae: 7.2848\n",
      "Epoch 5/20\n",
      "472/472 - 2s - 4ms/step - loss: 108.7242 - mae: 7.2601\n",
      "Epoch 6/20\n",
      "472/472 - 2s - 3ms/step - loss: 108.5789 - mae: 7.2603\n",
      "Epoch 7/20\n",
      "472/472 - 2s - 3ms/step - loss: 107.1123 - mae: 7.1948\n",
      "Epoch 8/20\n",
      "472/472 - 2s - 3ms/step - loss: 106.0337 - mae: 7.1712\n",
      "Epoch 9/20\n",
      "472/472 - 2s - 4ms/step - loss: 106.2194 - mae: 7.1756\n",
      "Epoch 10/20\n",
      "472/472 - 2s - 3ms/step - loss: 105.6340 - mae: 7.1618\n",
      "Epoch 11/20\n",
      "472/472 - 2s - 3ms/step - loss: 104.4030 - mae: 7.1025\n",
      "Epoch 12/20\n",
      "472/472 - 2s - 3ms/step - loss: 104.1666 - mae: 7.1126\n",
      "Epoch 13/20\n",
      "472/472 - 2s - 4ms/step - loss: 103.3216 - mae: 7.0417\n",
      "Epoch 14/20\n",
      "472/472 - 2s - 3ms/step - loss: 102.9984 - mae: 7.0408\n",
      "Epoch 15/20\n",
      "472/472 - 2s - 4ms/step - loss: 102.7341 - mae: 7.0276\n",
      "Epoch 16/20\n",
      "472/472 - 2s - 4ms/step - loss: 102.4947 - mae: 7.0257\n",
      "Epoch 17/20\n",
      "472/472 - 2s - 4ms/step - loss: 102.0543 - mae: 7.0215\n",
      "Epoch 18/20\n",
      "472/472 - 2s - 4ms/step - loss: 101.3766 - mae: 6.9862\n",
      "Epoch 19/20\n",
      "472/472 - 2s - 3ms/step - loss: 101.2946 - mae: 6.9771\n",
      "Epoch 20/20\n",
      "472/472 - 2s - 3ms/step - loss: 101.2995 - mae: 6.9875\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 95.6416 - mae: 6.7674\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點512, epoch20, batch64 訓練集績效:\n",
      "MAE score: 6.831228733062744\n",
      "MAPE score: 24.766400456428528\n",
      "RMSE score: 9.914082893128159\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點512, epoch20, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 27.994099259376526\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "236/236 - 2s - 10ms/step - loss: 220.8180 - mae: 9.8131\n",
      "Epoch 2/20\n",
      "236/236 - 1s - 5ms/step - loss: 115.7614 - mae: 7.4058\n",
      "Epoch 3/20\n",
      "236/236 - 1s - 4ms/step - loss: 112.4737 - mae: 7.3205\n",
      "Epoch 4/20\n",
      "236/236 - 1s - 4ms/step - loss: 110.3070 - mae: 7.2555\n",
      "Epoch 5/20\n",
      "236/236 - 1s - 4ms/step - loss: 108.5576 - mae: 7.2064\n",
      "Epoch 6/20\n",
      "236/236 - 1s - 4ms/step - loss: 107.7491 - mae: 7.2040\n",
      "Epoch 7/20\n",
      "236/236 - 1s - 5ms/step - loss: 107.0353 - mae: 7.1719\n",
      "Epoch 8/20\n",
      "236/236 - 1s - 4ms/step - loss: 105.7097 - mae: 7.1234\n",
      "Epoch 9/20\n",
      "236/236 - 1s - 4ms/step - loss: 105.5527 - mae: 7.1111\n",
      "Epoch 10/20\n",
      "236/236 - 1s - 4ms/step - loss: 104.9296 - mae: 7.0948\n",
      "Epoch 11/20\n",
      "236/236 - 1s - 5ms/step - loss: 104.5430 - mae: 7.0814\n",
      "Epoch 12/20\n",
      "236/236 - 1s - 4ms/step - loss: 104.2291 - mae: 7.0673\n",
      "Epoch 13/20\n",
      "236/236 - 1s - 4ms/step - loss: 104.4340 - mae: 7.0882\n",
      "Epoch 14/20\n",
      "236/236 - 1s - 4ms/step - loss: 103.3381 - mae: 7.0487\n",
      "Epoch 15/20\n",
      "236/236 - 1s - 5ms/step - loss: 103.0528 - mae: 7.0456\n",
      "Epoch 16/20\n",
      "236/236 - 1s - 4ms/step - loss: 103.0866 - mae: 7.0401\n",
      "Epoch 17/20\n",
      "236/236 - 1s - 5ms/step - loss: 102.5416 - mae: 7.0213\n",
      "Epoch 18/20\n",
      "236/236 - 1s - 4ms/step - loss: 102.6747 - mae: 7.0474\n",
      "Epoch 19/20\n",
      "236/236 - 1s - 5ms/step - loss: 102.6275 - mae: 7.0376\n",
      "Epoch 20/20\n",
      "236/236 - 1s - 5ms/step - loss: 101.3821 - mae: 6.9944\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 97.6155 - mae: 6.8665\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點512, epoch20, batch128 訓練集績效:\n",
      "MAE score: 6.938877105712891\n",
      "MAPE score: 25.2072274684906\n",
      "RMSE score: 10.03636310072283\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點512, epoch20, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.203692078590393\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "118/118 - 2s - 16ms/step - loss: 293.7829 - mae: 11.6343\n",
      "Epoch 2/20\n",
      "118/118 - 1s - 6ms/step - loss: 119.6395 - mae: 7.5000\n",
      "Epoch 3/20\n",
      "118/118 - 1s - 6ms/step - loss: 112.9614 - mae: 7.3207\n",
      "Epoch 4/20\n",
      "118/118 - 1s - 7ms/step - loss: 110.7112 - mae: 7.2406\n",
      "Epoch 5/20\n",
      "118/118 - 1s - 6ms/step - loss: 108.8328 - mae: 7.1777\n",
      "Epoch 6/20\n",
      "118/118 - 1s - 6ms/step - loss: 107.5928 - mae: 7.1533\n",
      "Epoch 7/20\n",
      "118/118 - 1s - 6ms/step - loss: 106.6712 - mae: 7.1461\n",
      "Epoch 8/20\n",
      "118/118 - 1s - 7ms/step - loss: 105.5450 - mae: 7.0983\n",
      "Epoch 9/20\n",
      "118/118 - 1s - 6ms/step - loss: 104.9611 - mae: 7.0866\n",
      "Epoch 10/20\n",
      "118/118 - 1s - 6ms/step - loss: 104.2532 - mae: 7.0770\n",
      "Epoch 11/20\n",
      "118/118 - 1s - 6ms/step - loss: 103.7135 - mae: 7.0362\n",
      "Epoch 12/20\n",
      "118/118 - 1s - 7ms/step - loss: 103.4767 - mae: 7.0377\n",
      "Epoch 13/20\n",
      "118/118 - 1s - 6ms/step - loss: 103.1714 - mae: 7.0400\n",
      "Epoch 14/20\n",
      "118/118 - 1s - 6ms/step - loss: 103.1435 - mae: 7.0440\n",
      "Epoch 15/20\n",
      "118/118 - 1s - 6ms/step - loss: 102.3216 - mae: 7.0079\n",
      "Epoch 16/20\n",
      "118/118 - 1s - 7ms/step - loss: 102.1471 - mae: 7.0038\n",
      "Epoch 17/20\n",
      "118/118 - 1s - 6ms/step - loss: 101.7455 - mae: 6.9803\n",
      "Epoch 18/20\n",
      "118/118 - 1s - 6ms/step - loss: 101.6031 - mae: 6.9849\n",
      "Epoch 19/20\n",
      "118/118 - 1s - 6ms/step - loss: 102.3449 - mae: 7.0158\n",
      "Epoch 20/20\n",
      "118/118 - 1s - 7ms/step - loss: 101.5683 - mae: 6.9987\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 96.2191 - mae: 6.8384\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點512, epoch20, batch256 訓練集績效:\n",
      "MAE score: 6.9034953117370605\n",
      "MAPE score: 24.993896484375\n",
      "RMSE score: 9.949273195031635\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點512, epoch20, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.12605106830597\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "943/943 - 14s - 15ms/step - loss: 139.3058 - mae: 8.1864\n",
      "Epoch 2/5\n",
      "943/943 - 12s - 13ms/step - loss: 116.7356 - mae: 7.5537\n",
      "Epoch 3/5\n",
      "943/943 - 12s - 13ms/step - loss: 112.9736 - mae: 7.4078\n",
      "Epoch 4/5\n",
      "943/943 - 12s - 13ms/step - loss: 111.6263 - mae: 7.3911\n",
      "Epoch 5/5\n",
      "943/943 - 12s - 13ms/step - loss: 110.4904 - mae: 7.3325\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 102.1538 - mae: 6.9840\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點1024, epoch5, batch32 訓練集績效:\n",
      "MAE score: 7.064391136169434\n",
      "MAPE score: 25.592777132987976\n",
      "RMSE score: 10.272213939138231\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點1024, epoch5, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.078395128250122\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "472/472 - 8s - 18ms/step - loss: 168.4272 - mae: 8.3681\n",
      "Epoch 2/5\n",
      "472/472 - 7s - 14ms/step - loss: 116.3844 - mae: 7.4749\n",
      "Epoch 3/5\n",
      "472/472 - 7s - 14ms/step - loss: 113.0314 - mae: 7.4028\n",
      "Epoch 4/5\n",
      "472/472 - 7s - 15ms/step - loss: 110.1822 - mae: 7.3154\n",
      "Epoch 5/5\n",
      "472/472 - 7s - 15ms/step - loss: 109.4285 - mae: 7.2903\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 102.1144 - mae: 7.0851\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點1024, epoch5, batch64 訓練集績效:\n",
      "MAE score: 7.14689826965332\n",
      "MAPE score: 25.949591398239136\n",
      "RMSE score: 10.228700418716905\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點1024, epoch5, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.3123722076416\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "236/236 - 6s - 25ms/step - loss: 190.3852 - mae: 9.0282\n",
      "Epoch 2/5\n",
      "236/236 - 4s - 17ms/step - loss: 115.4280 - mae: 7.3910\n",
      "Epoch 3/5\n",
      "236/236 - 4s - 16ms/step - loss: 111.9862 - mae: 7.3411\n",
      "Epoch 4/5\n",
      "236/236 - 4s - 17ms/step - loss: 110.0758 - mae: 7.2672\n",
      "Epoch 5/5\n",
      "236/236 - 4s - 17ms/step - loss: 108.5066 - mae: 7.2353\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 102.9629 - mae: 7.0250\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點1024, epoch5, batch128 訓練集績效:\n",
      "MAE score: 7.093662261962891\n",
      "MAPE score: 25.20679235458374\n",
      "RMSE score: 10.291629271239838\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點1024, epoch5, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.191800951957703\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "118/118 - 4s - 34ms/step - loss: 238.8088 - mae: 10.2130\n",
      "Epoch 2/5\n",
      "118/118 - 2s - 20ms/step - loss: 114.5740 - mae: 7.3830\n",
      "Epoch 3/5\n",
      "118/118 - 2s - 20ms/step - loss: 111.6165 - mae: 7.2836\n",
      "Epoch 4/5\n",
      "118/118 - 3s - 22ms/step - loss: 108.8548 - mae: 7.1910\n",
      "Epoch 5/5\n",
      "118/118 - 2s - 20ms/step - loss: 108.2060 - mae: 7.1964\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 101.1624 - mae: 7.0111\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點1024, epoch5, batch256 訓練集績效:\n",
      "MAE score: 7.100759506225586\n",
      "MAPE score: 26.057660579681396\n",
      "RMSE score: 10.220245718493597\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點1024, epoch5, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.716280102729797\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "943/943 - 15s - 15ms/step - loss: 139.2858 - mae: 8.1516\n",
      "Epoch 2/10\n",
      "943/943 - 12s - 13ms/step - loss: 117.4568 - mae: 7.5875\n",
      "Epoch 3/10\n",
      "943/943 - 12s - 13ms/step - loss: 114.2666 - mae: 7.4728\n",
      "Epoch 4/10\n",
      "943/943 - 13s - 13ms/step - loss: 111.3821 - mae: 7.3616\n",
      "Epoch 5/10\n",
      "943/943 - 12s - 13ms/step - loss: 111.0667 - mae: 7.3801\n",
      "Epoch 6/10\n",
      "943/943 - 12s - 13ms/step - loss: 108.3533 - mae: 7.2512\n",
      "Epoch 7/10\n",
      "943/943 - 12s - 13ms/step - loss: 108.2698 - mae: 7.2605\n",
      "Epoch 8/10\n",
      "943/943 - 12s - 13ms/step - loss: 107.0384 - mae: 7.2018\n",
      "Epoch 9/10\n",
      "943/943 - 14s - 15ms/step - loss: 106.7357 - mae: 7.1787\n",
      "Epoch 10/10\n",
      "943/943 - 14s - 15ms/step - loss: 105.8105 - mae: 7.1544\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 101.1970 - mae: 7.2042\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點1024, epoch10, batch32 訓練集績效:\n",
      "MAE score: 7.273427486419678\n",
      "MAPE score: 25.970596075057983\n",
      "RMSE score: 10.200581208667911\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點1024, epoch10, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.139492869377136\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "472/472 - 9s - 19ms/step - loss: 153.0744 - mae: 8.4347\n",
      "Epoch 2/10\n",
      "472/472 - 7s - 14ms/step - loss: 115.8168 - mae: 7.4878\n",
      "Epoch 3/10\n",
      "472/472 - 7s - 14ms/step - loss: 112.7328 - mae: 7.3866\n",
      "Epoch 4/10\n",
      "472/472 - 7s - 14ms/step - loss: 111.0644 - mae: 7.3567\n",
      "Epoch 5/10\n",
      "472/472 - 7s - 15ms/step - loss: 109.7662 - mae: 7.2876\n",
      "Epoch 6/10\n",
      "472/472 - 7s - 14ms/step - loss: 108.7311 - mae: 7.2534\n",
      "Epoch 7/10\n",
      "472/472 - 7s - 14ms/step - loss: 108.0228 - mae: 7.2414\n",
      "Epoch 8/10\n",
      "472/472 - 7s - 14ms/step - loss: 106.5811 - mae: 7.1767\n",
      "Epoch 9/10\n",
      "472/472 - 7s - 15ms/step - loss: 106.2911 - mae: 7.1825\n",
      "Epoch 10/10\n",
      "472/472 - 7s - 14ms/step - loss: 106.0341 - mae: 7.1734\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 101.0149 - mae: 6.9238\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點1024, epoch10, batch64 訓練集績效:\n",
      "MAE score: 6.991771697998047\n",
      "MAPE score: 24.846631288528442\n",
      "RMSE score: 10.19469511420914\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點1024, epoch10, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.939807415008545\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "236/236 - 6s - 25ms/step - loss: 182.2119 - mae: 9.0253\n",
      "Epoch 2/10\n",
      "236/236 - 4s - 16ms/step - loss: 114.5672 - mae: 7.4243\n",
      "Epoch 3/10\n",
      "236/236 - 4s - 17ms/step - loss: 111.4103 - mae: 7.3123\n",
      "Epoch 4/10\n",
      "236/236 - 4s - 16ms/step - loss: 110.1659 - mae: 7.3015\n",
      "Epoch 5/10\n",
      "236/236 - 4s - 16ms/step - loss: 109.0659 - mae: 7.2815\n",
      "Epoch 6/10\n",
      "236/236 - 4s - 16ms/step - loss: 107.8847 - mae: 7.2419\n",
      "Epoch 7/10\n",
      "236/236 - 4s - 17ms/step - loss: 106.6640 - mae: 7.1845\n",
      "Epoch 8/10\n",
      "236/236 - 4s - 16ms/step - loss: 106.2672 - mae: 7.1670\n",
      "Epoch 9/10\n",
      "236/236 - 4s - 16ms/step - loss: 105.6400 - mae: 7.1405\n",
      "Epoch 10/10\n",
      "236/236 - 4s - 17ms/step - loss: 105.3822 - mae: 7.1456\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 101.1545 - mae: 6.8709\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點1024, epoch10, batch128 訓練集績效:\n",
      "MAE score: 6.933356761932373\n",
      "MAPE score: 24.344532191753387\n",
      "RMSE score: 10.199605851879346\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點1024, epoch10, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.82576286792755\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "118/118 - 4s - 36ms/step - loss: 248.8745 - mae: 10.2603\n",
      "Epoch 2/10\n",
      "118/118 - 3s - 24ms/step - loss: 116.9037 - mae: 7.4223\n",
      "Epoch 3/10\n",
      "118/118 - 3s - 22ms/step - loss: 112.4902 - mae: 7.2994\n",
      "Epoch 4/10\n",
      "118/118 - 2s - 21ms/step - loss: 110.1984 - mae: 7.2302\n",
      "Epoch 5/10\n",
      "118/118 - 2s - 21ms/step - loss: 108.0893 - mae: 7.2033\n",
      "Epoch 6/10\n",
      "118/118 - 2s - 21ms/step - loss: 107.8694 - mae: 7.2047\n",
      "Epoch 7/10\n",
      "118/118 - 3s - 22ms/step - loss: 106.5208 - mae: 7.1597\n",
      "Epoch 8/10\n",
      "118/118 - 3s - 21ms/step - loss: 105.8441 - mae: 7.1437\n",
      "Epoch 9/10\n",
      "118/118 - 2s - 21ms/step - loss: 105.1019 - mae: 7.1020\n",
      "Epoch 10/10\n",
      "118/118 - 2s - 21ms/step - loss: 105.1555 - mae: 7.1294\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 101.2286 - mae: 7.1832\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點1024, epoch10, batch256 訓練集績效:\n",
      "MAE score: 7.272089958190918\n",
      "MAPE score: 27.034875750541687\n",
      "RMSE score: 10.22749798767473\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點1024, epoch10, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 30.126863718032837\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "943/943 - 15s - 16ms/step - loss: 140.7231 - mae: 8.1983\n",
      "Epoch 2/20\n",
      "943/943 - 12s - 13ms/step - loss: 117.8003 - mae: 7.6125\n",
      "Epoch 3/20\n",
      "943/943 - 12s - 13ms/step - loss: 113.6915 - mae: 7.4414\n",
      "Epoch 4/20\n",
      "943/943 - 12s - 13ms/step - loss: 112.2031 - mae: 7.4038\n",
      "Epoch 5/20\n",
      "943/943 - 21s - 22ms/step - loss: 110.0861 - mae: 7.2968\n",
      "Epoch 6/20\n",
      "943/943 - 20s - 21ms/step - loss: 109.3072 - mae: 7.2792\n",
      "Epoch 7/20\n",
      "943/943 - 12s - 13ms/step - loss: 108.9933 - mae: 7.2680\n",
      "Epoch 8/20\n",
      "943/943 - 12s - 13ms/step - loss: 108.0597 - mae: 7.2395\n",
      "Epoch 9/20\n",
      "943/943 - 12s - 13ms/step - loss: 106.8223 - mae: 7.1851\n",
      "Epoch 10/20\n",
      "943/943 - 13s - 13ms/step - loss: 105.8982 - mae: 7.1441\n",
      "Epoch 11/20\n",
      "943/943 - 12s - 13ms/step - loss: 105.5105 - mae: 7.1392\n",
      "Epoch 12/20\n",
      "943/943 - 20s - 22ms/step - loss: 105.4091 - mae: 7.1232\n",
      "Epoch 13/20\n",
      "943/943 - 21s - 22ms/step - loss: 104.5440 - mae: 7.1028\n",
      "Epoch 14/20\n",
      "943/943 - 12s - 13ms/step - loss: 103.9350 - mae: 7.0586\n",
      "Epoch 15/20\n",
      "943/943 - 21s - 22ms/step - loss: 103.5708 - mae: 7.0589\n",
      "Epoch 16/20\n",
      "943/943 - 12s - 13ms/step - loss: 102.6607 - mae: 7.0308\n",
      "Epoch 17/20\n",
      "943/943 - 12s - 13ms/step - loss: 103.2750 - mae: 7.0597\n",
      "Epoch 18/20\n",
      "943/943 - 12s - 13ms/step - loss: 101.5884 - mae: 7.0011\n",
      "Epoch 19/20\n",
      "943/943 - 12s - 13ms/step - loss: 101.6331 - mae: 6.9970\n",
      "Epoch 20/20\n",
      "943/943 - 12s - 13ms/step - loss: 101.0467 - mae: 6.9818\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 95.2984 - mae: 6.7504\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點1024, epoch20, batch32 訓練集績效:\n",
      "MAE score: 6.800053596496582\n",
      "MAPE score: 24.659384787082672\n",
      "RMSE score: 9.886831028970311\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點1024, epoch20, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 27.365773916244507\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "472/472 - 10s - 20ms/step - loss: 155.5939 - mae: 8.4882\n",
      "Epoch 2/20\n",
      "472/472 - 7s - 14ms/step - loss: 115.7568 - mae: 7.4921\n",
      "Epoch 3/20\n",
      "472/472 - 7s - 15ms/step - loss: 112.5079 - mae: 7.3748\n",
      "Epoch 4/20\n",
      "472/472 - 7s - 15ms/step - loss: 110.3726 - mae: 7.3057\n",
      "Epoch 5/20\n",
      "472/472 - 7s - 15ms/step - loss: 109.1534 - mae: 7.2749\n",
      "Epoch 6/20\n",
      "472/472 - 7s - 14ms/step - loss: 108.4570 - mae: 7.2531\n",
      "Epoch 7/20\n",
      "472/472 - 7s - 14ms/step - loss: 107.1464 - mae: 7.2025\n",
      "Epoch 8/20\n",
      "472/472 - 7s - 15ms/step - loss: 106.8134 - mae: 7.1888\n",
      "Epoch 9/20\n",
      "472/472 - 10s - 21ms/step - loss: 106.2940 - mae: 7.1692\n",
      "Epoch 10/20\n",
      "472/472 - 7s - 14ms/step - loss: 105.2248 - mae: 7.1497\n",
      "Epoch 11/20\n",
      "472/472 - 11s - 22ms/step - loss: 104.6138 - mae: 7.1092\n",
      "Epoch 12/20\n",
      "472/472 - 7s - 14ms/step - loss: 104.9493 - mae: 7.1243\n",
      "Epoch 13/20\n",
      "472/472 - 7s - 14ms/step - loss: 104.0902 - mae: 7.0816\n",
      "Epoch 14/20\n",
      "472/472 - 7s - 14ms/step - loss: 103.4688 - mae: 7.0762\n",
      "Epoch 15/20\n",
      "472/472 - 7s - 14ms/step - loss: 103.5490 - mae: 7.0815\n",
      "Epoch 16/20\n",
      "472/472 - 7s - 14ms/step - loss: 102.8478 - mae: 7.0502\n",
      "Epoch 17/20\n",
      "472/472 - 7s - 14ms/step - loss: 102.7248 - mae: 7.0486\n",
      "Epoch 18/20\n",
      "472/472 - 10s - 22ms/step - loss: 102.8221 - mae: 7.0600\n",
      "Epoch 19/20\n",
      "472/472 - 8s - 16ms/step - loss: 101.9793 - mae: 7.0250\n",
      "Epoch 20/20\n",
      "472/472 - 11s - 22ms/step - loss: 100.8733 - mae: 6.9860\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 96.9117 - mae: 6.8454\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點1024, epoch20, batch64 訓練集績效:\n",
      "MAE score: 6.915031433105469\n",
      "MAPE score: 24.097612500190735\n",
      "RMSE score: 9.982701407563892\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點1024, epoch20, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 27.466294169425964\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "236/236 - 6s - 26ms/step - loss: 189.4442 - mae: 9.1388\n",
      "Epoch 2/20\n",
      "236/236 - 4s - 19ms/step - loss: 114.6045 - mae: 7.4007\n",
      "Epoch 3/20\n",
      "236/236 - 4s - 16ms/step - loss: 111.9168 - mae: 7.3384\n",
      "Epoch 4/20\n",
      "236/236 - 4s - 16ms/step - loss: 110.0767 - mae: 7.2677\n",
      "Epoch 5/20\n",
      "236/236 - 4s - 16ms/step - loss: 108.4593 - mae: 7.2274\n",
      "Epoch 6/20\n",
      "236/236 - 4s - 17ms/step - loss: 108.1351 - mae: 7.2099\n",
      "Epoch 7/20\n",
      "236/236 - 4s - 16ms/step - loss: 107.1756 - mae: 7.1992\n",
      "Epoch 8/20\n",
      "236/236 - 4s - 16ms/step - loss: 106.3304 - mae: 7.1724\n",
      "Epoch 9/20\n",
      "236/236 - 4s - 16ms/step - loss: 105.9205 - mae: 7.1545\n",
      "Epoch 10/20\n",
      "236/236 - 4s - 17ms/step - loss: 104.8125 - mae: 7.1261\n",
      "Epoch 11/20\n",
      "236/236 - 4s - 16ms/step - loss: 104.1709 - mae: 7.1012\n",
      "Epoch 12/20\n",
      "236/236 - 4s - 16ms/step - loss: 104.6378 - mae: 7.1160\n",
      "Epoch 13/20\n",
      "236/236 - 4s - 16ms/step - loss: 103.6516 - mae: 7.0578\n",
      "Epoch 14/20\n",
      "236/236 - 4s - 17ms/step - loss: 103.4462 - mae: 7.0832\n",
      "Epoch 15/20\n",
      "236/236 - 4s - 16ms/step - loss: 102.7225 - mae: 7.0425\n",
      "Epoch 16/20\n",
      "236/236 - 4s - 16ms/step - loss: 102.4310 - mae: 7.0288\n",
      "Epoch 17/20\n",
      "236/236 - 4s - 16ms/step - loss: 102.3176 - mae: 7.0325\n",
      "Epoch 18/20\n",
      "236/236 - 4s - 17ms/step - loss: 101.7568 - mae: 7.0140\n",
      "Epoch 19/20\n",
      "236/236 - 4s - 16ms/step - loss: 102.1786 - mae: 7.0461\n",
      "Epoch 20/20\n",
      "236/236 - 4s - 16ms/step - loss: 101.2927 - mae: 6.9983\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 100.6039 - mae: 7.2243\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點1024, epoch20, batch128 訓練集績效:\n",
      "MAE score: 7.300978183746338\n",
      "MAPE score: 27.096110582351685\n",
      "RMSE score: 10.173239995779062\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點1024, epoch20, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.676946997642517\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "118/118 - 4s - 36ms/step - loss: 243.6692 - mae: 10.4031\n",
      "Epoch 2/20\n",
      "118/118 - 3s - 26ms/step - loss: 114.7136 - mae: 7.3989\n",
      "Epoch 3/20\n",
      "118/118 - 3s - 22ms/step - loss: 112.0374 - mae: 7.3098\n",
      "Epoch 4/20\n",
      "118/118 - 2s - 21ms/step - loss: 109.8053 - mae: 7.2278\n",
      "Epoch 5/20\n",
      "118/118 - 2s - 21ms/step - loss: 108.2431 - mae: 7.1984\n",
      "Epoch 6/20\n",
      "118/118 - 2s - 21ms/step - loss: 106.7789 - mae: 7.1613\n",
      "Epoch 7/20\n",
      "118/118 - 3s - 22ms/step - loss: 107.8325 - mae: 7.2336\n",
      "Epoch 8/20\n",
      "118/118 - 2s - 21ms/step - loss: 105.4862 - mae: 7.1259\n",
      "Epoch 9/20\n",
      "118/118 - 2s - 21ms/step - loss: 104.7619 - mae: 7.0915\n",
      "Epoch 10/20\n",
      "118/118 - 2s - 21ms/step - loss: 105.1409 - mae: 7.1078\n",
      "Epoch 11/20\n",
      "118/118 - 3s - 22ms/step - loss: 104.0481 - mae: 7.0831\n",
      "Epoch 12/20\n",
      "118/118 - 2s - 21ms/step - loss: 104.1885 - mae: 7.1009\n",
      "Epoch 13/20\n",
      "118/118 - 2s - 21ms/step - loss: 104.3894 - mae: 7.1106\n",
      "Epoch 14/20\n",
      "118/118 - 2s - 21ms/step - loss: 102.5789 - mae: 7.0123\n",
      "Epoch 15/20\n",
      "118/118 - 3s - 22ms/step - loss: 102.3715 - mae: 7.0197\n",
      "Epoch 16/20\n",
      "118/118 - 3s - 22ms/step - loss: 102.4171 - mae: 7.0223\n",
      "Epoch 17/20\n",
      "118/118 - 2s - 21ms/step - loss: 102.1061 - mae: 7.0235\n",
      "Epoch 18/20\n",
      "118/118 - 2s - 21ms/step - loss: 101.3798 - mae: 6.9805\n",
      "Epoch 19/20\n",
      "118/118 - 3s - 22ms/step - loss: 101.7095 - mae: 7.0077\n",
      "Epoch 20/20\n",
      "118/118 - 2s - 21ms/step - loss: 100.5520 - mae: 6.9423\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 97.0822 - mae: 6.9182\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點1024, epoch20, batch256 訓練集績效:\n",
      "MAE score: 6.972286224365234\n",
      "MAPE score: 25.741973519325256\n",
      "RMSE score: 9.967084117639695\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層2, 節點1024, epoch20, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.27720844745636\n",
      "RMSE score: 14.235763666311897\n",
      "==================================================\n",
      "Completed batch for layer 2\n",
      "==================================================\n",
      "Epoch 1/5\n",
      "943/943 - 2s - 3ms/step - loss: 189.1612 - mae: 9.2804\n",
      "Epoch 2/5\n",
      "943/943 - 1s - 1ms/step - loss: 115.5014 - mae: 7.4759\n",
      "Epoch 3/5\n",
      "943/943 - 1s - 1ms/step - loss: 112.5321 - mae: 7.3746\n",
      "Epoch 4/5\n",
      "943/943 - 1s - 1ms/step - loss: 110.4728 - mae: 7.3093\n",
      "Epoch 5/5\n",
      "943/943 - 1s - 1ms/step - loss: 108.8350 - mae: 7.2546\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 995us/step - loss: 103.2898 - mae: 7.1029\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點64, epoch5, batch32 訓練集績效:\n",
      "MAE score: 7.180906295776367\n",
      "MAPE score: 25.68872570991516\n",
      "RMSE score: 10.314153735181051\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點64, epoch5, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.402261972427368\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "472/472 - 2s - 4ms/step - loss: 263.9992 - mae: 10.8765\n",
      "Epoch 2/5\n",
      "472/472 - 1s - 1ms/step - loss: 116.4925 - mae: 7.4860\n",
      "Epoch 3/5\n",
      "472/472 - 1s - 1ms/step - loss: 113.9958 - mae: 7.3808\n",
      "Epoch 4/5\n",
      "472/472 - 1s - 1ms/step - loss: 112.2038 - mae: 7.3253\n",
      "Epoch 5/5\n",
      "472/472 - 1s - 1ms/step - loss: 109.9458 - mae: 7.2587\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 104.3434 - mae: 7.1500\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點64, epoch5, batch64 訓練集績效:\n",
      "MAE score: 7.219195365905762\n",
      "MAPE score: 26.78377330303192\n",
      "RMSE score: 10.360743275494434\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點64, epoch5, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 30.13017177581787\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "236/236 - 2s - 7ms/step - loss: 411.7001 - mae: 14.1474\n",
      "Epoch 2/5\n",
      "236/236 - 0s - 2ms/step - loss: 120.1444 - mae: 7.6228\n",
      "Epoch 3/5\n",
      "236/236 - 0s - 1ms/step - loss: 116.0109 - mae: 7.4501\n",
      "Epoch 4/5\n",
      "236/236 - 0s - 2ms/step - loss: 113.5536 - mae: 7.3668\n",
      "Epoch 5/5\n",
      "236/236 - 0s - 1ms/step - loss: 111.8215 - mae: 7.2904\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 959us/step - loss: 105.8550 - mae: 7.0713\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點64, epoch5, batch128 訓練集績效:\n",
      "MAE score: 7.1661834716796875\n",
      "MAPE score: 26.711323857307434\n",
      "RMSE score: 10.453422416709657\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點64, epoch5, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 30.877292156219482\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "118/118 - 2s - 13ms/step - loss: 650.7708 - mae: 19.2645\n",
      "Epoch 2/5\n",
      "118/118 - 0s - 2ms/step - loss: 129.2325 - mae: 7.9580\n",
      "Epoch 3/5\n",
      "118/118 - 0s - 1ms/step - loss: 119.4006 - mae: 7.6232\n",
      "Epoch 4/5\n",
      "118/118 - 0s - 2ms/step - loss: 116.2336 - mae: 7.4819\n",
      "Epoch 5/5\n",
      "118/118 - 0s - 3ms/step - loss: 114.0829 - mae: 7.3915\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 956us/step - loss: 109.0530 - mae: 7.2313\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點64, epoch5, batch256 訓練集績效:\n",
      "MAE score: 7.307331085205078\n",
      "MAPE score: 27.491366863250732\n",
      "RMSE score: 10.590365699166854\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點64, epoch5, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 31.15178942680359\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "943/943 - 3s - 3ms/step - loss: 194.5417 - mae: 9.3446\n",
      "Epoch 2/10\n",
      "943/943 - 1s - 1ms/step - loss: 116.8648 - mae: 7.4786\n",
      "Epoch 3/10\n",
      "943/943 - 1s - 1ms/step - loss: 113.2776 - mae: 7.3788\n",
      "Epoch 4/10\n",
      "943/943 - 1s - 1ms/step - loss: 111.4708 - mae: 7.3367\n",
      "Epoch 5/10\n",
      "943/943 - 1s - 1ms/step - loss: 109.9515 - mae: 7.2536\n",
      "Epoch 6/10\n",
      "943/943 - 1s - 1ms/step - loss: 108.8022 - mae: 7.2252\n",
      "Epoch 7/10\n",
      "943/943 - 1s - 1ms/step - loss: 107.9117 - mae: 7.1978\n",
      "Epoch 8/10\n",
      "943/943 - 1s - 1ms/step - loss: 107.9413 - mae: 7.1982\n",
      "Epoch 9/10\n",
      "943/943 - 1s - 1ms/step - loss: 107.0266 - mae: 7.1813\n",
      "Epoch 10/10\n",
      "943/943 - 1s - 1ms/step - loss: 106.5585 - mae: 7.1524\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 946us/step - loss: 101.2095 - mae: 6.9335\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點64, epoch10, batch32 訓練集績效:\n",
      "MAE score: 7.016322135925293\n",
      "MAPE score: 25.04637837409973\n",
      "RMSE score: 10.209608556284545\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點64, epoch10, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.769415616989136\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "472/472 - 2s - 4ms/step - loss: 284.0363 - mae: 11.3021\n",
      "Epoch 2/10\n",
      "472/472 - 1s - 1ms/step - loss: 117.7078 - mae: 7.5251\n",
      "Epoch 3/10\n",
      "472/472 - 0s - 1ms/step - loss: 114.0805 - mae: 7.3805\n",
      "Epoch 4/10\n",
      "472/472 - 1s - 1ms/step - loss: 112.2368 - mae: 7.3061\n",
      "Epoch 5/10\n",
      "472/472 - 1s - 1ms/step - loss: 110.6645 - mae: 7.2644\n",
      "Epoch 6/10\n",
      "472/472 - 1s - 1ms/step - loss: 109.4882 - mae: 7.2168\n",
      "Epoch 7/10\n",
      "472/472 - 1s - 1ms/step - loss: 108.4443 - mae: 7.1864\n",
      "Epoch 8/10\n",
      "472/472 - 1s - 1ms/step - loss: 107.8960 - mae: 7.1708\n",
      "Epoch 9/10\n",
      "472/472 - 1s - 1ms/step - loss: 107.1026 - mae: 7.1471\n",
      "Epoch 10/10\n",
      "472/472 - 1s - 1ms/step - loss: 106.7155 - mae: 7.1299\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 970us/step - loss: 104.5893 - mae: 7.3110\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step  \n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點64, epoch10, batch64 訓練集績效:\n",
      "MAE score: 7.401421546936035\n",
      "MAPE score: 27.692806720733643\n",
      "RMSE score: 10.388060656312069\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點64, epoch10, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 30.105024576187134\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "236/236 - 2s - 7ms/step - loss: 447.6165 - mae: 14.9150\n",
      "Epoch 2/10\n",
      "236/236 - 0s - 2ms/step - loss: 120.6999 - mae: 7.6673\n",
      "Epoch 3/10\n",
      "236/236 - 1s - 3ms/step - loss: 115.0039 - mae: 7.4386\n",
      "Epoch 4/10\n",
      "236/236 - 0s - 2ms/step - loss: 112.9253 - mae: 7.3522\n",
      "Epoch 5/10\n",
      "236/236 - 0s - 1ms/step - loss: 110.9899 - mae: 7.2694\n",
      "Epoch 6/10\n",
      "236/236 - 0s - 2ms/step - loss: 109.5352 - mae: 7.2281\n",
      "Epoch 7/10\n",
      "236/236 - 0s - 1ms/step - loss: 108.2920 - mae: 7.1935\n",
      "Epoch 8/10\n",
      "236/236 - 0s - 1ms/step - loss: 107.9544 - mae: 7.1908\n",
      "Epoch 9/10\n",
      "236/236 - 0s - 2ms/step - loss: 107.2349 - mae: 7.1677\n",
      "Epoch 10/10\n",
      "236/236 - 0s - 1ms/step - loss: 106.4304 - mae: 7.1414\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 960us/step - loss: 100.9715 - mae: 6.9882\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step  \n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點64, epoch10, batch128 訓練集績效:\n",
      "MAE score: 7.076370716094971\n",
      "MAPE score: 26.186981797218323\n",
      "RMSE score: 10.222709985051742\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點64, epoch10, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.99192774295807\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "118/118 - 2s - 14ms/step - loss: 656.3069 - mae: 19.4061\n",
      "Epoch 2/10\n",
      "118/118 - 0s - 1ms/step - loss: 138.6961 - mae: 7.9252\n",
      "Epoch 3/10\n",
      "118/118 - 0s - 2ms/step - loss: 121.9485 - mae: 7.6148\n",
      "Epoch 4/10\n",
      "118/118 - 0s - 2ms/step - loss: 117.1708 - mae: 7.4772\n",
      "Epoch 5/10\n",
      "118/118 - 0s - 1ms/step - loss: 114.3737 - mae: 7.3809\n",
      "Epoch 6/10\n",
      "118/118 - 0s - 1ms/step - loss: 112.6441 - mae: 7.3283\n",
      "Epoch 7/10\n",
      "118/118 - 0s - 2ms/step - loss: 111.4133 - mae: 7.2893\n",
      "Epoch 8/10\n",
      "118/118 - 0s - 2ms/step - loss: 110.2595 - mae: 7.2469\n",
      "Epoch 9/10\n",
      "118/118 - 0s - 1ms/step - loss: 109.2417 - mae: 7.2045\n",
      "Epoch 10/10\n",
      "118/118 - 0s - 4ms/step - loss: 108.4395 - mae: 7.2000\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 965us/step - loss: 103.6291 - mae: 7.0338\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點64, epoch10, batch256 訓練集績效:\n",
      "MAE score: 7.1029229164123535\n",
      "MAPE score: 26.082006096839905\n",
      "RMSE score: 10.342920552445484\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點64, epoch10, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.73669171333313\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "943/943 - 3s - 3ms/step - loss: 194.9523 - mae: 9.3898\n",
      "Epoch 2/20\n",
      "943/943 - 1s - 1ms/step - loss: 117.1617 - mae: 7.5186\n",
      "Epoch 3/20\n",
      "943/943 - 1s - 1ms/step - loss: 113.8093 - mae: 7.3663\n",
      "Epoch 4/20\n",
      "943/943 - 1s - 1ms/step - loss: 111.8957 - mae: 7.3310\n",
      "Epoch 5/20\n",
      "943/943 - 1s - 1ms/step - loss: 110.5142 - mae: 7.2941\n",
      "Epoch 6/20\n",
      "943/943 - 1s - 1ms/step - loss: 108.9430 - mae: 7.2282\n",
      "Epoch 7/20\n",
      "943/943 - 1s - 1ms/step - loss: 107.8681 - mae: 7.1881\n",
      "Epoch 8/20\n",
      "943/943 - 1s - 1ms/step - loss: 107.4419 - mae: 7.1866\n",
      "Epoch 9/20\n",
      "943/943 - 1s - 1ms/step - loss: 107.0746 - mae: 7.1597\n",
      "Epoch 10/20\n",
      "943/943 - 1s - 1ms/step - loss: 106.1534 - mae: 7.1382\n",
      "Epoch 11/20\n",
      "943/943 - 1s - 1ms/step - loss: 105.8046 - mae: 7.1240\n",
      "Epoch 12/20\n",
      "943/943 - 1s - 1ms/step - loss: 105.6968 - mae: 7.1105\n",
      "Epoch 13/20\n",
      "943/943 - 1s - 1ms/step - loss: 105.0723 - mae: 7.0877\n",
      "Epoch 14/20\n",
      "943/943 - 1s - 1ms/step - loss: 104.4752 - mae: 7.0617\n",
      "Epoch 15/20\n",
      "943/943 - 1s - 1ms/step - loss: 104.2224 - mae: 7.0590\n",
      "Epoch 16/20\n",
      "943/943 - 1s - 1ms/step - loss: 103.6199 - mae: 7.0457\n",
      "Epoch 17/20\n",
      "943/943 - 1s - 1ms/step - loss: 103.3914 - mae: 7.0343\n",
      "Epoch 18/20\n",
      "943/943 - 1s - 1ms/step - loss: 103.1729 - mae: 7.0236\n",
      "Epoch 19/20\n",
      "943/943 - 1s - 1ms/step - loss: 102.9382 - mae: 7.0267\n",
      "Epoch 20/20\n",
      "943/943 - 1s - 1ms/step - loss: 102.5661 - mae: 7.0045\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 98.6848 - mae: 6.9931\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點64, epoch20, batch32 訓練集績效:\n",
      "MAE score: 7.065621852874756\n",
      "MAPE score: 26.353731751441956\n",
      "RMSE score: 10.085177628594003\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 944us/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點64, epoch20, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.443421959877014\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "472/472 - 2s - 4ms/step - loss: 251.4550 - mae: 10.6836\n",
      "Epoch 2/20\n",
      "472/472 - 1s - 1ms/step - loss: 116.5694 - mae: 7.5088\n",
      "Epoch 3/20\n",
      "472/472 - 1s - 1ms/step - loss: 113.7676 - mae: 7.3815\n",
      "Epoch 4/20\n",
      "472/472 - 1s - 1ms/step - loss: 111.6361 - mae: 7.3146\n",
      "Epoch 5/20\n",
      "472/472 - 1s - 1ms/step - loss: 110.5468 - mae: 7.2851\n",
      "Epoch 6/20\n",
      "472/472 - 1s - 1ms/step - loss: 109.3307 - mae: 7.2407\n",
      "Epoch 7/20\n",
      "472/472 - 1s - 1ms/step - loss: 108.2703 - mae: 7.2124\n",
      "Epoch 8/20\n",
      "472/472 - 1s - 1ms/step - loss: 107.4810 - mae: 7.1789\n",
      "Epoch 9/20\n",
      "472/472 - 1s - 1ms/step - loss: 107.4744 - mae: 7.1786\n",
      "Epoch 10/20\n",
      "472/472 - 1s - 1ms/step - loss: 106.3932 - mae: 7.1444\n",
      "Epoch 11/20\n",
      "472/472 - 1s - 2ms/step - loss: 106.4128 - mae: 7.1297\n",
      "Epoch 12/20\n",
      "472/472 - 0s - 1ms/step - loss: 105.7656 - mae: 7.1118\n",
      "Epoch 13/20\n",
      "472/472 - 1s - 1ms/step - loss: 105.6994 - mae: 7.1190\n",
      "Epoch 14/20\n",
      "472/472 - 1s - 1ms/step - loss: 104.8627 - mae: 7.0890\n",
      "Epoch 15/20\n",
      "472/472 - 1s - 1ms/step - loss: 104.9537 - mae: 7.1069\n",
      "Epoch 16/20\n",
      "472/472 - 0s - 1ms/step - loss: 103.9035 - mae: 7.0555\n",
      "Epoch 17/20\n",
      "472/472 - 1s - 1ms/step - loss: 103.5324 - mae: 7.0325\n",
      "Epoch 18/20\n",
      "472/472 - 1s - 1ms/step - loss: 103.8023 - mae: 7.0632\n",
      "Epoch 19/20\n",
      "472/472 - 1s - 1ms/step - loss: 103.4674 - mae: 7.0377\n",
      "Epoch 20/20\n",
      "472/472 - 1s - 1ms/step - loss: 103.1117 - mae: 7.0242\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 963us/step - loss: 98.3063 - mae: 6.8546\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點64, epoch20, batch64 訓練集績效:\n",
      "MAE score: 6.936967372894287\n",
      "MAPE score: 24.611796438694\n",
      "RMSE score: 10.073743899966356\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點64, epoch20, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.07666265964508\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "236/236 - 2s - 8ms/step - loss: 410.2608 - mae: 14.0487\n",
      "Epoch 2/20\n",
      "236/236 - 0s - 2ms/step - loss: 131.5940 - mae: 7.7142\n",
      "Epoch 3/20\n",
      "236/236 - 0s - 2ms/step - loss: 119.3134 - mae: 7.4886\n",
      "Epoch 4/20\n",
      "236/236 - 0s - 1ms/step - loss: 115.1575 - mae: 7.3797\n",
      "Epoch 5/20\n",
      "236/236 - 0s - 2ms/step - loss: 113.0698 - mae: 7.3282\n",
      "Epoch 6/20\n",
      "236/236 - 0s - 1ms/step - loss: 110.8524 - mae: 7.2646\n",
      "Epoch 7/20\n",
      "236/236 - 0s - 1ms/step - loss: 109.2874 - mae: 7.2132\n",
      "Epoch 8/20\n",
      "236/236 - 0s - 2ms/step - loss: 108.3532 - mae: 7.1938\n",
      "Epoch 9/20\n",
      "236/236 - 0s - 1ms/step - loss: 107.5763 - mae: 7.1545\n",
      "Epoch 10/20\n",
      "236/236 - 0s - 1ms/step - loss: 107.0765 - mae: 7.1463\n",
      "Epoch 11/20\n",
      "236/236 - 0s - 2ms/step - loss: 106.7382 - mae: 7.1351\n",
      "Epoch 12/20\n",
      "236/236 - 0s - 1ms/step - loss: 105.6395 - mae: 7.0904\n",
      "Epoch 13/20\n",
      "236/236 - 0s - 1ms/step - loss: 105.6349 - mae: 7.0864\n",
      "Epoch 14/20\n",
      "236/236 - 0s - 2ms/step - loss: 105.2332 - mae: 7.0810\n",
      "Epoch 15/20\n",
      "236/236 - 0s - 1ms/step - loss: 104.5975 - mae: 7.0484\n",
      "Epoch 16/20\n",
      "236/236 - 0s - 1ms/step - loss: 104.5779 - mae: 7.0570\n",
      "Epoch 17/20\n",
      "236/236 - 0s - 1ms/step - loss: 104.4010 - mae: 7.0560\n",
      "Epoch 18/20\n",
      "236/236 - 0s - 2ms/step - loss: 103.9836 - mae: 7.0298\n",
      "Epoch 19/20\n",
      "236/236 - 0s - 1ms/step - loss: 103.5961 - mae: 7.0147\n",
      "Epoch 20/20\n",
      "236/236 - 0s - 1ms/step - loss: 103.1723 - mae: 7.0028\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 969us/step - loss: 98.1574 - mae: 6.9021\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點64, epoch20, batch128 訓練集績效:\n",
      "MAE score: 6.982697010040283\n",
      "MAPE score: 25.38418471813202\n",
      "RMSE score: 10.061551446217567\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點64, epoch20, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.674209117889404\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "118/118 - 2s - 15ms/step - loss: 625.8448 - mae: 18.9480\n",
      "Epoch 2/20\n",
      "118/118 - 0s - 2ms/step - loss: 130.4529 - mae: 7.9832\n",
      "Epoch 3/20\n",
      "118/118 - 0s - 2ms/step - loss: 120.4251 - mae: 7.6537\n",
      "Epoch 4/20\n",
      "118/118 - 0s - 2ms/step - loss: 116.9039 - mae: 7.5114\n",
      "Epoch 5/20\n",
      "118/118 - 0s - 3ms/step - loss: 114.5725 - mae: 7.4096\n",
      "Epoch 6/20\n",
      "118/118 - 0s - 2ms/step - loss: 112.9986 - mae: 7.3541\n",
      "Epoch 7/20\n",
      "118/118 - 0s - 2ms/step - loss: 111.5441 - mae: 7.3046\n",
      "Epoch 8/20\n",
      "118/118 - 0s - 2ms/step - loss: 110.5334 - mae: 7.2741\n",
      "Epoch 9/20\n",
      "118/118 - 0s - 2ms/step - loss: 109.5002 - mae: 7.2347\n",
      "Epoch 10/20\n",
      "118/118 - 0s - 2ms/step - loss: 108.6595 - mae: 7.2066\n",
      "Epoch 11/20\n",
      "118/118 - 0s - 2ms/step - loss: 107.8858 - mae: 7.1887\n",
      "Epoch 12/20\n",
      "118/118 - 0s - 2ms/step - loss: 107.1053 - mae: 7.1580\n",
      "Epoch 13/20\n",
      "118/118 - 0s - 2ms/step - loss: 107.0356 - mae: 7.1643\n",
      "Epoch 14/20\n",
      "118/118 - 0s - 2ms/step - loss: 106.6505 - mae: 7.1579\n",
      "Epoch 15/20\n",
      "118/118 - 0s - 2ms/step - loss: 106.1451 - mae: 7.1206\n",
      "Epoch 16/20\n",
      "118/118 - 0s - 2ms/step - loss: 105.4032 - mae: 7.1026\n",
      "Epoch 17/20\n",
      "118/118 - 0s - 2ms/step - loss: 105.0550 - mae: 7.0909\n",
      "Epoch 18/20\n",
      "118/118 - 0s - 2ms/step - loss: 105.1200 - mae: 7.0960\n",
      "Epoch 19/20\n",
      "118/118 - 0s - 1ms/step - loss: 104.9060 - mae: 7.0928\n",
      "Epoch 20/20\n",
      "118/118 - 0s - 2ms/step - loss: 104.6738 - mae: 7.0782\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 914us/step - loss: 100.5823 - mae: 6.9388\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點64, epoch20, batch256 訓練集績效:\n",
      "MAE score: 7.01396369934082\n",
      "MAPE score: 25.01186728477478\n",
      "RMSE score: 10.179985410908436\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點64, epoch20, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.20585870742798\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "943/943 - 3s - 3ms/step - loss: 172.6605 - mae: 8.8236\n",
      "Epoch 2/5\n",
      "943/943 - 1s - 1ms/step - loss: 115.2910 - mae: 7.4653\n",
      "Epoch 3/5\n",
      "943/943 - 1s - 1ms/step - loss: 112.3045 - mae: 7.3624\n",
      "Epoch 4/5\n",
      "943/943 - 1s - 1ms/step - loss: 110.2886 - mae: 7.2871\n",
      "Epoch 5/5\n",
      "943/943 - 1s - 1ms/step - loss: 109.3646 - mae: 7.2714\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 978us/step - loss: 107.1435 - mae: 7.1084\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點128, epoch5, batch32 訓練集績效:\n",
      "MAE score: 7.176849842071533\n",
      "MAPE score: 24.70555007457733\n",
      "RMSE score: 10.511781531422514\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點128, epoch5, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.13268506526947\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "472/472 - 2s - 4ms/step - loss: 218.9661 - mae: 9.8810\n",
      "Epoch 2/5\n",
      "472/472 - 1s - 2ms/step - loss: 116.0970 - mae: 7.4805\n",
      "Epoch 3/5\n",
      "472/472 - 1s - 1ms/step - loss: 112.7028 - mae: 7.3796\n",
      "Epoch 4/5\n",
      "472/472 - 1s - 2ms/step - loss: 110.6638 - mae: 7.3079\n",
      "Epoch 5/5\n",
      "472/472 - 1s - 1ms/step - loss: 108.8093 - mae: 7.2408\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 104.3909 - mae: 7.1147\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點128, epoch5, batch64 訓練集績效:\n",
      "MAE score: 7.184058666229248\n",
      "MAPE score: 25.33188760280609\n",
      "RMSE score: 10.363340513517883\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點128, epoch5, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.31152880191803\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "236/236 - 2s - 8ms/step - loss: 289.9475 - mae: 11.4964\n",
      "Epoch 2/5\n",
      "236/236 - 0s - 2ms/step - loss: 117.0097 - mae: 7.4966\n",
      "Epoch 3/5\n",
      "236/236 - 0s - 2ms/step - loss: 113.3981 - mae: 7.3450\n",
      "Epoch 4/5\n",
      "236/236 - 0s - 2ms/step - loss: 111.5422 - mae: 7.3000\n",
      "Epoch 5/5\n",
      "236/236 - 0s - 2ms/step - loss: 109.7605 - mae: 7.2413\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 967us/step - loss: 102.8633 - mae: 7.0106\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點128, epoch5, batch128 訓練集績效:\n",
      "MAE score: 7.104923725128174\n",
      "MAPE score: 25.774094462394714\n",
      "RMSE score: 10.316804484575115\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點128, epoch5, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.610100388526917\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "118/118 - 2s - 14ms/step - loss: 435.8650 - mae: 14.7016\n",
      "Epoch 2/5\n",
      "118/118 - 0s - 2ms/step - loss: 119.3318 - mae: 7.6051\n",
      "Epoch 3/5\n",
      "118/118 - 0s - 3ms/step - loss: 114.2296 - mae: 7.3956\n",
      "Epoch 4/5\n",
      "118/118 - 0s - 2ms/step - loss: 111.7098 - mae: 7.3004\n",
      "Epoch 5/5\n",
      "118/118 - 0s - 2ms/step - loss: 110.0670 - mae: 7.2327\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 104.8838 - mae: 7.1696\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點128, epoch5, batch256 訓練集績效:\n",
      "MAE score: 7.249289035797119\n",
      "MAPE score: 26.921483874320984\n",
      "RMSE score: 10.399653546358039\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點128, epoch5, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 30.053406953811646\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "943/943 - 3s - 3ms/step - loss: 166.6602 - mae: 8.7263\n",
      "Epoch 2/10\n",
      "943/943 - 1s - 1ms/step - loss: 115.9095 - mae: 7.4946\n",
      "Epoch 3/10\n",
      "943/943 - 1s - 1ms/step - loss: 112.3022 - mae: 7.3784\n",
      "Epoch 4/10\n",
      "943/943 - 1s - 1ms/step - loss: 110.1754 - mae: 7.2999\n",
      "Epoch 5/10\n",
      "943/943 - 1s - 1ms/step - loss: 109.1476 - mae: 7.2844\n",
      "Epoch 6/10\n",
      "943/943 - 1s - 1ms/step - loss: 108.5090 - mae: 7.2464\n",
      "Epoch 7/10\n",
      "943/943 - 1s - 1ms/step - loss: 107.0059 - mae: 7.1846\n",
      "Epoch 8/10\n",
      "943/943 - 1s - 1ms/step - loss: 106.8348 - mae: 7.1744\n",
      "Epoch 9/10\n",
      "943/943 - 1s - 1ms/step - loss: 105.8371 - mae: 7.1427\n",
      "Epoch 10/10\n",
      "943/943 - 1s - 1ms/step - loss: 105.1665 - mae: 7.1087\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 984us/step - loss: 100.5463 - mae: 6.9155\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點128, epoch10, batch32 訓練集績效:\n",
      "MAE score: 6.980802059173584\n",
      "MAPE score: 24.714206159114838\n",
      "RMSE score: 10.159568268020946\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點128, epoch10, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.09382975101471\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "472/472 - 2s - 4ms/step - loss: 216.1486 - mae: 9.7766\n",
      "Epoch 2/10\n",
      "472/472 - 1s - 2ms/step - loss: 116.2286 - mae: 7.4581\n",
      "Epoch 3/10\n",
      "472/472 - 1s - 1ms/step - loss: 112.4278 - mae: 7.3246\n",
      "Epoch 4/10\n",
      "472/472 - 1s - 1ms/step - loss: 110.6630 - mae: 7.2757\n",
      "Epoch 5/10\n",
      "472/472 - 1s - 2ms/step - loss: 109.6246 - mae: 7.2780\n",
      "Epoch 6/10\n",
      "472/472 - 1s - 1ms/step - loss: 107.7001 - mae: 7.1941\n",
      "Epoch 7/10\n",
      "472/472 - 1s - 1ms/step - loss: 107.9820 - mae: 7.1918\n",
      "Epoch 8/10\n",
      "472/472 - 1s - 2ms/step - loss: 106.6142 - mae: 7.1739\n",
      "Epoch 9/10\n",
      "472/472 - 1s - 1ms/step - loss: 106.2106 - mae: 7.1533\n",
      "Epoch 10/10\n",
      "472/472 - 1s - 1ms/step - loss: 105.4654 - mae: 7.1139\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 989us/step - loss: 99.1700 - mae: 6.9084\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點128, epoch10, batch64 訓練集績效:\n",
      "MAE score: 6.996908664703369\n",
      "MAPE score: 25.475308299064636\n",
      "RMSE score: 10.130842618853022\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點128, epoch10, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.1251003742218\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "236/236 - 2s - 8ms/step - loss: 285.6414 - mae: 11.4002\n",
      "Epoch 2/10\n",
      "236/236 - 0s - 2ms/step - loss: 116.6194 - mae: 7.4689\n",
      "Epoch 3/10\n",
      "236/236 - 0s - 2ms/step - loss: 113.2210 - mae: 7.3380\n",
      "Epoch 4/10\n",
      "236/236 - 0s - 2ms/step - loss: 110.7825 - mae: 7.2485\n",
      "Epoch 5/10\n",
      "236/236 - 0s - 2ms/step - loss: 109.1722 - mae: 7.2054\n",
      "Epoch 6/10\n",
      "236/236 - 1s - 2ms/step - loss: 108.2615 - mae: 7.1866\n",
      "Epoch 7/10\n",
      "236/236 - 0s - 2ms/step - loss: 106.9280 - mae: 7.1406\n",
      "Epoch 8/10\n",
      "236/236 - 0s - 2ms/step - loss: 106.4200 - mae: 7.1280\n",
      "Epoch 9/10\n",
      "236/236 - 0s - 2ms/step - loss: 105.9361 - mae: 7.1269\n",
      "Epoch 10/10\n",
      "236/236 - 0s - 2ms/step - loss: 105.7052 - mae: 7.1287\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 993us/step - loss: 100.4888 - mae: 7.0517\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點128, epoch10, batch128 訓練集績效:\n",
      "MAE score: 7.131483554840088\n",
      "MAPE score: 26.39530301094055\n",
      "RMSE score: 10.17424600042903\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點128, epoch10, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 30.067870020866394\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "118/118 - 2s - 15ms/step - loss: 438.7359 - mae: 14.7869\n",
      "Epoch 2/10\n",
      "118/118 - 0s - 2ms/step - loss: 120.3707 - mae: 7.6397\n",
      "Epoch 3/10\n",
      "118/118 - 0s - 3ms/step - loss: 114.8734 - mae: 7.4388\n",
      "Epoch 4/10\n",
      "118/118 - 0s - 2ms/step - loss: 112.1632 - mae: 7.3254\n",
      "Epoch 5/10\n",
      "118/118 - 0s - 2ms/step - loss: 109.9770 - mae: 7.2397\n",
      "Epoch 6/10\n",
      "118/118 - 0s - 3ms/step - loss: 108.6359 - mae: 7.1948\n",
      "Epoch 7/10\n",
      "118/118 - 0s - 3ms/step - loss: 107.7941 - mae: 7.1864\n",
      "Epoch 8/10\n",
      "118/118 - 0s - 2ms/step - loss: 106.6530 - mae: 7.1390\n",
      "Epoch 9/10\n",
      "118/118 - 0s - 2ms/step - loss: 105.8382 - mae: 7.0995\n",
      "Epoch 10/10\n",
      "118/118 - 0s - 3ms/step - loss: 106.1216 - mae: 7.1494\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1000us/step - loss: 100.0599 - mae: 6.9512\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點128, epoch10, batch256 訓練集績效:\n",
      "MAE score: 7.0400776863098145\n",
      "MAPE score: 26.236790418624878\n",
      "RMSE score: 10.173602963828744\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點128, epoch10, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.97550666332245\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "943/943 - 3s - 3ms/step - loss: 168.6334 - mae: 8.7801\n",
      "Epoch 2/20\n",
      "943/943 - 1s - 1ms/step - loss: 115.9243 - mae: 7.4910\n",
      "Epoch 3/20\n",
      "943/943 - 1s - 1ms/step - loss: 113.0613 - mae: 7.4205\n",
      "Epoch 4/20\n",
      "943/943 - 1s - 1ms/step - loss: 111.1359 - mae: 7.3315\n",
      "Epoch 5/20\n",
      "943/943 - 1s - 1ms/step - loss: 109.6326 - mae: 7.2663\n",
      "Epoch 6/20\n",
      "943/943 - 1s - 1ms/step - loss: 108.4993 - mae: 7.2388\n",
      "Epoch 7/20\n",
      "943/943 - 1s - 1ms/step - loss: 107.6404 - mae: 7.2123\n",
      "Epoch 8/20\n",
      "943/943 - 1s - 1ms/step - loss: 107.5688 - mae: 7.2047\n",
      "Epoch 9/20\n",
      "943/943 - 1s - 1ms/step - loss: 106.6149 - mae: 7.1705\n",
      "Epoch 10/20\n",
      "943/943 - 1s - 1ms/step - loss: 105.8392 - mae: 7.1423\n",
      "Epoch 11/20\n",
      "943/943 - 1s - 1ms/step - loss: 105.5426 - mae: 7.1331\n",
      "Epoch 12/20\n",
      "943/943 - 1s - 1ms/step - loss: 104.4172 - mae: 7.1060\n",
      "Epoch 13/20\n",
      "943/943 - 1s - 1ms/step - loss: 104.2007 - mae: 7.0896\n",
      "Epoch 14/20\n",
      "943/943 - 1s - 1ms/step - loss: 104.1992 - mae: 7.0954\n",
      "Epoch 15/20\n",
      "943/943 - 1s - 1ms/step - loss: 103.0685 - mae: 7.0627\n",
      "Epoch 16/20\n",
      "943/943 - 1s - 1ms/step - loss: 102.8785 - mae: 7.0537\n",
      "Epoch 17/20\n",
      "943/943 - 1s - 1ms/step - loss: 102.4863 - mae: 7.0329\n",
      "Epoch 18/20\n",
      "943/943 - 1s - 1ms/step - loss: 101.7293 - mae: 7.0119\n",
      "Epoch 19/20\n",
      "943/943 - 1s - 1ms/step - loss: 101.7536 - mae: 7.0235\n",
      "Epoch 20/20\n",
      "943/943 - 1s - 1ms/step - loss: 101.0861 - mae: 6.9820\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 94.8942 - mae: 6.6969\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點128, epoch20, batch32 訓練集績效:\n",
      "MAE score: 6.747611999511719\n",
      "MAPE score: 24.004361033439636\n",
      "RMSE score: 9.876380147941864\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點128, epoch20, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.053832054138184\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "472/472 - 2s - 5ms/step - loss: 215.8405 - mae: 9.7957\n",
      "Epoch 2/20\n",
      "472/472 - 1s - 2ms/step - loss: 115.2602 - mae: 7.4603\n",
      "Epoch 3/20\n",
      "472/472 - 1s - 1ms/step - loss: 112.3272 - mae: 7.3577\n",
      "Epoch 4/20\n",
      "472/472 - 1s - 2ms/step - loss: 110.1936 - mae: 7.2949\n",
      "Epoch 5/20\n",
      "472/472 - 1s - 1ms/step - loss: 109.1490 - mae: 7.2523\n",
      "Epoch 6/20\n",
      "472/472 - 1s - 1ms/step - loss: 108.4658 - mae: 7.2314\n",
      "Epoch 7/20\n",
      "472/472 - 1s - 2ms/step - loss: 107.3782 - mae: 7.1936\n",
      "Epoch 8/20\n",
      "472/472 - 1s - 1ms/step - loss: 106.6398 - mae: 7.1662\n",
      "Epoch 9/20\n",
      "472/472 - 1s - 1ms/step - loss: 106.7802 - mae: 7.1874\n",
      "Epoch 10/20\n",
      "472/472 - 1s - 2ms/step - loss: 105.7140 - mae: 7.1300\n",
      "Epoch 11/20\n",
      "472/472 - 1s - 1ms/step - loss: 105.2062 - mae: 7.1165\n",
      "Epoch 12/20\n",
      "472/472 - 1s - 1ms/step - loss: 104.8094 - mae: 7.0886\n",
      "Epoch 13/20\n",
      "472/472 - 1s - 1ms/step - loss: 104.0156 - mae: 7.0608\n",
      "Epoch 14/20\n",
      "472/472 - 1s - 1ms/step - loss: 103.5032 - mae: 7.0599\n",
      "Epoch 15/20\n",
      "472/472 - 1s - 1ms/step - loss: 103.6258 - mae: 7.0718\n",
      "Epoch 16/20\n",
      "472/472 - 1s - 1ms/step - loss: 102.3755 - mae: 7.0164\n",
      "Epoch 17/20\n",
      "472/472 - 1s - 1ms/step - loss: 102.0708 - mae: 6.9976\n",
      "Epoch 18/20\n",
      "472/472 - 1s - 1ms/step - loss: 101.6772 - mae: 6.9979\n",
      "Epoch 19/20\n",
      "472/472 - 1s - 2ms/step - loss: 100.9029 - mae: 6.9618\n",
      "Epoch 20/20\n",
      "472/472 - 1s - 1ms/step - loss: 101.0487 - mae: 6.9904\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 987us/step - loss: 94.8015 - mae: 6.8059\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點128, epoch20, batch64 訓練集績效:\n",
      "MAE score: 6.864102363586426\n",
      "MAPE score: 24.730411171913147\n",
      "RMSE score: 9.878407723309927\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點128, epoch20, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.54245901107788\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "236/236 - 2s - 8ms/step - loss: 308.3440 - mae: 11.8235\n",
      "Epoch 2/20\n",
      "236/236 - 0s - 2ms/step - loss: 116.6661 - mae: 7.4992\n",
      "Epoch 3/20\n",
      "236/236 - 0s - 2ms/step - loss: 112.6411 - mae: 7.3291\n",
      "Epoch 4/20\n",
      "236/236 - 0s - 2ms/step - loss: 110.1510 - mae: 7.2523\n",
      "Epoch 5/20\n",
      "236/236 - 0s - 2ms/step - loss: 108.9957 - mae: 7.2378\n",
      "Epoch 6/20\n",
      "236/236 - 0s - 2ms/step - loss: 107.9721 - mae: 7.2036\n",
      "Epoch 7/20\n",
      "236/236 - 0s - 2ms/step - loss: 107.0748 - mae: 7.1556\n",
      "Epoch 8/20\n",
      "236/236 - 0s - 2ms/step - loss: 105.9093 - mae: 7.1141\n",
      "Epoch 9/20\n",
      "236/236 - 0s - 2ms/step - loss: 105.7920 - mae: 7.1141\n",
      "Epoch 10/20\n",
      "236/236 - 0s - 2ms/step - loss: 105.1774 - mae: 7.0979\n",
      "Epoch 11/20\n",
      "236/236 - 1s - 2ms/step - loss: 104.5110 - mae: 7.0689\n",
      "Epoch 12/20\n",
      "236/236 - 0s - 2ms/step - loss: 104.2319 - mae: 7.0533\n",
      "Epoch 13/20\n",
      "236/236 - 0s - 2ms/step - loss: 103.5216 - mae: 7.0395\n",
      "Epoch 14/20\n",
      "236/236 - 0s - 2ms/step - loss: 103.4254 - mae: 7.0384\n",
      "Epoch 15/20\n",
      "236/236 - 0s - 2ms/step - loss: 102.7756 - mae: 7.0217\n",
      "Epoch 16/20\n",
      "236/236 - 0s - 2ms/step - loss: 103.2539 - mae: 7.0437\n",
      "Epoch 17/20\n",
      "236/236 - 0s - 2ms/step - loss: 102.0582 - mae: 6.9848\n",
      "Epoch 18/20\n",
      "236/236 - 0s - 2ms/step - loss: 102.7770 - mae: 7.0439\n",
      "Epoch 19/20\n",
      "236/236 - 1s - 3ms/step - loss: 101.1717 - mae: 6.9536\n",
      "Epoch 20/20\n",
      "236/236 - 0s - 2ms/step - loss: 101.1572 - mae: 6.9709\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 100.4631 - mae: 6.9143\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點128, epoch20, batch128 訓練集績效:\n",
      "MAE score: 6.976303577423096\n",
      "MAPE score: 23.57938140630722\n",
      "RMSE score: 10.153465664010215\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點128, epoch20, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.577029705047607\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "118/118 - 2s - 14ms/step - loss: 439.6305 - mae: 14.7697\n",
      "Epoch 2/20\n",
      "118/118 - 0s - 3ms/step - loss: 119.7118 - mae: 7.5860\n",
      "Epoch 3/20\n",
      "118/118 - 0s - 3ms/step - loss: 114.2663 - mae: 7.3781\n",
      "Epoch 4/20\n",
      "118/118 - 0s - 2ms/step - loss: 111.7215 - mae: 7.2897\n",
      "Epoch 5/20\n",
      "118/118 - 0s - 2ms/step - loss: 110.2353 - mae: 7.2506\n",
      "Epoch 6/20\n",
      "118/118 - 0s - 3ms/step - loss: 108.5667 - mae: 7.1986\n",
      "Epoch 7/20\n",
      "118/118 - 0s - 2ms/step - loss: 107.3142 - mae: 7.1400\n",
      "Epoch 8/20\n",
      "118/118 - 0s - 2ms/step - loss: 106.6353 - mae: 7.1415\n",
      "Epoch 9/20\n",
      "118/118 - 0s - 3ms/step - loss: 106.1704 - mae: 7.1272\n",
      "Epoch 10/20\n",
      "118/118 - 0s - 3ms/step - loss: 105.7359 - mae: 7.1279\n",
      "Epoch 11/20\n",
      "118/118 - 0s - 2ms/step - loss: 105.0055 - mae: 7.0878\n",
      "Epoch 12/20\n",
      "118/118 - 0s - 3ms/step - loss: 104.4578 - mae: 7.0699\n",
      "Epoch 13/20\n",
      "118/118 - 0s - 3ms/step - loss: 104.0394 - mae: 7.0614\n",
      "Epoch 14/20\n",
      "118/118 - 1s - 6ms/step - loss: 103.3533 - mae: 7.0276\n",
      "Epoch 15/20\n",
      "118/118 - 0s - 3ms/step - loss: 103.1304 - mae: 7.0298\n",
      "Epoch 16/20\n",
      "118/118 - 0s - 2ms/step - loss: 103.2737 - mae: 7.0323\n",
      "Epoch 17/20\n",
      "118/118 - 0s - 4ms/step - loss: 102.3691 - mae: 7.0077\n",
      "Epoch 18/20\n",
      "118/118 - 0s - 3ms/step - loss: 102.1835 - mae: 6.9923\n",
      "Epoch 19/20\n",
      "118/118 - 0s - 2ms/step - loss: 102.1680 - mae: 6.9979\n",
      "Epoch 20/20\n",
      "118/118 - 0s - 3ms/step - loss: 101.8278 - mae: 6.9987\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 96.7976 - mae: 6.7932\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點128, epoch20, batch256 訓練集績效:\n",
      "MAE score: 6.865986347198486\n",
      "MAPE score: 24.707841873168945\n",
      "RMSE score: 9.972813462700303\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點128, epoch20, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.19672429561615\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "943/943 - 4s - 4ms/step - loss: 150.4476 - mae: 8.3899\n",
      "Epoch 2/5\n",
      "943/943 - 2s - 2ms/step - loss: 116.1722 - mae: 7.5090\n",
      "Epoch 3/5\n",
      "943/943 - 2s - 2ms/step - loss: 114.0423 - mae: 7.4518\n",
      "Epoch 4/5\n",
      "943/943 - 3s - 3ms/step - loss: 111.4925 - mae: 7.3399\n",
      "Epoch 5/5\n",
      "943/943 - 3s - 3ms/step - loss: 110.1159 - mae: 7.3294\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 103.9103 - mae: 7.3059\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點256, epoch5, batch32 訓練集績效:\n",
      "MAE score: 7.376525402069092\n",
      "MAPE score: 27.229884266853333\n",
      "RMSE score: 10.341873782468994\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點256, epoch5, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.607966542243958\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "472/472 - 3s - 5ms/step - loss: 169.5610 - mae: 8.8382\n",
      "Epoch 2/5\n",
      "472/472 - 1s - 2ms/step - loss: 114.9626 - mae: 7.4584\n",
      "Epoch 3/5\n",
      "472/472 - 1s - 3ms/step - loss: 111.8484 - mae: 7.3606\n",
      "Epoch 4/5\n",
      "472/472 - 1s - 3ms/step - loss: 110.3049 - mae: 7.3313\n",
      "Epoch 5/5\n",
      "472/472 - 1s - 2ms/step - loss: 109.3173 - mae: 7.2779\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 103.0001 - mae: 7.1888\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點256, epoch5, batch64 訓練集績效:\n",
      "MAE score: 7.257163047790527\n",
      "MAPE score: 26.314550638198853\n",
      "RMSE score: 10.28163067423106\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點256, epoch5, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.87469232082367\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "236/236 - 2s - 9ms/step - loss: 220.8445 - mae: 9.8946\n",
      "Epoch 2/5\n",
      "236/236 - 1s - 3ms/step - loss: 114.8684 - mae: 7.4105\n",
      "Epoch 3/5\n",
      "236/236 - 1s - 3ms/step - loss: 111.3703 - mae: 7.3191\n",
      "Epoch 4/5\n",
      "236/236 - 1s - 3ms/step - loss: 110.7819 - mae: 7.3149\n",
      "Epoch 5/5\n",
      "236/236 - 1s - 3ms/step - loss: 109.0040 - mae: 7.2481\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 105.9756 - mae: 7.1571\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點256, epoch5, batch128 訓練集績效:\n",
      "MAE score: 7.223186016082764\n",
      "MAPE score: 25.012323260307312\n",
      "RMSE score: 10.431999538913084\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點256, epoch5, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.06191051006317\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "118/118 - 2s - 18ms/step - loss: 327.6269 - mae: 12.2611\n",
      "Epoch 2/5\n",
      "118/118 - 1s - 4ms/step - loss: 117.1298 - mae: 7.5022\n",
      "Epoch 3/5\n",
      "118/118 - 0s - 4ms/step - loss: 112.4221 - mae: 7.3288\n",
      "Epoch 4/5\n",
      "118/118 - 1s - 5ms/step - loss: 110.3778 - mae: 7.2484\n",
      "Epoch 5/5\n",
      "118/118 - 0s - 4ms/step - loss: 108.4467 - mae: 7.1970\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 102.3979 - mae: 7.0017\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點256, epoch5, batch256 訓練集績效:\n",
      "MAE score: 7.08506965637207\n",
      "MAPE score: 25.822743773460388\n",
      "RMSE score: 10.290506480276152\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點256, epoch5, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.906630516052246\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "943/943 - 4s - 4ms/step - loss: 150.6959 - mae: 8.3942\n",
      "Epoch 2/10\n",
      "943/943 - 2s - 2ms/step - loss: 116.4833 - mae: 7.5328\n",
      "Epoch 3/10\n",
      "943/943 - 2s - 2ms/step - loss: 113.6293 - mae: 7.4586\n",
      "Epoch 4/10\n",
      "943/943 - 2s - 2ms/step - loss: 110.8122 - mae: 7.3532\n",
      "Epoch 5/10\n",
      "943/943 - 2s - 2ms/step - loss: 109.9952 - mae: 7.3201\n",
      "Epoch 6/10\n",
      "943/943 - 2s - 2ms/step - loss: 109.1878 - mae: 7.2844\n",
      "Epoch 7/10\n",
      "943/943 - 2s - 2ms/step - loss: 108.2407 - mae: 7.2487\n",
      "Epoch 8/10\n",
      "943/943 - 2s - 2ms/step - loss: 106.9102 - mae: 7.1718\n",
      "Epoch 9/10\n",
      "943/943 - 2s - 2ms/step - loss: 106.8845 - mae: 7.1820\n",
      "Epoch 10/10\n",
      "943/943 - 2s - 2ms/step - loss: 105.9088 - mae: 7.1510\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 107.7706 - mae: 7.5681\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點256, epoch10, batch32 訓練集績效:\n",
      "MAE score: 7.650608539581299\n",
      "MAPE score: 28.844544291496277\n",
      "RMSE score: 10.532203699050868\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點256, epoch10, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 30.42939603328705\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "472/472 - 3s - 5ms/step - loss: 180.2208 - mae: 9.0165\n",
      "Epoch 2/10\n",
      "472/472 - 1s - 3ms/step - loss: 115.5061 - mae: 7.4762\n",
      "Epoch 3/10\n",
      "472/472 - 1s - 3ms/step - loss: 112.9177 - mae: 7.3997\n",
      "Epoch 4/10\n",
      "472/472 - 1s - 3ms/step - loss: 110.1595 - mae: 7.3010\n",
      "Epoch 5/10\n",
      "472/472 - 1s - 2ms/step - loss: 109.4674 - mae: 7.2686\n",
      "Epoch 6/10\n",
      "472/472 - 1s - 2ms/step - loss: 108.5568 - mae: 7.2621\n",
      "Epoch 7/10\n",
      "472/472 - 1s - 2ms/step - loss: 107.9394 - mae: 7.2230\n",
      "Epoch 8/10\n",
      "472/472 - 1s - 2ms/step - loss: 106.7515 - mae: 7.1912\n",
      "Epoch 9/10\n",
      "472/472 - 1s - 2ms/step - loss: 106.0940 - mae: 7.1548\n",
      "Epoch 10/10\n",
      "472/472 - 1s - 2ms/step - loss: 106.0830 - mae: 7.1541\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 101.2406 - mae: 7.0958\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點256, epoch10, batch64 訓練集績效:\n",
      "MAE score: 7.168907165527344\n",
      "MAPE score: 27.01977789402008\n",
      "RMSE score: 10.20900623413338\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點256, epoch10, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.383429884910583\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "236/236 - 2s - 9ms/step - loss: 233.5680 - mae: 10.1564\n",
      "Epoch 2/10\n",
      "236/236 - 1s - 3ms/step - loss: 114.7870 - mae: 7.4134\n",
      "Epoch 3/10\n",
      "236/236 - 1s - 3ms/step - loss: 111.3928 - mae: 7.3162\n",
      "Epoch 4/10\n",
      "236/236 - 1s - 3ms/step - loss: 109.0157 - mae: 7.2215\n",
      "Epoch 5/10\n",
      "236/236 - 1s - 3ms/step - loss: 108.7033 - mae: 7.2478\n",
      "Epoch 6/10\n",
      "236/236 - 1s - 3ms/step - loss: 107.4306 - mae: 7.2038\n",
      "Epoch 7/10\n",
      "236/236 - 1s - 3ms/step - loss: 106.3852 - mae: 7.1776\n",
      "Epoch 8/10\n",
      "236/236 - 1s - 3ms/step - loss: 106.4814 - mae: 7.1735\n",
      "Epoch 9/10\n",
      "236/236 - 1s - 2ms/step - loss: 105.5649 - mae: 7.1540\n",
      "Epoch 10/10\n",
      "236/236 - 1s - 3ms/step - loss: 105.3202 - mae: 7.1372\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 100.1623 - mae: 7.0627\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點256, epoch10, batch128 訓練集績效:\n",
      "MAE score: 7.125514984130859\n",
      "MAPE score: 26.051077246665955\n",
      "RMSE score: 10.139573523226218\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點256, epoch10, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.33972179889679\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "118/118 - 2s - 16ms/step - loss: 337.1927 - mae: 12.5226\n",
      "Epoch 2/10\n",
      "118/118 - 1s - 4ms/step - loss: 116.2543 - mae: 7.4951\n",
      "Epoch 3/10\n",
      "118/118 - 0s - 4ms/step - loss: 112.2204 - mae: 7.3206\n",
      "Epoch 4/10\n",
      "118/118 - 0s - 4ms/step - loss: 109.8528 - mae: 7.2347\n",
      "Epoch 5/10\n",
      "118/118 - 1s - 5ms/step - loss: 108.3074 - mae: 7.1917\n",
      "Epoch 6/10\n",
      "118/118 - 0s - 4ms/step - loss: 107.6572 - mae: 7.1987\n",
      "Epoch 7/10\n",
      "118/118 - 1s - 5ms/step - loss: 106.5386 - mae: 7.1461\n",
      "Epoch 8/10\n",
      "118/118 - 0s - 4ms/step - loss: 106.6784 - mae: 7.1670\n",
      "Epoch 9/10\n",
      "118/118 - 1s - 5ms/step - loss: 104.9994 - mae: 7.0991\n",
      "Epoch 10/10\n",
      "118/118 - 0s - 4ms/step - loss: 104.7652 - mae: 7.0957\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 98.3839 - mae: 6.8711\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點256, epoch10, batch256 訓練集績效:\n",
      "MAE score: 6.959589958190918\n",
      "MAPE score: 25.21374821662903\n",
      "RMSE score: 10.081484117999908\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點256, epoch10, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.78853678703308\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "943/943 - 4s - 4ms/step - loss: 152.6479 - mae: 8.4265\n",
      "Epoch 2/20\n",
      "943/943 - 2s - 2ms/step - loss: 116.5403 - mae: 7.5564\n",
      "Epoch 3/20\n",
      "943/943 - 2s - 2ms/step - loss: 112.8412 - mae: 7.4083\n",
      "Epoch 4/20\n",
      "943/943 - 2s - 2ms/step - loss: 111.1322 - mae: 7.3353\n",
      "Epoch 5/20\n",
      "943/943 - 2s - 2ms/step - loss: 110.4609 - mae: 7.3405\n",
      "Epoch 6/20\n",
      "943/943 - 2s - 2ms/step - loss: 108.9959 - mae: 7.2591\n",
      "Epoch 7/20\n",
      "943/943 - 2s - 2ms/step - loss: 108.2140 - mae: 7.2521\n",
      "Epoch 8/20\n",
      "943/943 - 2s - 2ms/step - loss: 107.1566 - mae: 7.2083\n",
      "Epoch 9/20\n",
      "943/943 - 2s - 2ms/step - loss: 106.7973 - mae: 7.2004\n",
      "Epoch 10/20\n",
      "943/943 - 2s - 2ms/step - loss: 105.7911 - mae: 7.1364\n",
      "Epoch 11/20\n",
      "943/943 - 2s - 2ms/step - loss: 105.5124 - mae: 7.1262\n",
      "Epoch 12/20\n",
      "943/943 - 2s - 2ms/step - loss: 104.9322 - mae: 7.1116\n",
      "Epoch 13/20\n",
      "943/943 - 2s - 2ms/step - loss: 104.4912 - mae: 7.1151\n",
      "Epoch 14/20\n",
      "943/943 - 2s - 2ms/step - loss: 104.0591 - mae: 7.0746\n",
      "Epoch 15/20\n",
      "943/943 - 2s - 2ms/step - loss: 103.6368 - mae: 7.0792\n",
      "Epoch 16/20\n",
      "943/943 - 2s - 2ms/step - loss: 102.8199 - mae: 7.0591\n",
      "Epoch 17/20\n",
      "943/943 - 2s - 2ms/step - loss: 102.5098 - mae: 7.0469\n",
      "Epoch 18/20\n",
      "943/943 - 2s - 2ms/step - loss: 101.9378 - mae: 7.0266\n",
      "Epoch 19/20\n",
      "943/943 - 2s - 2ms/step - loss: 101.6943 - mae: 7.0046\n",
      "Epoch 20/20\n",
      "943/943 - 2s - 2ms/step - loss: 100.8819 - mae: 6.9938\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 95.1806 - mae: 6.7595\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點256, epoch20, batch32 訓練集績效:\n",
      "MAE score: 6.802661895751953\n",
      "MAPE score: 24.318990111351013\n",
      "RMSE score: 9.874215010334366\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點256, epoch20, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 27.507242560386658\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "472/472 - 3s - 5ms/step - loss: 176.7185 - mae: 8.9297\n",
      "Epoch 2/20\n",
      "472/472 - 1s - 2ms/step - loss: 114.8450 - mae: 7.4474\n",
      "Epoch 3/20\n",
      "472/472 - 1s - 3ms/step - loss: 111.5034 - mae: 7.3291\n",
      "Epoch 4/20\n",
      "472/472 - 1s - 3ms/step - loss: 110.8058 - mae: 7.3448\n",
      "Epoch 5/20\n",
      "472/472 - 1s - 3ms/step - loss: 109.5361 - mae: 7.2858\n",
      "Epoch 6/20\n",
      "472/472 - 1s - 2ms/step - loss: 107.9435 - mae: 7.2312\n",
      "Epoch 7/20\n",
      "472/472 - 1s - 2ms/step - loss: 108.0585 - mae: 7.2163\n",
      "Epoch 8/20\n",
      "472/472 - 1s - 2ms/step - loss: 107.5053 - mae: 7.2031\n",
      "Epoch 9/20\n",
      "472/472 - 1s - 2ms/step - loss: 106.9446 - mae: 7.2047\n",
      "Epoch 10/20\n",
      "472/472 - 1s - 2ms/step - loss: 106.0455 - mae: 7.1638\n",
      "Epoch 11/20\n",
      "472/472 - 1s - 2ms/step - loss: 105.7027 - mae: 7.1428\n",
      "Epoch 12/20\n",
      "472/472 - 1s - 2ms/step - loss: 104.6894 - mae: 7.1180\n",
      "Epoch 13/20\n",
      "472/472 - 1s - 2ms/step - loss: 104.2647 - mae: 7.0880\n",
      "Epoch 14/20\n",
      "472/472 - 1s - 2ms/step - loss: 103.4597 - mae: 7.0598\n",
      "Epoch 15/20\n",
      "472/472 - 1s - 2ms/step - loss: 103.7965 - mae: 7.0820\n",
      "Epoch 16/20\n",
      "472/472 - 1s - 2ms/step - loss: 102.4765 - mae: 7.0207\n",
      "Epoch 17/20\n",
      "472/472 - 1s - 2ms/step - loss: 102.5270 - mae: 7.0539\n",
      "Epoch 18/20\n",
      "472/472 - 1s - 2ms/step - loss: 101.1969 - mae: 6.9944\n",
      "Epoch 19/20\n",
      "472/472 - 1s - 2ms/step - loss: 100.9467 - mae: 6.9934\n",
      "Epoch 20/20\n",
      "472/472 - 1s - 3ms/step - loss: 100.5264 - mae: 6.9810\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 94.7910 - mae: 6.8726\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點256, epoch20, batch64 訓練集績效:\n",
      "MAE score: 6.962075710296631\n",
      "MAPE score: 24.81989711523056\n",
      "RMSE score: 9.889110286486888\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點256, epoch20, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.328177332878113\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "236/236 - 2s - 9ms/step - loss: 221.5727 - mae: 9.9555\n",
      "Epoch 2/20\n",
      "236/236 - 1s - 3ms/step - loss: 115.1038 - mae: 7.4357\n",
      "Epoch 3/20\n",
      "236/236 - 1s - 3ms/step - loss: 111.3127 - mae: 7.3061\n",
      "Epoch 4/20\n",
      "236/236 - 1s - 3ms/step - loss: 109.6495 - mae: 7.2737\n",
      "Epoch 5/20\n",
      "236/236 - 1s - 3ms/step - loss: 108.9721 - mae: 7.2506\n",
      "Epoch 6/20\n",
      "236/236 - 1s - 3ms/step - loss: 107.9374 - mae: 7.2212\n",
      "Epoch 7/20\n",
      "236/236 - 1s - 3ms/step - loss: 107.4157 - mae: 7.2158\n",
      "Epoch 8/20\n",
      "236/236 - 1s - 3ms/step - loss: 105.8299 - mae: 7.1453\n",
      "Epoch 9/20\n",
      "236/236 - 1s - 3ms/step - loss: 104.9894 - mae: 7.1040\n",
      "Epoch 10/20\n",
      "236/236 - 1s - 3ms/step - loss: 105.1121 - mae: 7.1354\n",
      "Epoch 11/20\n",
      "236/236 - 1s - 3ms/step - loss: 106.1523 - mae: 7.1808\n",
      "Epoch 12/20\n",
      "236/236 - 1s - 2ms/step - loss: 104.0541 - mae: 7.0973\n",
      "Epoch 13/20\n",
      "236/236 - 1s - 3ms/step - loss: 103.9916 - mae: 7.0947\n",
      "Epoch 14/20\n",
      "236/236 - 1s - 2ms/step - loss: 103.2807 - mae: 7.0614\n",
      "Epoch 15/20\n",
      "236/236 - 1s - 2ms/step - loss: 103.2784 - mae: 7.0726\n",
      "Epoch 16/20\n",
      "236/236 - 1s - 3ms/step - loss: 102.1957 - mae: 7.0256\n",
      "Epoch 17/20\n",
      "236/236 - 1s - 2ms/step - loss: 102.0476 - mae: 7.0230\n",
      "Epoch 18/20\n",
      "236/236 - 1s - 2ms/step - loss: 101.7478 - mae: 7.0336\n",
      "Epoch 19/20\n",
      "236/236 - 1s - 3ms/step - loss: 101.4857 - mae: 7.0202\n",
      "Epoch 20/20\n",
      "236/236 - 1s - 2ms/step - loss: 101.0510 - mae: 6.9890\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 94.3909 - mae: 6.7729\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點256, epoch20, batch128 訓練集績效:\n",
      "MAE score: 6.846904754638672\n",
      "MAPE score: 24.34685081243515\n",
      "RMSE score: 9.85349413866587\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點256, epoch20, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.340333700180054\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "118/118 - 2s - 16ms/step - loss: 330.5765 - mae: 12.3352\n",
      "Epoch 2/20\n",
      "118/118 - 0s - 4ms/step - loss: 121.0344 - mae: 7.5517\n",
      "Epoch 3/20\n",
      "118/118 - 1s - 5ms/step - loss: 112.7118 - mae: 7.3321\n",
      "Epoch 4/20\n",
      "118/118 - 0s - 3ms/step - loss: 110.3541 - mae: 7.2632\n",
      "Epoch 5/20\n",
      "118/118 - 0s - 4ms/step - loss: 108.3320 - mae: 7.1865\n",
      "Epoch 6/20\n",
      "118/118 - 1s - 6ms/step - loss: 107.5819 - mae: 7.1705\n",
      "Epoch 7/20\n",
      "118/118 - 1s - 5ms/step - loss: 106.1585 - mae: 7.1259\n",
      "Epoch 8/20\n",
      "118/118 - 0s - 4ms/step - loss: 105.9041 - mae: 7.1210\n",
      "Epoch 9/20\n",
      "118/118 - 0s - 4ms/step - loss: 105.0184 - mae: 7.0980\n",
      "Epoch 10/20\n",
      "118/118 - 1s - 5ms/step - loss: 104.6518 - mae: 7.0846\n",
      "Epoch 11/20\n",
      "118/118 - 0s - 4ms/step - loss: 103.9560 - mae: 7.0572\n",
      "Epoch 12/20\n",
      "118/118 - 1s - 5ms/step - loss: 103.6839 - mae: 7.0516\n",
      "Epoch 13/20\n",
      "118/118 - 0s - 3ms/step - loss: 103.4501 - mae: 7.0495\n",
      "Epoch 14/20\n",
      "118/118 - 1s - 4ms/step - loss: 102.7968 - mae: 7.0378\n",
      "Epoch 15/20\n",
      "118/118 - 0s - 3ms/step - loss: 102.8691 - mae: 7.0400\n",
      "Epoch 16/20\n",
      "118/118 - 0s - 3ms/step - loss: 101.8722 - mae: 7.0032\n",
      "Epoch 17/20\n",
      "118/118 - 1s - 6ms/step - loss: 102.4344 - mae: 7.0325\n",
      "Epoch 18/20\n",
      "118/118 - 0s - 3ms/step - loss: 101.7132 - mae: 6.9942\n",
      "Epoch 19/20\n",
      "118/118 - 0s - 3ms/step - loss: 101.3011 - mae: 6.9966\n",
      "Epoch 20/20\n",
      "118/118 - 1s - 4ms/step - loss: 100.7688 - mae: 6.9713\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 96.8050 - mae: 6.7803\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點256, epoch20, batch256 訓練集績效:\n",
      "MAE score: 6.8429694175720215\n",
      "MAPE score: 23.93285632133484\n",
      "RMSE score: 9.973908910139189\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點256, epoch20, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.507691621780396\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "943/943 - 8s - 9ms/step - loss: 148.4259 - mae: 8.4012\n",
      "Epoch 2/5\n",
      "943/943 - 6s - 6ms/step - loss: 118.0070 - mae: 7.6269\n",
      "Epoch 3/5\n",
      "943/943 - 6s - 6ms/step - loss: 114.4306 - mae: 7.4965\n",
      "Epoch 4/5\n",
      "943/943 - 6s - 6ms/step - loss: 111.6045 - mae: 7.3817\n",
      "Epoch 5/5\n",
      "943/943 - 6s - 6ms/step - loss: 110.5395 - mae: 7.3618\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 102.4759 - mae: 7.0686\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點512, epoch5, batch32 訓練集績效:\n",
      "MAE score: 7.138009548187256\n",
      "MAPE score: 26.11115574836731\n",
      "RMSE score: 10.270706846581591\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點512, epoch5, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.65181267261505\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "472/472 - 5s - 11ms/step - loss: 158.9056 - mae: 8.5538\n",
      "Epoch 2/5\n",
      "472/472 - 4s - 8ms/step - loss: 116.2068 - mae: 7.5561\n",
      "Epoch 3/5\n",
      "472/472 - 3s - 7ms/step - loss: 113.5791 - mae: 7.4672\n",
      "Epoch 4/5\n",
      "472/472 - 3s - 6ms/step - loss: 110.8984 - mae: 7.3435\n",
      "Epoch 5/5\n",
      "472/472 - 3s - 7ms/step - loss: 109.7758 - mae: 7.2930\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 102.5196 - mae: 7.0283\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點512, epoch5, batch64 訓練集績效:\n",
      "MAE score: 7.094332695007324\n",
      "MAPE score: 25.47907531261444\n",
      "RMSE score: 10.257134536454409\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點512, epoch5, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.143264889717102\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "236/236 - 4s - 17ms/step - loss: 183.2793 - mae: 9.0627\n",
      "Epoch 2/5\n",
      "236/236 - 2s - 10ms/step - loss: 123.5429 - mae: 7.5554\n",
      "Epoch 3/5\n",
      "236/236 - 3s - 12ms/step - loss: 118.0447 - mae: 7.6437\n",
      "Epoch 4/5\n",
      "236/236 - 2s - 9ms/step - loss: 110.2659 - mae: 7.2924\n",
      "Epoch 5/5\n",
      "236/236 - 2s - 8ms/step - loss: 108.5103 - mae: 7.2338\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 100.6306 - mae: 6.8967\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點512, epoch5, batch128 訓練集績效:\n",
      "MAE score: 6.976546764373779\n",
      "MAPE score: 25.801941752433777\n",
      "RMSE score: 10.187586122862578\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點512, epoch5, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.632461071014404\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "118/118 - 3s - 24ms/step - loss: 252.5490 - mae: 10.6953\n",
      "Epoch 2/5\n",
      "118/118 - 2s - 14ms/step - loss: 114.6708 - mae: 7.4124\n",
      "Epoch 3/5\n",
      "118/118 - 2s - 13ms/step - loss: 112.1585 - mae: 7.3371\n",
      "Epoch 4/5\n",
      "118/118 - 2s - 13ms/step - loss: 109.5649 - mae: 7.2479\n",
      "Epoch 5/5\n",
      "118/118 - 2s - 13ms/step - loss: 108.2521 - mae: 7.2237\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 102.3758 - mae: 7.0681\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點512, epoch5, batch256 訓練集績效:\n",
      "MAE score: 7.1434454917907715\n",
      "MAPE score: 25.664830207824707\n",
      "RMSE score: 10.265992876541993\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點512, epoch5, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.27173376083374\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "943/943 - 9s - 9ms/step - loss: 143.5963 - mae: 8.3120\n",
      "Epoch 2/10\n",
      "943/943 - 7s - 7ms/step - loss: 117.7518 - mae: 7.6077\n",
      "Epoch 3/10\n",
      "943/943 - 6s - 6ms/step - loss: 114.0155 - mae: 7.4663\n",
      "Epoch 4/10\n",
      "943/943 - 6s - 6ms/step - loss: 112.2238 - mae: 7.4084\n",
      "Epoch 5/10\n",
      "943/943 - 6s - 6ms/step - loss: 111.4568 - mae: 7.3817\n",
      "Epoch 6/10\n",
      "943/943 - 6s - 6ms/step - loss: 109.5455 - mae: 7.3011\n",
      "Epoch 7/10\n",
      "943/943 - 6s - 6ms/step - loss: 108.9372 - mae: 7.2732\n",
      "Epoch 8/10\n",
      "943/943 - 6s - 6ms/step - loss: 107.6588 - mae: 7.2139\n",
      "Epoch 9/10\n",
      "943/943 - 6s - 6ms/step - loss: 107.2694 - mae: 7.2151\n",
      "Epoch 10/10\n",
      "943/943 - 6s - 6ms/step - loss: 105.9898 - mae: 7.1679\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 97.9468 - mae: 6.8641\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點512, epoch10, batch32 訓練集績效:\n",
      "MAE score: 6.931684494018555\n",
      "MAPE score: 25.19831359386444\n",
      "RMSE score: 10.03489395458106\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點512, epoch10, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 27.544063329696655\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "472/472 - 5s - 11ms/step - loss: 153.4895 - mae: 8.4573\n",
      "Epoch 2/10\n",
      "472/472 - 5s - 11ms/step - loss: 115.5900 - mae: 7.4865\n",
      "Epoch 3/10\n",
      "472/472 - 3s - 7ms/step - loss: 113.2627 - mae: 7.4378\n",
      "Epoch 4/10\n",
      "472/472 - 3s - 7ms/step - loss: 112.8423 - mae: 7.4374\n",
      "Epoch 5/10\n",
      "472/472 - 3s - 6ms/step - loss: 109.9772 - mae: 7.2975\n",
      "Epoch 6/10\n",
      "472/472 - 3s - 7ms/step - loss: 108.5770 - mae: 7.2548\n",
      "Epoch 7/10\n",
      "472/472 - 3s - 7ms/step - loss: 108.2064 - mae: 7.2509\n",
      "Epoch 8/10\n",
      "472/472 - 3s - 7ms/step - loss: 107.4635 - mae: 7.2293\n",
      "Epoch 9/10\n",
      "472/472 - 3s - 7ms/step - loss: 106.1950 - mae: 7.1864\n",
      "Epoch 10/10\n",
      "472/472 - 3s - 7ms/step - loss: 105.9388 - mae: 7.1750\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 100.3735 - mae: 6.9018\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點512, epoch10, batch64 訓練集績效:\n",
      "MAE score: 6.97080659866333\n",
      "MAPE score: 24.4802787899971\n",
      "RMSE score: 10.165778658081123\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點512, epoch10, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.425976634025574\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "236/236 - 4s - 16ms/step - loss: 184.6921 - mae: 9.1397\n",
      "Epoch 2/10\n",
      "236/236 - 2s - 10ms/step - loss: 114.2641 - mae: 7.4208\n",
      "Epoch 3/10\n",
      "236/236 - 2s - 9ms/step - loss: 111.6627 - mae: 7.3500\n",
      "Epoch 4/10\n",
      "236/236 - 2s - 10ms/step - loss: 110.2500 - mae: 7.3103\n",
      "Epoch 5/10\n",
      "236/236 - 2s - 9ms/step - loss: 110.1137 - mae: 7.3263\n",
      "Epoch 6/10\n",
      "236/236 - 2s - 8ms/step - loss: 108.1068 - mae: 7.2455\n",
      "Epoch 7/10\n",
      "236/236 - 2s - 8ms/step - loss: 106.6500 - mae: 7.1718\n",
      "Epoch 8/10\n",
      "236/236 - 2s - 8ms/step - loss: 106.7623 - mae: 7.1938\n",
      "Epoch 9/10\n",
      "236/236 - 2s - 8ms/step - loss: 105.9699 - mae: 7.1721\n",
      "Epoch 10/10\n",
      "236/236 - 3s - 11ms/step - loss: 106.1045 - mae: 7.1692\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 100.0818 - mae: 6.9367\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點512, epoch10, batch128 訓練集績效:\n",
      "MAE score: 7.002331733703613\n",
      "MAPE score: 24.726766347885132\n",
      "RMSE score: 10.14453125\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點512, epoch10, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.76480519771576\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "118/118 - 3s - 24ms/step - loss: 258.9556 - mae: 10.8523\n",
      "Epoch 2/10\n",
      "118/118 - 2s - 13ms/step - loss: 115.2058 - mae: 7.4334\n",
      "Epoch 3/10\n",
      "118/118 - 2s - 13ms/step - loss: 110.9907 - mae: 7.2795\n",
      "Epoch 4/10\n",
      "118/118 - 1s - 13ms/step - loss: 109.4948 - mae: 7.2340\n",
      "Epoch 5/10\n",
      "118/118 - 2s - 13ms/step - loss: 108.2194 - mae: 7.2178\n",
      "Epoch 6/10\n",
      "118/118 - 2s - 14ms/step - loss: 107.1558 - mae: 7.1950\n",
      "Epoch 7/10\n",
      "118/118 - 1s - 11ms/step - loss: 106.4028 - mae: 7.1634\n",
      "Epoch 8/10\n",
      "118/118 - 1s - 11ms/step - loss: 106.3661 - mae: 7.1889\n",
      "Epoch 9/10\n",
      "118/118 - 1s - 10ms/step - loss: 106.8308 - mae: 7.2281\n",
      "Epoch 10/10\n",
      "118/118 - 1s - 10ms/step - loss: 105.2023 - mae: 7.1462\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 104.0041 - mae: 7.4048\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點512, epoch10, batch256 訓練集績效:\n",
      "MAE score: 7.486171245574951\n",
      "MAPE score: 28.097376227378845\n",
      "RMSE score: 10.358831837311165\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點512, epoch10, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 30.602285265922546\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "943/943 - 9s - 9ms/step - loss: 143.1324 - mae: 8.2702\n",
      "Epoch 2/20\n",
      "943/943 - 6s - 6ms/step - loss: 116.3485 - mae: 7.5668\n",
      "Epoch 3/20\n",
      "943/943 - 6s - 6ms/step - loss: 114.8182 - mae: 7.5179\n",
      "Epoch 4/20\n",
      "943/943 - 6s - 6ms/step - loss: 111.6298 - mae: 7.3772\n",
      "Epoch 5/20\n",
      "943/943 - 6s - 6ms/step - loss: 110.3008 - mae: 7.3154\n",
      "Epoch 6/20\n",
      "943/943 - 6s - 6ms/step - loss: 109.4226 - mae: 7.3015\n",
      "Epoch 7/20\n",
      "943/943 - 6s - 6ms/step - loss: 107.9065 - mae: 7.2388\n",
      "Epoch 8/20\n",
      "943/943 - 6s - 6ms/step - loss: 107.7813 - mae: 7.2271\n",
      "Epoch 9/20\n",
      "943/943 - 6s - 6ms/step - loss: 107.0587 - mae: 7.2114\n",
      "Epoch 10/20\n",
      "943/943 - 6s - 6ms/step - loss: 105.6930 - mae: 7.1387\n",
      "Epoch 11/20\n",
      "943/943 - 6s - 6ms/step - loss: 106.0708 - mae: 7.1669\n",
      "Epoch 12/20\n",
      "943/943 - 6s - 6ms/step - loss: 105.0117 - mae: 7.1356\n",
      "Epoch 13/20\n",
      "943/943 - 6s - 6ms/step - loss: 104.1390 - mae: 7.0841\n",
      "Epoch 14/20\n",
      "943/943 - 6s - 6ms/step - loss: 104.1691 - mae: 7.1050\n",
      "Epoch 15/20\n",
      "943/943 - 6s - 6ms/step - loss: 103.5136 - mae: 7.0870\n",
      "Epoch 16/20\n",
      "943/943 - 6s - 6ms/step - loss: 102.6109 - mae: 7.0566\n",
      "Epoch 17/20\n",
      "943/943 - 6s - 6ms/step - loss: 102.3370 - mae: 7.0373\n",
      "Epoch 18/20\n",
      "943/943 - 6s - 6ms/step - loss: 101.5551 - mae: 7.0081\n",
      "Epoch 19/20\n",
      "943/943 - 6s - 6ms/step - loss: 101.3420 - mae: 7.0016\n",
      "Epoch 20/20\n",
      "943/943 - 10s - 11ms/step - loss: 100.7751 - mae: 6.9775\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 95.8633 - mae: 6.7619\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點512, epoch20, batch32 訓練集績效:\n",
      "MAE score: 6.803994178771973\n",
      "MAPE score: 23.866035044193268\n",
      "RMSE score: 9.909740134026007\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點512, epoch20, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 27.774345874786377\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "472/472 - 5s - 11ms/step - loss: 161.1787 - mae: 8.6189\n",
      "Epoch 2/20\n",
      "472/472 - 4s - 8ms/step - loss: 115.6551 - mae: 7.4904\n",
      "Epoch 3/20\n",
      "472/472 - 4s - 8ms/step - loss: 113.3184 - mae: 7.4333\n",
      "Epoch 4/20\n",
      "472/472 - 3s - 7ms/step - loss: 111.0362 - mae: 7.3604\n",
      "Epoch 5/20\n",
      "472/472 - 3s - 6ms/step - loss: 110.2841 - mae: 7.3544\n",
      "Epoch 6/20\n",
      "472/472 - 3s - 7ms/step - loss: 109.1319 - mae: 7.3022\n",
      "Epoch 7/20\n",
      "472/472 - 3s - 7ms/step - loss: 107.8738 - mae: 7.2362\n",
      "Epoch 8/20\n",
      "472/472 - 3s - 7ms/step - loss: 107.4132 - mae: 7.2209\n",
      "Epoch 9/20\n",
      "472/472 - 3s - 7ms/step - loss: 107.9812 - mae: 7.2307\n",
      "Epoch 10/20\n",
      "472/472 - 3s - 6ms/step - loss: 105.9159 - mae: 7.1702\n",
      "Epoch 11/20\n",
      "472/472 - 5s - 11ms/step - loss: 105.3135 - mae: 7.1261\n",
      "Epoch 12/20\n",
      "472/472 - 3s - 7ms/step - loss: 104.9861 - mae: 7.1322\n",
      "Epoch 13/20\n",
      "472/472 - 5s - 11ms/step - loss: 104.4891 - mae: 7.1244\n",
      "Epoch 14/20\n",
      "472/472 - 3s - 6ms/step - loss: 103.5445 - mae: 7.0800\n",
      "Epoch 15/20\n",
      "472/472 - 3s - 7ms/step - loss: 103.2914 - mae: 7.0911\n",
      "Epoch 16/20\n",
      "472/472 - 3s - 7ms/step - loss: 102.4449 - mae: 7.0493\n",
      "Epoch 17/20\n",
      "472/472 - 3s - 6ms/step - loss: 102.5194 - mae: 7.0647\n",
      "Epoch 18/20\n",
      "472/472 - 3s - 7ms/step - loss: 101.3531 - mae: 7.0226\n",
      "Epoch 19/20\n",
      "472/472 - 3s - 7ms/step - loss: 101.4684 - mae: 7.0261\n",
      "Epoch 20/20\n",
      "472/472 - 3s - 6ms/step - loss: 100.5902 - mae: 7.0009\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 95.1859 - mae: 6.8028\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點512, epoch20, batch64 訓練集績效:\n",
      "MAE score: 6.853389263153076\n",
      "MAPE score: 24.63923990726471\n",
      "RMSE score: 9.871461644806345\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點512, epoch20, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 27.84152328968048\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "236/236 - 4s - 16ms/step - loss: 194.5973 - mae: 9.3155\n",
      "Epoch 2/20\n",
      "236/236 - 2s - 10ms/step - loss: 114.6571 - mae: 7.4530\n",
      "Epoch 3/20\n",
      "236/236 - 2s - 10ms/step - loss: 111.3114 - mae: 7.3141\n",
      "Epoch 4/20\n",
      "236/236 - 2s - 10ms/step - loss: 109.8791 - mae: 7.3113\n",
      "Epoch 5/20\n",
      "236/236 - 2s - 9ms/step - loss: 109.6723 - mae: 7.2840\n",
      "Epoch 6/20\n",
      "236/236 - 2s - 8ms/step - loss: 108.2755 - mae: 7.2525\n",
      "Epoch 7/20\n",
      "236/236 - 2s - 8ms/step - loss: 107.6203 - mae: 7.2373\n",
      "Epoch 8/20\n",
      "236/236 - 2s - 8ms/step - loss: 107.7451 - mae: 7.2415\n",
      "Epoch 9/20\n",
      "236/236 - 3s - 11ms/step - loss: 106.1473 - mae: 7.1630\n",
      "Epoch 10/20\n",
      "236/236 - 2s - 8ms/step - loss: 105.2921 - mae: 7.1252\n",
      "Epoch 11/20\n",
      "236/236 - 2s - 8ms/step - loss: 104.6794 - mae: 7.1183\n",
      "Epoch 12/20\n",
      "236/236 - 2s - 8ms/step - loss: 104.7636 - mae: 7.1257\n",
      "Epoch 13/20\n",
      "236/236 - 2s - 8ms/step - loss: 104.1493 - mae: 7.1044\n",
      "Epoch 14/20\n",
      "236/236 - 2s - 8ms/step - loss: 103.1198 - mae: 7.0641\n",
      "Epoch 15/20\n",
      "236/236 - 2s - 8ms/step - loss: 103.7323 - mae: 7.0989\n",
      "Epoch 16/20\n",
      "236/236 - 2s - 8ms/step - loss: 102.1138 - mae: 7.0367\n",
      "Epoch 17/20\n",
      "236/236 - 2s - 8ms/step - loss: 102.3996 - mae: 7.0466\n",
      "Epoch 18/20\n",
      "236/236 - 3s - 11ms/step - loss: 101.7287 - mae: 7.0234\n",
      "Epoch 19/20\n",
      "236/236 - 2s - 8ms/step - loss: 101.3829 - mae: 7.0269\n",
      "Epoch 20/20\n",
      "236/236 - 2s - 8ms/step - loss: 100.1008 - mae: 6.9510\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 94.0847 - mae: 6.7489\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點512, epoch20, batch128 訓練集績效:\n",
      "MAE score: 6.802763938903809\n",
      "MAPE score: 25.08603036403656\n",
      "RMSE score: 9.82634171892818\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點512, epoch20, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.509950637817383\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "118/118 - 3s - 25ms/step - loss: 263.1019 - mae: 10.8542\n",
      "Epoch 2/20\n",
      "118/118 - 2s - 13ms/step - loss: 115.3667 - mae: 7.4287\n",
      "Epoch 3/20\n",
      "118/118 - 2s - 14ms/step - loss: 112.5306 - mae: 7.3353\n",
      "Epoch 4/20\n",
      "118/118 - 3s - 22ms/step - loss: 109.6936 - mae: 7.2546\n",
      "Epoch 5/20\n",
      "118/118 - 2s - 13ms/step - loss: 108.3428 - mae: 7.2230\n",
      "Epoch 6/20\n",
      "118/118 - 2s - 13ms/step - loss: 107.5171 - mae: 7.2095\n",
      "Epoch 7/20\n",
      "118/118 - 1s - 11ms/step - loss: 106.4340 - mae: 7.1512\n",
      "Epoch 8/20\n",
      "118/118 - 1s - 10ms/step - loss: 105.7841 - mae: 7.1480\n",
      "Epoch 9/20\n",
      "118/118 - 1s - 10ms/step - loss: 106.1754 - mae: 7.1742\n",
      "Epoch 10/20\n",
      "118/118 - 1s - 11ms/step - loss: 104.4086 - mae: 7.0949\n",
      "Epoch 11/20\n",
      "118/118 - 1s - 10ms/step - loss: 104.3378 - mae: 7.0868\n",
      "Epoch 12/20\n",
      "118/118 - 1s - 10ms/step - loss: 104.3914 - mae: 7.1260\n",
      "Epoch 13/20\n",
      "118/118 - 1s - 12ms/step - loss: 103.3489 - mae: 7.0880\n",
      "Epoch 14/20\n",
      "118/118 - 1s - 10ms/step - loss: 103.0867 - mae: 7.0842\n",
      "Epoch 15/20\n",
      "118/118 - 1s - 10ms/step - loss: 103.0837 - mae: 7.0893\n",
      "Epoch 16/20\n",
      "118/118 - 1s - 11ms/step - loss: 102.6089 - mae: 7.0436\n",
      "Epoch 17/20\n",
      "118/118 - 1s - 10ms/step - loss: 102.0712 - mae: 7.0524\n",
      "Epoch 18/20\n",
      "118/118 - 1s - 10ms/step - loss: 101.2435 - mae: 7.0066\n",
      "Epoch 19/20\n",
      "118/118 - 1s - 11ms/step - loss: 101.4420 - mae: 7.0373\n",
      "Epoch 20/20\n",
      "118/118 - 1s - 10ms/step - loss: 101.1664 - mae: 7.0215\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 94.3578 - mae: 6.6102\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點512, epoch20, batch256 訓練集績效:\n",
      "MAE score: 6.695350170135498\n",
      "MAPE score: 24.23478364944458\n",
      "RMSE score: 9.868124197794911\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點512, epoch20, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.76395583152771\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "943/943 - 27s - 28ms/step - loss: 143.0946 - mae: 8.3127\n",
      "Epoch 2/5\n",
      "943/943 - 23s - 24ms/step - loss: 119.8013 - mae: 7.7093\n",
      "Epoch 3/5\n",
      "943/943 - 23s - 25ms/step - loss: 115.6115 - mae: 7.5351\n",
      "Epoch 4/5\n",
      "943/943 - 23s - 25ms/step - loss: 113.8443 - mae: 7.4761\n",
      "Epoch 5/5\n",
      "943/943 - 23s - 25ms/step - loss: 111.7950 - mae: 7.4040\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 103.1188 - mae: 7.1046\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點1024, epoch5, batch32 訓練集績效:\n",
      "MAE score: 7.1746439933776855\n",
      "MAPE score: 25.034812092781067\n",
      "RMSE score: 10.297002070891761\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點1024, epoch5, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.460222482681274\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "472/472 - 18s - 37ms/step - loss: 152.2625 - mae: 8.4692\n",
      "Epoch 2/5\n",
      "472/472 - 14s - 30ms/step - loss: 117.2204 - mae: 7.5970\n",
      "Epoch 3/5\n",
      "472/472 - 13s - 27ms/step - loss: 113.7936 - mae: 7.4772\n",
      "Epoch 4/5\n",
      "472/472 - 13s - 27ms/step - loss: 112.5039 - mae: 7.4428\n",
      "Epoch 5/5\n",
      "472/472 - 13s - 27ms/step - loss: 109.8644 - mae: 7.3176\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 103.0093 - mae: 7.1554\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點1024, epoch5, batch64 訓練集績效:\n",
      "MAE score: 7.204618453979492\n",
      "MAPE score: 25.96312165260315\n",
      "RMSE score: 10.27628658806473\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點1024, epoch5, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.640666604042053\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "236/236 - 11s - 45ms/step - loss: 178.9516 - mae: 8.9960\n",
      "Epoch 2/5\n",
      "236/236 - 10s - 44ms/step - loss: 114.6112 - mae: 7.4726\n",
      "Epoch 3/5\n",
      "236/236 - 8s - 33ms/step - loss: 112.2977 - mae: 7.3882\n",
      "Epoch 4/5\n",
      "236/236 - 7s - 31ms/step - loss: 110.4880 - mae: 7.3243\n",
      "Epoch 5/5\n",
      "236/236 - 7s - 30ms/step - loss: 110.7347 - mae: 7.3751\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 106.5950 - mae: 7.0261\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點1024, epoch5, batch128 訓練集績效:\n",
      "MAE score: 7.098246097564697\n",
      "MAPE score: 24.849212169647217\n",
      "RMSE score: 10.479727657361185\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點1024, epoch5, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.95775043964386\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/5\n",
      "118/118 - 7s - 61ms/step - loss: 218.4776 - mae: 9.9089\n",
      "Epoch 2/5\n",
      "118/118 - 6s - 50ms/step - loss: 114.8792 - mae: 7.4312\n",
      "Epoch 3/5\n",
      "118/118 - 6s - 49ms/step - loss: 111.0402 - mae: 7.3108\n",
      "Epoch 4/5\n",
      "118/118 - 6s - 48ms/step - loss: 110.3192 - mae: 7.2953\n",
      "Epoch 5/5\n",
      "118/118 - 5s - 39ms/step - loss: 108.1948 - mae: 7.2312\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 104.6767 - mae: 7.0452\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點1024, epoch5, batch256 訓練集績效:\n",
      "MAE score: 7.112067222595215\n",
      "MAPE score: 24.98064637184143\n",
      "RMSE score: 10.36651337766826\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點1024, epoch5, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.932424426078796\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "943/943 - 28s - 30ms/step - loss: 145.7608 - mae: 8.3888\n",
      "Epoch 2/10\n",
      "943/943 - 23s - 25ms/step - loss: 118.4073 - mae: 7.6534\n",
      "Epoch 3/10\n",
      "943/943 - 23s - 25ms/step - loss: 115.7306 - mae: 7.5672\n",
      "Epoch 4/10\n",
      "943/943 - 23s - 25ms/step - loss: 112.6228 - mae: 7.4233\n",
      "Epoch 5/10\n",
      "943/943 - 23s - 25ms/step - loss: 112.4565 - mae: 7.4087\n",
      "Epoch 6/10\n",
      "943/943 - 23s - 25ms/step - loss: 109.9289 - mae: 7.3275\n",
      "Epoch 7/10\n",
      "943/943 - 23s - 25ms/step - loss: 109.2886 - mae: 7.2965\n",
      "Epoch 8/10\n",
      "943/943 - 24s - 25ms/step - loss: 108.3419 - mae: 7.2548\n",
      "Epoch 9/10\n",
      "943/943 - 23s - 25ms/step - loss: 107.6051 - mae: 7.2482\n",
      "Epoch 10/10\n",
      "943/943 - 24s - 25ms/step - loss: 106.6693 - mae: 7.1951\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 99.2910 - mae: 6.9553\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點1024, epoch10, batch32 訓練集績效:\n",
      "MAE score: 7.038695812225342\n",
      "MAPE score: 25.509127974510193\n",
      "RMSE score: 10.1251409073432\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點1024, epoch10, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.19131910800934\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "472/472 - 17s - 37ms/step - loss: 151.2024 - mae: 8.3848\n",
      "Epoch 2/10\n",
      "472/472 - 15s - 31ms/step - loss: 117.4467 - mae: 7.5901\n",
      "Epoch 3/10\n",
      "472/472 - 13s - 27ms/step - loss: 114.4586 - mae: 7.5044\n",
      "Epoch 4/10\n",
      "472/472 - 13s - 27ms/step - loss: 112.3677 - mae: 7.4345\n",
      "Epoch 5/10\n",
      "472/472 - 13s - 28ms/step - loss: 110.2220 - mae: 7.3478\n",
      "Epoch 6/10\n",
      "472/472 - 13s - 27ms/step - loss: 110.1731 - mae: 7.3413\n",
      "Epoch 7/10\n",
      "472/472 - 13s - 27ms/step - loss: 109.3086 - mae: 7.3156\n",
      "Epoch 8/10\n",
      "472/472 - 13s - 27ms/step - loss: 107.6655 - mae: 7.2369\n",
      "Epoch 9/10\n",
      "472/472 - 13s - 27ms/step - loss: 107.1994 - mae: 7.2098\n",
      "Epoch 10/10\n",
      "472/472 - 13s - 28ms/step - loss: 107.0023 - mae: 7.2185\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 100.6605 - mae: 6.9574\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點1024, epoch10, batch64 訓練集績效:\n",
      "MAE score: 7.043174743652344\n",
      "MAPE score: 24.37189370393753\n",
      "RMSE score: 10.193334114202749\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點1024, epoch10, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.162959218025208\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "236/236 - 11s - 45ms/step - loss: 167.9131 - mae: 8.7764\n",
      "Epoch 2/10\n",
      "236/236 - 9s - 39ms/step - loss: 116.6500 - mae: 7.5701\n",
      "Epoch 3/10\n",
      "236/236 - 9s - 37ms/step - loss: 113.5805 - mae: 7.4758\n",
      "Epoch 4/10\n",
      "236/236 - 7s - 30ms/step - loss: 110.3279 - mae: 7.3349\n",
      "Epoch 5/10\n",
      "236/236 - 7s - 31ms/step - loss: 109.8491 - mae: 7.3132\n",
      "Epoch 6/10\n",
      "236/236 - 7s - 30ms/step - loss: 108.4763 - mae: 7.2568\n",
      "Epoch 7/10\n",
      "236/236 - 7s - 30ms/step - loss: 107.4936 - mae: 7.2143\n",
      "Epoch 8/10\n",
      "236/236 - 7s - 31ms/step - loss: 106.5023 - mae: 7.1831\n",
      "Epoch 9/10\n",
      "236/236 - 7s - 30ms/step - loss: 107.9838 - mae: 7.2721\n",
      "Epoch 10/10\n",
      "236/236 - 8s - 32ms/step - loss: 106.2909 - mae: 7.1875\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 100.2106 - mae: 7.0912\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點1024, epoch10, batch128 訓練集績效:\n",
      "MAE score: 7.15434455871582\n",
      "MAPE score: 25.94008445739746\n",
      "RMSE score: 10.147506753412232\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點1024, epoch10, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.919005393981934\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/10\n",
      "118/118 - 7s - 61ms/step - loss: 217.2999 - mae: 9.9231\n",
      "Epoch 2/10\n",
      "118/118 - 6s - 49ms/step - loss: 113.9879 - mae: 7.3739\n",
      "Epoch 3/10\n",
      "118/118 - 6s - 49ms/step - loss: 112.3827 - mae: 7.3552\n",
      "Epoch 4/10\n",
      "118/118 - 6s - 50ms/step - loss: 109.6447 - mae: 7.2772\n",
      "Epoch 5/10\n",
      "118/118 - 5s - 40ms/step - loss: 109.7688 - mae: 7.2991\n",
      "Epoch 6/10\n",
      "118/118 - 4s - 38ms/step - loss: 107.8808 - mae: 7.2388\n",
      "Epoch 7/10\n",
      "118/118 - 5s - 39ms/step - loss: 107.0300 - mae: 7.1897\n",
      "Epoch 8/10\n",
      "118/118 - 5s - 41ms/step - loss: 105.7941 - mae: 7.1487\n",
      "Epoch 9/10\n",
      "118/118 - 5s - 39ms/step - loss: 108.5061 - mae: 7.3005\n",
      "Epoch 10/10\n",
      "118/118 - 4s - 38ms/step - loss: 105.1026 - mae: 7.1221\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 98.8817 - mae: 6.9098\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點1024, epoch10, batch256 訓練集績效:\n",
      "MAE score: 6.969263076782227\n",
      "MAPE score: 25.120076537132263\n",
      "RMSE score: 10.088077994690224\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點1024, epoch10, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 29.284897446632385\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "943/943 - 30s - 31ms/step - loss: 141.9707 - mae: 8.3809\n",
      "Epoch 2/20\n",
      "943/943 - 24s - 25ms/step - loss: 119.5519 - mae: 7.7169\n",
      "Epoch 3/20\n",
      "943/943 - 23s - 25ms/step - loss: 115.5939 - mae: 7.5689\n",
      "Epoch 4/20\n",
      "943/943 - 23s - 25ms/step - loss: 113.7558 - mae: 7.5020\n",
      "Epoch 5/20\n",
      "943/943 - 23s - 25ms/step - loss: 111.2308 - mae: 7.3778\n",
      "Epoch 6/20\n",
      "943/943 - 25s - 26ms/step - loss: 109.7460 - mae: 7.3047\n",
      "Epoch 7/20\n",
      "943/943 - 23s - 25ms/step - loss: 109.1163 - mae: 7.2853\n",
      "Epoch 8/20\n",
      "943/943 - 25s - 27ms/step - loss: 107.9031 - mae: 7.2370\n",
      "Epoch 9/20\n",
      "943/943 - 23s - 25ms/step - loss: 107.2381 - mae: 7.2245\n",
      "Epoch 10/20\n",
      "943/943 - 23s - 25ms/step - loss: 106.5913 - mae: 7.1939\n",
      "Epoch 11/20\n",
      "943/943 - 23s - 25ms/step - loss: 106.0126 - mae: 7.1591\n",
      "Epoch 12/20\n",
      "943/943 - 23s - 25ms/step - loss: 105.5508 - mae: 7.1535\n",
      "Epoch 13/20\n",
      "943/943 - 23s - 25ms/step - loss: 104.8090 - mae: 7.1387\n",
      "Epoch 14/20\n",
      "943/943 - 23s - 25ms/step - loss: 104.1164 - mae: 7.0909\n",
      "Epoch 15/20\n",
      "943/943 - 23s - 25ms/step - loss: 103.3583 - mae: 7.0684\n",
      "Epoch 16/20\n",
      "943/943 - 23s - 25ms/step - loss: 103.1598 - mae: 7.0726\n",
      "Epoch 17/20\n",
      "943/943 - 23s - 25ms/step - loss: 102.6122 - mae: 7.0440\n",
      "Epoch 18/20\n",
      "943/943 - 23s - 25ms/step - loss: 101.9992 - mae: 7.0212\n",
      "Epoch 19/20\n",
      "943/943 - 24s - 25ms/step - loss: 101.1821 - mae: 6.9888\n",
      "Epoch 20/20\n",
      "943/943 - 23s - 25ms/step - loss: 101.5208 - mae: 7.0303\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 94.4868 - mae: 6.7603\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點1024, epoch20, batch32 訓練集績效:\n",
      "MAE score: 6.804990768432617\n",
      "MAPE score: 24.60503578186035\n",
      "RMSE score: 9.828306648261725\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點1024, epoch20, batch32 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 27.2238552570343\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "472/472 - 17s - 36ms/step - loss: 152.8581 - mae: 8.3900\n",
      "Epoch 2/20\n",
      "472/472 - 18s - 39ms/step - loss: 118.8659 - mae: 7.6673\n",
      "Epoch 3/20\n",
      "472/472 - 13s - 27ms/step - loss: 114.2657 - mae: 7.4916\n",
      "Epoch 4/20\n",
      "472/472 - 13s - 27ms/step - loss: 112.0903 - mae: 7.4262\n",
      "Epoch 5/20\n",
      "472/472 - 13s - 27ms/step - loss: 110.9434 - mae: 7.3602\n",
      "Epoch 6/20\n",
      "472/472 - 13s - 27ms/step - loss: 110.3464 - mae: 7.3475\n",
      "Epoch 7/20\n",
      "472/472 - 13s - 27ms/step - loss: 108.9419 - mae: 7.2912\n",
      "Epoch 8/20\n",
      "472/472 - 13s - 27ms/step - loss: 107.5550 - mae: 7.2239\n",
      "Epoch 9/20\n",
      "472/472 - 13s - 27ms/step - loss: 106.9183 - mae: 7.1924\n",
      "Epoch 10/20\n",
      "472/472 - 13s - 27ms/step - loss: 106.5097 - mae: 7.1842\n",
      "Epoch 11/20\n",
      "472/472 - 13s - 27ms/step - loss: 104.8614 - mae: 7.1086\n",
      "Epoch 12/20\n",
      "472/472 - 13s - 27ms/step - loss: 105.2564 - mae: 7.1442\n",
      "Epoch 13/20\n",
      "472/472 - 13s - 27ms/step - loss: 103.9184 - mae: 7.0875\n",
      "Epoch 14/20\n",
      "472/472 - 13s - 27ms/step - loss: 103.4015 - mae: 7.0689\n",
      "Epoch 15/20\n",
      "472/472 - 13s - 27ms/step - loss: 103.0024 - mae: 7.0606\n",
      "Epoch 16/20\n",
      "472/472 - 13s - 27ms/step - loss: 102.2970 - mae: 7.0539\n",
      "Epoch 17/20\n",
      "472/472 - 13s - 27ms/step - loss: 101.8693 - mae: 7.0206\n",
      "Epoch 18/20\n",
      "472/472 - 13s - 27ms/step - loss: 100.8669 - mae: 6.9736\n",
      "Epoch 19/20\n",
      "472/472 - 13s - 27ms/step - loss: 101.5741 - mae: 7.0300\n",
      "Epoch 20/20\n",
      "472/472 - 13s - 27ms/step - loss: 99.9552 - mae: 6.9258\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 93.8035 - mae: 6.6345\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點1024, epoch20, batch64 訓練集績效:\n",
      "MAE score: 6.6848039627075195\n",
      "MAPE score: 24.18152242898941\n",
      "RMSE score: 9.82054556704336\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點1024, epoch20, batch64 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 27.840682864189148\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "236/236 - 10s - 44ms/step - loss: 169.3660 - mae: 8.8604\n",
      "Epoch 2/20\n",
      "236/236 - 9s - 38ms/step - loss: 114.7909 - mae: 7.4889\n",
      "Epoch 3/20\n",
      "236/236 - 9s - 38ms/step - loss: 112.8865 - mae: 7.4170\n",
      "Epoch 4/20\n",
      "236/236 - 7s - 31ms/step - loss: 111.7269 - mae: 7.3799\n",
      "Epoch 5/20\n",
      "236/236 - 7s - 31ms/step - loss: 109.3502 - mae: 7.2691\n",
      "Epoch 6/20\n",
      "236/236 - 7s - 30ms/step - loss: 110.0366 - mae: 7.3544\n",
      "Epoch 7/20\n",
      "236/236 - 7s - 30ms/step - loss: 108.2173 - mae: 7.2566\n",
      "Epoch 8/20\n",
      "236/236 - 7s - 31ms/step - loss: 107.1306 - mae: 7.2218\n",
      "Epoch 9/20\n",
      "236/236 - 7s - 30ms/step - loss: 106.6901 - mae: 7.2021\n",
      "Epoch 10/20\n",
      "236/236 - 7s - 31ms/step - loss: 105.8134 - mae: 7.1888\n",
      "Epoch 11/20\n",
      "236/236 - 7s - 30ms/step - loss: 104.9468 - mae: 7.1211\n",
      "Epoch 12/20\n",
      "236/236 - 7s - 31ms/step - loss: 104.7122 - mae: 7.1351\n",
      "Epoch 13/20\n",
      "236/236 - 7s - 30ms/step - loss: 104.2264 - mae: 7.1131\n",
      "Epoch 14/20\n",
      "236/236 - 7s - 31ms/step - loss: 103.7413 - mae: 7.0904\n",
      "Epoch 15/20\n",
      "236/236 - 7s - 30ms/step - loss: 104.6568 - mae: 7.1396\n",
      "Epoch 16/20\n",
      "236/236 - 7s - 31ms/step - loss: 102.8079 - mae: 7.0437\n",
      "Epoch 17/20\n",
      "236/236 - 7s - 30ms/step - loss: 102.4159 - mae: 7.0472\n",
      "Epoch 18/20\n",
      "236/236 - 7s - 31ms/step - loss: 102.4680 - mae: 7.0505\n",
      "Epoch 19/20\n",
      "236/236 - 7s - 30ms/step - loss: 101.5289 - mae: 7.0175\n",
      "Epoch 20/20\n",
      "236/236 - 8s - 32ms/step - loss: 101.6510 - mae: 7.0526\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 96.7392 - mae: 6.8268\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點1024, epoch20, batch128 訓練集績效:\n",
      "MAE score: 6.893186569213867\n",
      "MAPE score: 23.682789504528046\n",
      "RMSE score: 9.973672542345351\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點1024, epoch20, batch128 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 27.86964476108551\n",
      "RMSE score: 14.235763666311897\n",
      "Epoch 1/20\n",
      "118/118 - 7s - 62ms/step - loss: 215.1281 - mae: 9.8732\n",
      "Epoch 2/20\n",
      "118/118 - 6s - 49ms/step - loss: 114.6962 - mae: 7.4482\n",
      "Epoch 3/20\n",
      "118/118 - 6s - 49ms/step - loss: 110.2156 - mae: 7.2638\n",
      "Epoch 4/20\n",
      "118/118 - 6s - 49ms/step - loss: 109.6296 - mae: 7.2751\n",
      "Epoch 5/20\n",
      "118/118 - 5s - 43ms/step - loss: 108.8232 - mae: 7.2521\n",
      "Epoch 6/20\n",
      "118/118 - 4s - 38ms/step - loss: 107.5990 - mae: 7.2260\n",
      "Epoch 7/20\n",
      "118/118 - 4s - 38ms/step - loss: 106.7867 - mae: 7.1887\n",
      "Epoch 8/20\n",
      "118/118 - 5s - 40ms/step - loss: 105.5367 - mae: 7.1439\n",
      "Epoch 9/20\n",
      "118/118 - 5s - 39ms/step - loss: 106.4994 - mae: 7.1792\n",
      "Epoch 10/20\n",
      "118/118 - 5s - 39ms/step - loss: 105.3315 - mae: 7.1312\n",
      "Epoch 11/20\n",
      "118/118 - 5s - 39ms/step - loss: 105.0793 - mae: 7.1282\n",
      "Epoch 12/20\n",
      "118/118 - 4s - 38ms/step - loss: 103.1697 - mae: 7.0528\n",
      "Epoch 13/20\n",
      "118/118 - 4s - 38ms/step - loss: 105.5779 - mae: 7.1870\n",
      "Epoch 14/20\n",
      "118/118 - 5s - 39ms/step - loss: 102.8866 - mae: 7.0335\n",
      "Epoch 15/20\n",
      "118/118 - 4s - 38ms/step - loss: 103.0962 - mae: 7.0693\n",
      "Epoch 16/20\n",
      "118/118 - 5s - 38ms/step - loss: 102.9397 - mae: 7.0592\n",
      "Epoch 17/20\n",
      "118/118 - 5s - 39ms/step - loss: 101.1056 - mae: 6.9841\n",
      "Epoch 18/20\n",
      "118/118 - 5s - 39ms/step - loss: 101.2563 - mae: 6.9963\n",
      "Epoch 19/20\n",
      "118/118 - 5s - 38ms/step - loss: 101.1333 - mae: 7.0016\n",
      "Epoch 20/20\n",
      "118/118 - 5s - 39ms/step - loss: 99.9882 - mae: 6.9574\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 95.2164 - mae: 6.7399\n",
      "\u001b[1m943/943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點1024, epoch20, batch256 訓練集績效:\n",
      "MAE score: 6.788782119750977\n",
      "MAPE score: 24.26292896270752\n",
      "RMSE score: 9.88533155580842\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
      "--------------------------------------------------\n",
      "隱藏層3, 節點1024, epoch20, batch256 測試集績效:\n",
      "MAE score: 8.814265251159668\n",
      "MAPE score: 28.714075684547424\n",
      "RMSE score: 14.235763666311897\n",
      "==================================================\n",
      "Completed batch for layer 3\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def create_model(input_size, layer_number, unites_number, activation, optimizer):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=(input_size,)))\n",
    "    for i in range(layer_number):\n",
    "        model.add(layers.Dense(unites_number, activation=activation))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "layers_to_test = [1, 2, 3]\n",
    "unites_number = [64, 128, 256, 512, 1024]\n",
    "epochs_to_test = [5, 10, 20]\n",
    "batch_size = [32, 64, 128, 256]\n",
    "\n",
    "all_record = []\n",
    "\n",
    "activation = 'relu'\n",
    "optimizer = 'adam'\n",
    "input_size = train_features.shape[1]\n",
    "\n",
    "for lay in layers_to_test:\n",
    "    for unit in unites_number:\n",
    "        for epo in epochs_to_test:\n",
    "            for bat in batch_size:\n",
    "                test_model = create_model(input_size, lay, unit, activation, optimizer)\n",
    "                history = test_model.fit(train_features, train_target, epochs=epo, batch_size=bat, verbose=2)\n",
    "                train_mse_score, train_mae_score = test_model.evaluate(train_features, train_target)\n",
    "                \n",
    "                train_predict = test_model.predict(train_features)\n",
    "                train_mape_score = mean_absolute_percentage_error(train_target, train_predict)\n",
    "                train_rmse_score = math.sqrt(train_mse_score)\n",
    "                \n",
    "                print(\"-\"*50)\n",
    "                print(f\"隱藏層{lay}, 節點{unit}, epoch{epo}, batch{bat} 訓練集績效:\")\n",
    "                print(\"MAE score:\", train_mae_score)\n",
    "                print(\"MAPE score:\", train_mape_score)\n",
    "                print(\"RMSE score:\", train_rmse_score)\n",
    "\n",
    "                test_prediction = test_model.predict(test_features)      \n",
    "                test_mape_score = mean_absolute_percentage_error(test_target, test_prediction)\n",
    "                test_rmse_score = math.sqrt(test_mse_score)\n",
    "                \n",
    "                print(\"-\"*50)\n",
    "                print(f\"隱藏層{lay}, 節點{unit}, epoch{epo}, batch{bat} 測試集績效:\")\n",
    "                print(\"MAE score:\", test_mae_score)\n",
    "                print(\"MAPE score:\", test_mape_score)\n",
    "                print(\"RMSE score:\", test_rmse_score)\n",
    "\n",
    "                current_result = {\"layer\": lay,\n",
    "                                  \"units\": unit,\n",
    "                                  \"epochs\": epo,\n",
    "                                  \"batch_size\": bat,\n",
    "                                  \"activation\": activation,\n",
    "                                  \"optimizer\": optimizer,\n",
    "                                  \"train_mae\": train_mae_score,\n",
    "                                  \"train_mape\": train_mape_score,\n",
    "                                  \"train_rmse\": train_rmse_score,\n",
    "                                  \"test_mae\": test_mae_score,\n",
    "                                  \"test_mape\": test_mape_score,\n",
    "                                  \"test_rmse\": test_rmse_score\n",
    "                                 }\n",
    "                \n",
    "                all_record.append(current_result)\n",
    "                K.clear_session()\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Completed batch for layer {lay}\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d9eaa6b-f083-4045-a896-50a954a755a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'layer': 1, 'units': 64, 'epochs': 5, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.222611904144287, 'train_mape': 26.867493987083435, 'train_rmse': 10.513422787837476, 'test_mae': 8.814265251159668, 'test_mape': 30.203649401664734, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 64, 'epochs': 5, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.421987056732178, 'train_mape': 27.84073054790497, 'train_rmse': 10.702857689408308, 'test_mae': 8.814265251159668, 'test_mape': 30.5501788854599, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 64, 'epochs': 5, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.647298336029053, 'train_mape': 28.31076681613922, 'train_rmse': 10.895463653964583, 'test_mae': 8.814265251159668, 'test_mape': 30.916696786880493, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 64, 'epochs': 5, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 8.118735313415527, 'train_mape': 29.46229577064514, 'train_rmse': 11.379989703396662, 'test_mae': 8.814265251159668, 'test_mape': 32.13045299053192, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 64, 'epochs': 10, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.028019905090332, 'train_mape': 25.865256786346436, 'train_rmse': 10.265083937415588, 'test_mae': 8.814265251159668, 'test_mape': 28.877708315849304, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 64, 'epochs': 10, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.11116886138916, 'train_mape': 26.319333910942078, 'train_rmse': 10.364886030572542, 'test_mae': 8.814265251159668, 'test_mape': 29.305025935173035, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 64, 'epochs': 10, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.354572296142578, 'train_mape': 27.23422348499298, 'train_rmse': 10.565355264853075, 'test_mae': 8.814265251159668, 'test_mape': 30.288007855415344, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 64, 'epochs': 10, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.604226589202881, 'train_mape': 28.191977739334106, 'train_rmse': 10.839044874841516, 'test_mae': 8.814265251159668, 'test_mape': 30.60816526412964, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 64, 'epochs': 20, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.949417591094971, 'train_mape': 25.39319097995758, 'train_rmse': 10.110911044795207, 'test_mae': 8.814265251159668, 'test_mape': 28.42545211315155, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 64, 'epochs': 20, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.968047618865967, 'train_mape': 25.477999448776245, 'train_rmse': 10.148047318567391, 'test_mae': 8.814265251159668, 'test_mape': 28.289160132408142, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 64, 'epochs': 20, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.038013935089111, 'train_mape': 25.820007920265198, 'train_rmse': 10.23214953737842, 'test_mae': 8.814265251159668, 'test_mape': 28.865617513656616, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 64, 'epochs': 20, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.290943145751953, 'train_mape': 26.922112703323364, 'train_rmse': 10.502598395591543, 'test_mae': 8.814265251159668, 'test_mape': 29.56104576587677, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 128, 'epochs': 5, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.064770698547363, 'train_mape': 26.30406618118286, 'train_rmse': 10.402760330092757, 'test_mae': 8.814265251159668, 'test_mape': 29.524481296539307, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 128, 'epochs': 5, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.220568656921387, 'train_mape': 26.94985568523407, 'train_rmse': 10.534756492693676, 'test_mae': 8.814265251159668, 'test_mape': 30.033284425735474, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 128, 'epochs': 5, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.490508556365967, 'train_mape': 27.925828099250793, 'train_rmse': 10.742990026840612, 'test_mae': 8.814265251159668, 'test_mape': 30.72434365749359, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 128, 'epochs': 5, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.786827564239502, 'train_mape': 28.723829984664917, 'train_rmse': 11.022013744652321, 'test_mae': 8.814265251159668, 'test_mape': 31.582802534103394, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 128, 'epochs': 10, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.095277786254883, 'train_mape': 25.828048586845398, 'train_rmse': 10.193871874989942, 'test_mae': 8.814265251159668, 'test_mape': 29.000866413116455, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 128, 'epochs': 10, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.043642044067383, 'train_mape': 25.845202803611755, 'train_rmse': 10.253259652232247, 'test_mae': 8.814265251159668, 'test_mape': 28.823009133338928, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 128, 'epochs': 10, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.164577960968018, 'train_mape': 26.71564221382141, 'train_rmse': 10.44126120772343, 'test_mae': 8.814265251159668, 'test_mape': 29.501613974571228, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 128, 'epochs': 10, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.4119181632995605, 'train_mape': 27.51193940639496, 'train_rmse': 10.663534857024318, 'test_mae': 8.814265251159668, 'test_mape': 30.415084958076477, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 128, 'epochs': 20, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.895312309265137, 'train_mape': 25.157254934310913, 'train_rmse': 10.040301555953022, 'test_mae': 8.814265251159668, 'test_mape': 28.29425036907196, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 128, 'epochs': 20, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.963493824005127, 'train_mape': 25.177636742591858, 'train_rmse': 10.078141276028523, 'test_mae': 8.814265251159668, 'test_mape': 27.83121168613434, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 128, 'epochs': 20, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.979163646697998, 'train_mape': 25.66448748111725, 'train_rmse': 10.148163848312043, 'test_mae': 8.814265251159668, 'test_mape': 28.52734625339508, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 128, 'epochs': 20, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.054036617279053, 'train_mape': 26.108813285827637, 'train_rmse': 10.313966958872369, 'test_mae': 8.814265251159668, 'test_mape': 28.813469409942627, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 256, 'epochs': 5, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.139409065246582, 'train_mape': 26.3208270072937, 'train_rmse': 10.334130369231909, 'test_mae': 8.814265251159668, 'test_mape': 29.44004237651825, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 256, 'epochs': 5, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.224432468414307, 'train_mape': 26.961377263069153, 'train_rmse': 10.429957788515486, 'test_mae': 8.814265251159668, 'test_mape': 29.834452271461487, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 256, 'epochs': 5, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.33009672164917, 'train_mape': 27.419084310531616, 'train_rmse': 10.610794803860308, 'test_mae': 8.814265251159668, 'test_mape': 30.28758466243744, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 256, 'epochs': 5, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.517463207244873, 'train_mape': 27.96047031879425, 'train_rmse': 10.789132506787718, 'test_mae': 8.814265251159668, 'test_mape': 30.792030692100525, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 256, 'epochs': 10, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.047982215881348, 'train_mape': 25.101807713508606, 'train_rmse': 10.180927051834013, 'test_mae': 8.814265251159668, 'test_mape': 27.764949202537537, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 256, 'epochs': 10, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.012208461761475, 'train_mape': 25.496739149093628, 'train_rmse': 10.194585103361858, 'test_mae': 8.814265251159668, 'test_mape': 28.342685103416443, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 256, 'epochs': 10, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.042294979095459, 'train_mape': 26.16422474384308, 'train_rmse': 10.299470195292132, 'test_mae': 8.814265251159668, 'test_mape': 28.782758116722107, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 256, 'epochs': 10, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.2950119972229, 'train_mape': 27.344664931297302, 'train_rmse': 10.537040046979994, 'test_mae': 8.814265251159668, 'test_mape': 30.035483837127686, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 256, 'epochs': 20, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.861979007720947, 'train_mape': 24.91055130958557, 'train_rmse': 10.001296531550883, 'test_mae': 8.814265251159668, 'test_mape': 28.15156579017639, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 256, 'epochs': 20, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.901322841644287, 'train_mape': 25.18732249736786, 'train_rmse': 10.020196356457925, 'test_mae': 8.814265251159668, 'test_mape': 28.56670320034027, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 256, 'epochs': 20, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.938536643981934, 'train_mape': 25.27083456516266, 'train_rmse': 10.085078527157128, 'test_mae': 8.814265251159668, 'test_mape': 28.478631377220154, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 256, 'epochs': 20, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.070056438446045, 'train_mape': 26.046672463417053, 'train_rmse': 10.196155825992935, 'test_mae': 8.814265251159668, 'test_mape': 28.750687837600708, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 512, 'epochs': 5, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.128464221954346, 'train_mape': 26.534143090248108, 'train_rmse': 10.315096441604867, 'test_mae': 8.814265251159668, 'test_mape': 29.697805643081665, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 512, 'epochs': 5, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.1969499588012695, 'train_mape': 27.091798186302185, 'train_rmse': 10.385954806900354, 'test_mae': 8.814265251159668, 'test_mape': 29.63515818119049, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 512, 'epochs': 5, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.210919380187988, 'train_mape': 26.81327760219574, 'train_rmse': 10.492344563232459, 'test_mae': 8.814265251159668, 'test_mape': 29.94937002658844, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 512, 'epochs': 5, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.330744743347168, 'train_mape': 27.468600869178772, 'train_rmse': 10.64775646380036, 'test_mae': 8.814265251159668, 'test_mape': 30.483970046043396, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 512, 'epochs': 10, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.0675458908081055, 'train_mape': 26.003101468086243, 'train_rmse': 10.16571373981403, 'test_mae': 8.814265251159668, 'test_mape': 28.685715794563293, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 512, 'epochs': 10, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.907339572906494, 'train_mape': 24.757401645183563, 'train_rmse': 10.150599013819601, 'test_mae': 8.814265251159668, 'test_mape': 28.07656228542328, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 512, 'epochs': 10, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.013269424438477, 'train_mape': 25.38980543613434, 'train_rmse': 10.214761217998326, 'test_mae': 8.814265251159668, 'test_mape': 28.609350323677063, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 512, 'epochs': 10, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.121380805969238, 'train_mape': 26.45319104194641, 'train_rmse': 10.397882436702218, 'test_mae': 8.814265251159668, 'test_mape': 29.55872416496277, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 512, 'epochs': 20, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.818526744842529, 'train_mape': 24.616242945194244, 'train_rmse': 9.984856774492506, 'test_mae': 8.814265251159668, 'test_mape': 27.575653791427612, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 512, 'epochs': 20, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.961170673370361, 'train_mape': 25.484171509742737, 'train_rmse': 9.988876641303355, 'test_mae': 8.814265251159668, 'test_mape': 27.950018644332886, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 512, 'epochs': 20, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.902624607086182, 'train_mape': 25.52625834941864, 'train_rmse': 10.017165900138544, 'test_mae': 8.814265251159668, 'test_mape': 28.48295569419861, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 512, 'epochs': 20, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.939386367797852, 'train_mape': 25.498291850090027, 'train_rmse': 10.11187873506869, 'test_mae': 8.814265251159668, 'test_mape': 28.883644938468933, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 1024, 'epochs': 5, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.035341739654541, 'train_mape': 25.87983012199402, 'train_rmse': 10.403912439220582, 'test_mae': 8.814265251159668, 'test_mape': 29.411974549293518, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 1024, 'epochs': 5, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.179378986358643, 'train_mape': 26.392674446105957, 'train_rmse': 10.306542727706846, 'test_mae': 8.814265251159668, 'test_mape': 28.787818551063538, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 1024, 'epochs': 5, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.155813217163086, 'train_mape': 26.7225980758667, 'train_rmse': 10.397544174742546, 'test_mae': 8.814265251159668, 'test_mape': 29.574838280677795, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 1024, 'epochs': 5, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.264667987823486, 'train_mape': 27.147620916366577, 'train_rmse': 10.553978004581563, 'test_mae': 8.814265251159668, 'test_mape': 30.13041615486145, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 1024, 'epochs': 10, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.083189487457275, 'train_mape': 25.010675191879272, 'train_rmse': 10.235290765922983, 'test_mae': 8.814265251159668, 'test_mape': 28.36005389690399, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 1024, 'epochs': 10, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.117006778717041, 'train_mape': 26.321572065353394, 'train_rmse': 10.163582464283978, 'test_mae': 8.814265251159668, 'test_mape': 28.46217453479767, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 1024, 'epochs': 10, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.973602771759033, 'train_mape': 25.512436032295227, 'train_rmse': 10.161572373436403, 'test_mae': 8.814265251159668, 'test_mape': 28.437641263008118, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 1024, 'epochs': 10, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.02797794342041, 'train_mape': 26.10924541950226, 'train_rmse': 10.272085447508601, 'test_mae': 8.814265251159668, 'test_mape': 29.191669821739197, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 1024, 'epochs': 20, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.817963123321533, 'train_mape': 24.844667315483093, 'train_rmse': 9.965610882858847, 'test_mae': 8.814265251159668, 'test_mape': 27.620825171470642, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 1024, 'epochs': 20, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.868446350097656, 'train_mape': 24.699674546718597, 'train_rmse': 9.996110922831088, 'test_mae': 8.814265251159668, 'test_mape': 27.43844985961914, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 1024, 'epochs': 20, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.838010311126709, 'train_mape': 25.042825937271118, 'train_rmse': 9.951021028972, 'test_mae': 8.814265251159668, 'test_mape': 27.915215492248535, 'test_rmse': 14.235763666311897}, {'layer': 1, 'units': 1024, 'epochs': 20, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.903898239135742, 'train_mape': 25.416848063468933, 'train_rmse': 10.038055108137428, 'test_mae': 8.814265251159668, 'test_mape': 28.417304158210754, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 64, 'epochs': 5, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.32235050201416, 'train_mape': 27.779439091682434, 'train_rmse': 10.522661368813255, 'test_mae': 8.814265251159668, 'test_mape': 31.095123291015625, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 64, 'epochs': 5, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.237822532653809, 'train_mape': 27.277424931526184, 'train_rmse': 10.52887062790776, 'test_mae': 8.814265251159668, 'test_mape': 31.02101981639862, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 64, 'epochs': 5, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.272233009338379, 'train_mape': 27.055230736732483, 'train_rmse': 10.599527859519336, 'test_mae': 8.814265251159668, 'test_mape': 31.213131546974182, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 64, 'epochs': 5, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.392140865325928, 'train_mape': 27.74980664253235, 'train_rmse': 10.680265063593378, 'test_mae': 8.814265251159668, 'test_mape': 31.11148476600647, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 64, 'epochs': 10, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.018354415893555, 'train_mape': 25.579825043678284, 'train_rmse': 10.216838879609217, 'test_mae': 8.814265251159668, 'test_mape': 29.487508535385132, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 64, 'epochs': 10, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.145233154296875, 'train_mape': 25.219255685806274, 'train_rmse': 10.379192194734346, 'test_mae': 8.814265251159668, 'test_mape': 30.55315613746643, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 64, 'epochs': 10, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.116014003753662, 'train_mape': 26.275604963302612, 'train_rmse': 10.413264296234042, 'test_mae': 8.814265251159668, 'test_mape': 30.223822593688965, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 64, 'epochs': 10, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.180125713348389, 'train_mape': 26.79232954978943, 'train_rmse': 10.429299793823798, 'test_mae': 8.814265251159668, 'test_mape': 30.47488033771515, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 64, 'epochs': 20, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.863498687744141, 'train_mape': 24.32691901922226, 'train_rmse': 10.10774172954047, 'test_mae': 8.814265251159668, 'test_mape': 29.35676872730255, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 64, 'epochs': 20, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.987977981567383, 'train_mape': 25.99422335624695, 'train_rmse': 10.097106564462965, 'test_mae': 8.814265251159668, 'test_mape': 29.735705256462097, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 64, 'epochs': 20, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.962857723236084, 'train_mape': 25.747737288475037, 'train_rmse': 10.14360465781773, 'test_mae': 8.814265251159668, 'test_mape': 29.797476530075073, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 64, 'epochs': 20, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.176427364349365, 'train_mape': 26.888245344161987, 'train_rmse': 10.400427853513182, 'test_mae': 8.814265251159668, 'test_mape': 30.111393332481384, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 128, 'epochs': 5, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.087594032287598, 'train_mape': 25.63776671886444, 'train_rmse': 10.283868427255454, 'test_mae': 8.814265251159668, 'test_mape': 29.350942373275757, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 128, 'epochs': 5, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.197141647338867, 'train_mape': 27.096331119537354, 'train_rmse': 10.404792752344386, 'test_mae': 8.814265251159668, 'test_mape': 30.219757556915283, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 128, 'epochs': 5, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.1921000480651855, 'train_mape': 27.52949893474579, 'train_rmse': 10.500988868288266, 'test_mae': 8.814265251159668, 'test_mape': 31.47982954978943, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 128, 'epochs': 5, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.259960651397705, 'train_mape': 27.40527093410492, 'train_rmse': 10.537172910200018, 'test_mae': 8.814265251159668, 'test_mape': 30.765551328659058, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 128, 'epochs': 10, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.962782859802246, 'train_mape': 24.59862530231476, 'train_rmse': 10.166634189574685, 'test_mae': 8.814265251159668, 'test_mape': 29.267248511314392, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 128, 'epochs': 10, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.09232759475708, 'train_mape': 25.130698084831238, 'train_rmse': 10.253815103761571, 'test_mae': 8.814265251159668, 'test_mape': 29.503411054611206, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 128, 'epochs': 10, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.148702144622803, 'train_mape': 26.7958402633667, 'train_rmse': 10.25944493270218, 'test_mae': 8.814265251159668, 'test_mape': 30.185553431510925, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 128, 'epochs': 10, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.083693981170654, 'train_mape': 26.455870270729065, 'train_rmse': 10.361026039717453, 'test_mae': 8.814265251159668, 'test_mape': 30.73960542678833, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 128, 'epochs': 20, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.80300235748291, 'train_mape': 23.949241638183594, 'train_rmse': 9.878315043227854, 'test_mae': 8.814265251159668, 'test_mape': 28.027009963989258, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 128, 'epochs': 20, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.019326686859131, 'train_mape': 25.728413462638855, 'train_rmse': 9.945126084515675, 'test_mae': 8.814265251159668, 'test_mape': 29.34548258781433, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 128, 'epochs': 20, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.964567184448242, 'train_mape': 25.64721703529358, 'train_rmse': 10.02410919721817, 'test_mae': 8.814265251159668, 'test_mape': 29.39588725566864, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 128, 'epochs': 20, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.967438220977783, 'train_mape': 25.911349058151245, 'train_rmse': 10.135960427439578, 'test_mae': 8.814265251159668, 'test_mape': 30.28523325920105, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 256, 'epochs': 5, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.2522664070129395, 'train_mape': 25.033852458000183, 'train_rmse': 10.467559473466888, 'test_mae': 8.814265251159668, 'test_mape': 29.266971349716187, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 256, 'epochs': 5, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.09694766998291, 'train_mape': 26.304274797439575, 'train_rmse': 10.276247981778555, 'test_mae': 8.814265251159668, 'test_mape': 29.66170608997345, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 256, 'epochs': 5, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.052067279815674, 'train_mape': 26.007530093193054, 'train_rmse': 10.312517755666534, 'test_mae': 8.814265251159668, 'test_mape': 30.02755641937256, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 256, 'epochs': 5, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.18557596206665, 'train_mape': 26.908156275749207, 'train_rmse': 10.462467141595468, 'test_mae': 8.814265251159668, 'test_mape': 30.513480305671692, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 256, 'epochs': 10, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.939159870147705, 'train_mape': 24.286068975925446, 'train_rmse': 10.18737493332932, 'test_mae': 8.814265251159668, 'test_mape': 28.533196449279785, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 256, 'epochs': 10, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.0725932121276855, 'train_mape': 26.0715514421463, 'train_rmse': 10.163736348413343, 'test_mae': 8.814265251159668, 'test_mape': 29.202759265899658, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 256, 'epochs': 10, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.990258693695068, 'train_mape': 25.78336000442505, 'train_rmse': 10.104159535408781, 'test_mae': 8.814265251159668, 'test_mape': 29.269951581954956, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 256, 'epochs': 10, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.992161750793457, 'train_mape': 25.799766182899475, 'train_rmse': 10.172763018073065, 'test_mae': 8.814265251159668, 'test_mape': 29.562243819236755, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 256, 'epochs': 20, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.765221118927002, 'train_mape': 23.7109512090683, 'train_rmse': 9.957310920699642, 'test_mae': 8.814265251159668, 'test_mape': 27.35360562801361, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 256, 'epochs': 20, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.922616004943848, 'train_mape': 24.780629575252533, 'train_rmse': 9.915363343661008, 'test_mae': 8.814265251159668, 'test_mape': 28.495889902114868, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 256, 'epochs': 20, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.813763618469238, 'train_mape': 24.194246530532837, 'train_rmse': 9.953150678808123, 'test_mae': 8.814265251159668, 'test_mape': 29.07421886920929, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 256, 'epochs': 20, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.914530277252197, 'train_mape': 25.120827555656433, 'train_rmse': 10.012788606025062, 'test_mae': 8.814265251159668, 'test_mape': 29.227861762046814, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 512, 'epochs': 5, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.388790130615234, 'train_mape': 25.04643201828003, 'train_rmse': 10.583961848621996, 'test_mae': 8.814265251159668, 'test_mape': 29.229119420051575, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 512, 'epochs': 5, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.324461936950684, 'train_mape': 25.750231742858887, 'train_rmse': 10.385631583287992, 'test_mae': 8.814265251159668, 'test_mape': 29.780974984169006, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 512, 'epochs': 5, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.123043060302734, 'train_mape': 25.415977835655212, 'train_rmse': 10.35058699707809, 'test_mae': 8.814265251159668, 'test_mape': 30.050697922706604, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 512, 'epochs': 5, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.462074279785156, 'train_mape': 28.652730584144592, 'train_rmse': 10.554289566772239, 'test_mae': 8.814265251159668, 'test_mape': 31.279179453849792, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 512, 'epochs': 10, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.09377908706665, 'train_mape': 25.069046020507812, 'train_rmse': 10.183952977817333, 'test_mae': 8.814265251159668, 'test_mape': 28.01916003227234, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 512, 'epochs': 10, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.935197353363037, 'train_mape': 25.2066433429718, 'train_rmse': 10.07351744844767, 'test_mae': 8.814265251159668, 'test_mape': 29.057204723358154, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 512, 'epochs': 10, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.990810871124268, 'train_mape': 24.846187233924866, 'train_rmse': 10.188416609454706, 'test_mae': 8.814265251159668, 'test_mape': 28.814542293548584, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 512, 'epochs': 10, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.0019426345825195, 'train_mape': 25.576677918434143, 'train_rmse': 10.156598176123266, 'test_mae': 8.814265251159668, 'test_mape': 29.533538222312927, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 512, 'epochs': 20, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.89227294921875, 'train_mape': 24.63168352842331, 'train_rmse': 9.881730502158272, 'test_mae': 8.814265251159668, 'test_mape': 27.271482348442078, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 512, 'epochs': 20, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.831228733062744, 'train_mape': 24.766400456428528, 'train_rmse': 9.914082893128159, 'test_mae': 8.814265251159668, 'test_mape': 27.994099259376526, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 512, 'epochs': 20, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.938877105712891, 'train_mape': 25.2072274684906, 'train_rmse': 10.03636310072283, 'test_mae': 8.814265251159668, 'test_mape': 29.203692078590393, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 512, 'epochs': 20, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.9034953117370605, 'train_mape': 24.993896484375, 'train_rmse': 9.949273195031635, 'test_mae': 8.814265251159668, 'test_mape': 29.12605106830597, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 1024, 'epochs': 5, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.064391136169434, 'train_mape': 25.592777132987976, 'train_rmse': 10.272213939138231, 'test_mae': 8.814265251159668, 'test_mape': 28.078395128250122, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 1024, 'epochs': 5, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.14689826965332, 'train_mape': 25.949591398239136, 'train_rmse': 10.228700418716905, 'test_mae': 8.814265251159668, 'test_mape': 29.3123722076416, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 1024, 'epochs': 5, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.093662261962891, 'train_mape': 25.20679235458374, 'train_rmse': 10.291629271239838, 'test_mae': 8.814265251159668, 'test_mape': 29.191800951957703, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 1024, 'epochs': 5, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.100759506225586, 'train_mape': 26.057660579681396, 'train_rmse': 10.220245718493597, 'test_mae': 8.814265251159668, 'test_mape': 29.716280102729797, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 1024, 'epochs': 10, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.273427486419678, 'train_mape': 25.970596075057983, 'train_rmse': 10.200581208667911, 'test_mae': 8.814265251159668, 'test_mape': 28.139492869377136, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 1024, 'epochs': 10, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.991771697998047, 'train_mape': 24.846631288528442, 'train_rmse': 10.19469511420914, 'test_mae': 8.814265251159668, 'test_mape': 28.939807415008545, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 1024, 'epochs': 10, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.933356761932373, 'train_mape': 24.344532191753387, 'train_rmse': 10.199605851879346, 'test_mae': 8.814265251159668, 'test_mape': 28.82576286792755, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 1024, 'epochs': 10, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.272089958190918, 'train_mape': 27.034875750541687, 'train_rmse': 10.22749798767473, 'test_mae': 8.814265251159668, 'test_mape': 30.126863718032837, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 1024, 'epochs': 20, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.800053596496582, 'train_mape': 24.659384787082672, 'train_rmse': 9.886831028970311, 'test_mae': 8.814265251159668, 'test_mape': 27.365773916244507, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 1024, 'epochs': 20, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.915031433105469, 'train_mape': 24.097612500190735, 'train_rmse': 9.982701407563892, 'test_mae': 8.814265251159668, 'test_mape': 27.466294169425964, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 1024, 'epochs': 20, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.300978183746338, 'train_mape': 27.096110582351685, 'train_rmse': 10.173239995779062, 'test_mae': 8.814265251159668, 'test_mape': 29.676946997642517, 'test_rmse': 14.235763666311897}, {'layer': 2, 'units': 1024, 'epochs': 20, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.972286224365234, 'train_mape': 25.741973519325256, 'train_rmse': 9.967084117639695, 'test_mae': 8.814265251159668, 'test_mape': 29.27720844745636, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 64, 'epochs': 5, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.180906295776367, 'train_mape': 25.68872570991516, 'train_rmse': 10.314153735181051, 'test_mae': 8.814265251159668, 'test_mape': 29.402261972427368, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 64, 'epochs': 5, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.219195365905762, 'train_mape': 26.78377330303192, 'train_rmse': 10.360743275494434, 'test_mae': 8.814265251159668, 'test_mape': 30.13017177581787, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 64, 'epochs': 5, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.1661834716796875, 'train_mape': 26.711323857307434, 'train_rmse': 10.453422416709657, 'test_mae': 8.814265251159668, 'test_mape': 30.877292156219482, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 64, 'epochs': 5, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.307331085205078, 'train_mape': 27.491366863250732, 'train_rmse': 10.590365699166854, 'test_mae': 8.814265251159668, 'test_mape': 31.15178942680359, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 64, 'epochs': 10, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.016322135925293, 'train_mape': 25.04637837409973, 'train_rmse': 10.209608556284545, 'test_mae': 8.814265251159668, 'test_mape': 28.769415616989136, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 64, 'epochs': 10, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.401421546936035, 'train_mape': 27.692806720733643, 'train_rmse': 10.388060656312069, 'test_mae': 8.814265251159668, 'test_mape': 30.105024576187134, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 64, 'epochs': 10, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.076370716094971, 'train_mape': 26.186981797218323, 'train_rmse': 10.222709985051742, 'test_mae': 8.814265251159668, 'test_mape': 29.99192774295807, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 64, 'epochs': 10, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.1029229164123535, 'train_mape': 26.082006096839905, 'train_rmse': 10.342920552445484, 'test_mae': 8.814265251159668, 'test_mape': 29.73669171333313, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 64, 'epochs': 20, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.065621852874756, 'train_mape': 26.353731751441956, 'train_rmse': 10.085177628594003, 'test_mae': 8.814265251159668, 'test_mape': 29.443421959877014, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 64, 'epochs': 20, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.936967372894287, 'train_mape': 24.611796438694, 'train_rmse': 10.073743899966356, 'test_mae': 8.814265251159668, 'test_mape': 29.07666265964508, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 64, 'epochs': 20, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.982697010040283, 'train_mape': 25.38418471813202, 'train_rmse': 10.061551446217567, 'test_mae': 8.814265251159668, 'test_mape': 28.674209117889404, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 64, 'epochs': 20, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.01396369934082, 'train_mape': 25.01186728477478, 'train_rmse': 10.179985410908436, 'test_mae': 8.814265251159668, 'test_mape': 29.20585870742798, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 128, 'epochs': 5, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.176849842071533, 'train_mape': 24.70555007457733, 'train_rmse': 10.511781531422514, 'test_mae': 8.814265251159668, 'test_mape': 29.13268506526947, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 128, 'epochs': 5, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.184058666229248, 'train_mape': 25.33188760280609, 'train_rmse': 10.363340513517883, 'test_mae': 8.814265251159668, 'test_mape': 29.31152880191803, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 128, 'epochs': 5, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.104923725128174, 'train_mape': 25.774094462394714, 'train_rmse': 10.316804484575115, 'test_mae': 8.814265251159668, 'test_mape': 29.610100388526917, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 128, 'epochs': 5, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.249289035797119, 'train_mape': 26.921483874320984, 'train_rmse': 10.399653546358039, 'test_mae': 8.814265251159668, 'test_mape': 30.053406953811646, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 128, 'epochs': 10, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.980802059173584, 'train_mape': 24.714206159114838, 'train_rmse': 10.159568268020946, 'test_mae': 8.814265251159668, 'test_mape': 28.09382975101471, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 128, 'epochs': 10, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.996908664703369, 'train_mape': 25.475308299064636, 'train_rmse': 10.130842618853022, 'test_mae': 8.814265251159668, 'test_mape': 29.1251003742218, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 128, 'epochs': 10, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.131483554840088, 'train_mape': 26.39530301094055, 'train_rmse': 10.17424600042903, 'test_mae': 8.814265251159668, 'test_mape': 30.067870020866394, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 128, 'epochs': 10, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.0400776863098145, 'train_mape': 26.236790418624878, 'train_rmse': 10.173602963828744, 'test_mae': 8.814265251159668, 'test_mape': 29.97550666332245, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 128, 'epochs': 20, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.747611999511719, 'train_mape': 24.004361033439636, 'train_rmse': 9.876380147941864, 'test_mae': 8.814265251159668, 'test_mape': 28.053832054138184, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 128, 'epochs': 20, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.864102363586426, 'train_mape': 24.730411171913147, 'train_rmse': 9.878407723309927, 'test_mae': 8.814265251159668, 'test_mape': 28.54245901107788, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 128, 'epochs': 20, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.976303577423096, 'train_mape': 23.57938140630722, 'train_rmse': 10.153465664010215, 'test_mae': 8.814265251159668, 'test_mape': 28.577029705047607, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 128, 'epochs': 20, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.865986347198486, 'train_mape': 24.707841873168945, 'train_rmse': 9.972813462700303, 'test_mae': 8.814265251159668, 'test_mape': 29.19672429561615, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 256, 'epochs': 5, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.376525402069092, 'train_mape': 27.229884266853333, 'train_rmse': 10.341873782468994, 'test_mae': 8.814265251159668, 'test_mape': 29.607966542243958, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 256, 'epochs': 5, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.257163047790527, 'train_mape': 26.314550638198853, 'train_rmse': 10.28163067423106, 'test_mae': 8.814265251159668, 'test_mape': 28.87469232082367, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 256, 'epochs': 5, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.223186016082764, 'train_mape': 25.012323260307312, 'train_rmse': 10.431999538913084, 'test_mae': 8.814265251159668, 'test_mape': 29.06191051006317, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 256, 'epochs': 5, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.08506965637207, 'train_mape': 25.822743773460388, 'train_rmse': 10.290506480276152, 'test_mae': 8.814265251159668, 'test_mape': 29.906630516052246, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 256, 'epochs': 10, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.650608539581299, 'train_mape': 28.844544291496277, 'train_rmse': 10.532203699050868, 'test_mae': 8.814265251159668, 'test_mape': 30.42939603328705, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 256, 'epochs': 10, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.168907165527344, 'train_mape': 27.01977789402008, 'train_rmse': 10.20900623413338, 'test_mae': 8.814265251159668, 'test_mape': 29.383429884910583, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 256, 'epochs': 10, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.125514984130859, 'train_mape': 26.051077246665955, 'train_rmse': 10.139573523226218, 'test_mae': 8.814265251159668, 'test_mape': 29.33972179889679, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 256, 'epochs': 10, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.959589958190918, 'train_mape': 25.21374821662903, 'train_rmse': 10.081484117999908, 'test_mae': 8.814265251159668, 'test_mape': 28.78853678703308, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 256, 'epochs': 20, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.802661895751953, 'train_mape': 24.318990111351013, 'train_rmse': 9.874215010334366, 'test_mae': 8.814265251159668, 'test_mape': 27.507242560386658, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 256, 'epochs': 20, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.962075710296631, 'train_mape': 24.81989711523056, 'train_rmse': 9.889110286486888, 'test_mae': 8.814265251159668, 'test_mape': 28.328177332878113, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 256, 'epochs': 20, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.846904754638672, 'train_mape': 24.34685081243515, 'train_rmse': 9.85349413866587, 'test_mae': 8.814265251159668, 'test_mape': 28.340333700180054, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 256, 'epochs': 20, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.8429694175720215, 'train_mape': 23.93285632133484, 'train_rmse': 9.973908910139189, 'test_mae': 8.814265251159668, 'test_mape': 28.507691621780396, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 512, 'epochs': 5, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.138009548187256, 'train_mape': 26.11115574836731, 'train_rmse': 10.270706846581591, 'test_mae': 8.814265251159668, 'test_mape': 28.65181267261505, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 512, 'epochs': 5, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.094332695007324, 'train_mape': 25.47907531261444, 'train_rmse': 10.257134536454409, 'test_mae': 8.814265251159668, 'test_mape': 29.143264889717102, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 512, 'epochs': 5, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.976546764373779, 'train_mape': 25.801941752433777, 'train_rmse': 10.187586122862578, 'test_mae': 8.814265251159668, 'test_mape': 29.632461071014404, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 512, 'epochs': 5, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.1434454917907715, 'train_mape': 25.664830207824707, 'train_rmse': 10.265992876541993, 'test_mae': 8.814265251159668, 'test_mape': 29.27173376083374, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 512, 'epochs': 10, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.931684494018555, 'train_mape': 25.19831359386444, 'train_rmse': 10.03489395458106, 'test_mae': 8.814265251159668, 'test_mape': 27.544063329696655, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 512, 'epochs': 10, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.97080659866333, 'train_mape': 24.4802787899971, 'train_rmse': 10.165778658081123, 'test_mae': 8.814265251159668, 'test_mape': 28.425976634025574, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 512, 'epochs': 10, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.002331733703613, 'train_mape': 24.726766347885132, 'train_rmse': 10.14453125, 'test_mae': 8.814265251159668, 'test_mape': 28.76480519771576, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 512, 'epochs': 10, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.486171245574951, 'train_mape': 28.097376227378845, 'train_rmse': 10.358831837311165, 'test_mae': 8.814265251159668, 'test_mape': 30.602285265922546, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 512, 'epochs': 20, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.803994178771973, 'train_mape': 23.866035044193268, 'train_rmse': 9.909740134026007, 'test_mae': 8.814265251159668, 'test_mape': 27.774345874786377, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 512, 'epochs': 20, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.853389263153076, 'train_mape': 24.63923990726471, 'train_rmse': 9.871461644806345, 'test_mae': 8.814265251159668, 'test_mape': 27.84152328968048, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 512, 'epochs': 20, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.802763938903809, 'train_mape': 25.08603036403656, 'train_rmse': 9.82634171892818, 'test_mae': 8.814265251159668, 'test_mape': 28.509950637817383, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 512, 'epochs': 20, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.695350170135498, 'train_mape': 24.23478364944458, 'train_rmse': 9.868124197794911, 'test_mae': 8.814265251159668, 'test_mape': 28.76395583152771, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 1024, 'epochs': 5, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.1746439933776855, 'train_mape': 25.034812092781067, 'train_rmse': 10.297002070891761, 'test_mae': 8.814265251159668, 'test_mape': 28.460222482681274, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 1024, 'epochs': 5, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.204618453979492, 'train_mape': 25.96312165260315, 'train_rmse': 10.27628658806473, 'test_mae': 8.814265251159668, 'test_mape': 28.640666604042053, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 1024, 'epochs': 5, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.098246097564697, 'train_mape': 24.849212169647217, 'train_rmse': 10.479727657361185, 'test_mae': 8.814265251159668, 'test_mape': 29.95775043964386, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 1024, 'epochs': 5, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.112067222595215, 'train_mape': 24.98064637184143, 'train_rmse': 10.36651337766826, 'test_mae': 8.814265251159668, 'test_mape': 29.932424426078796, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 1024, 'epochs': 10, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.038695812225342, 'train_mape': 25.509127974510193, 'train_rmse': 10.1251409073432, 'test_mae': 8.814265251159668, 'test_mape': 28.19131910800934, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 1024, 'epochs': 10, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.043174743652344, 'train_mape': 24.37189370393753, 'train_rmse': 10.193334114202749, 'test_mae': 8.814265251159668, 'test_mape': 28.162959218025208, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 1024, 'epochs': 10, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.15434455871582, 'train_mape': 25.94008445739746, 'train_rmse': 10.147506753412232, 'test_mae': 8.814265251159668, 'test_mape': 28.919005393981934, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 1024, 'epochs': 10, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.969263076782227, 'train_mape': 25.120076537132263, 'train_rmse': 10.088077994690224, 'test_mae': 8.814265251159668, 'test_mape': 29.284897446632385, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 1024, 'epochs': 20, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.804990768432617, 'train_mape': 24.60503578186035, 'train_rmse': 9.828306648261725, 'test_mae': 8.814265251159668, 'test_mape': 27.2238552570343, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 1024, 'epochs': 20, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.6848039627075195, 'train_mape': 24.18152242898941, 'train_rmse': 9.82054556704336, 'test_mae': 8.814265251159668, 'test_mape': 27.840682864189148, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 1024, 'epochs': 20, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.893186569213867, 'train_mape': 23.682789504528046, 'train_rmse': 9.973672542345351, 'test_mae': 8.814265251159668, 'test_mape': 27.86964476108551, 'test_rmse': 14.235763666311897}, {'layer': 3, 'units': 1024, 'epochs': 20, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.788782119750977, 'train_mape': 24.26292896270752, 'train_rmse': 9.88533155580842, 'test_mae': 8.814265251159668, 'test_mape': 28.714075684547424, 'test_rmse': 14.235763666311897}]\n"
     ]
    }
   ],
   "source": [
    "print(all_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63bfd32b-3ac4-406b-b333-4f8611563c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>units</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>activation</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>train_mae</th>\n",
       "      <th>train_mape</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>test_mae</th>\n",
       "      <th>test_mape</th>\n",
       "      <th>test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>7.222612</td>\n",
       "      <td>26.867494</td>\n",
       "      <td>10.513423</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>30.203649</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>7.421987</td>\n",
       "      <td>27.840731</td>\n",
       "      <td>10.702858</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>30.550179</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>7.647298</td>\n",
       "      <td>28.310767</td>\n",
       "      <td>10.895464</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>30.916697</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>256</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>8.118735</td>\n",
       "      <td>29.462296</td>\n",
       "      <td>11.379990</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>32.130453</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>7.028020</td>\n",
       "      <td>25.865257</td>\n",
       "      <td>10.265084</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>28.877708</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>6.969263</td>\n",
       "      <td>25.120077</td>\n",
       "      <td>10.088078</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>29.284897</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>6.804991</td>\n",
       "      <td>24.605036</td>\n",
       "      <td>9.828307</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>27.223855</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>20</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>6.684804</td>\n",
       "      <td>24.181522</td>\n",
       "      <td>9.820546</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>27.840683</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>20</td>\n",
       "      <td>128</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>6.893187</td>\n",
       "      <td>23.682790</td>\n",
       "      <td>9.973673</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>27.869645</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>3</td>\n",
       "      <td>1024</td>\n",
       "      <td>20</td>\n",
       "      <td>256</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>6.788782</td>\n",
       "      <td>24.262929</td>\n",
       "      <td>9.885332</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>28.714076</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     layer  units  epochs  batch_size activation optimizer  train_mae   \n",
       "0        1     64       5          32       relu      adam   7.222612  \\\n",
       "1        1     64       5          64       relu      adam   7.421987   \n",
       "2        1     64       5         128       relu      adam   7.647298   \n",
       "3        1     64       5         256       relu      adam   8.118735   \n",
       "4        1     64      10          32       relu      adam   7.028020   \n",
       "..     ...    ...     ...         ...        ...       ...        ...   \n",
       "175      3   1024      10         256       relu      adam   6.969263   \n",
       "176      3   1024      20          32       relu      adam   6.804991   \n",
       "177      3   1024      20          64       relu      adam   6.684804   \n",
       "178      3   1024      20         128       relu      adam   6.893187   \n",
       "179      3   1024      20         256       relu      adam   6.788782   \n",
       "\n",
       "     train_mape  train_rmse  test_mae  test_mape  test_rmse  \n",
       "0     26.867494   10.513423  8.814265  30.203649  14.235764  \n",
       "1     27.840731   10.702858  8.814265  30.550179  14.235764  \n",
       "2     28.310767   10.895464  8.814265  30.916697  14.235764  \n",
       "3     29.462296   11.379990  8.814265  32.130453  14.235764  \n",
       "4     25.865257   10.265084  8.814265  28.877708  14.235764  \n",
       "..          ...         ...       ...        ...        ...  \n",
       "175   25.120077   10.088078  8.814265  29.284897  14.235764  \n",
       "176   24.605036    9.828307  8.814265  27.223855  14.235764  \n",
       "177   24.181522    9.820546  8.814265  27.840683  14.235764  \n",
       "178   23.682790    9.973673  8.814265  27.869645  14.235764  \n",
       "179   24.262929    9.885332  8.814265  28.714076  14.235764  \n",
       "\n",
       "[180 rows x 12 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_data_forConvert = pd.DataFrame(all_record)\n",
    "record_df = pd.DataFrame.from_records(record_data_forConvert)\n",
    "record_df.to_csv('./lab4.csv', index=False)\n",
    "record_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b26c2cf-c33e-478f-b211-3daefbb28989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('group_layer_1',\n",
       "      layer  units  epochs  batch_size activation optimizer  train_mae   \n",
       "  0       1     64       5          32       relu      adam   7.222612  \\\n",
       "  1       1     64       5          64       relu      adam   7.421987   \n",
       "  2       1     64       5         128       relu      adam   7.647298   \n",
       "  3       1     64       5         256       relu      adam   8.118735   \n",
       "  4       1     64      10          32       relu      adam   7.028020   \n",
       "  5       1     64      10          64       relu      adam   7.111169   \n",
       "  6       1     64      10         128       relu      adam   7.354572   \n",
       "  7       1     64      10         256       relu      adam   7.604227   \n",
       "  8       1     64      20          32       relu      adam   6.949418   \n",
       "  9       1     64      20          64       relu      adam   6.968048   \n",
       "  10      1     64      20         128       relu      adam   7.038014   \n",
       "  11      1     64      20         256       relu      adam   7.290943   \n",
       "  12      1    128       5          32       relu      adam   7.064771   \n",
       "  13      1    128       5          64       relu      adam   7.220569   \n",
       "  14      1    128       5         128       relu      adam   7.490509   \n",
       "  15      1    128       5         256       relu      adam   7.786828   \n",
       "  16      1    128      10          32       relu      adam   7.095278   \n",
       "  17      1    128      10          64       relu      adam   7.043642   \n",
       "  18      1    128      10         128       relu      adam   7.164578   \n",
       "  19      1    128      10         256       relu      adam   7.411918   \n",
       "  20      1    128      20          32       relu      adam   6.895312   \n",
       "  21      1    128      20          64       relu      adam   6.963494   \n",
       "  22      1    128      20         128       relu      adam   6.979164   \n",
       "  23      1    128      20         256       relu      adam   7.054037   \n",
       "  24      1    256       5          32       relu      adam   7.139409   \n",
       "  25      1    256       5          64       relu      adam   7.224432   \n",
       "  26      1    256       5         128       relu      adam   7.330097   \n",
       "  27      1    256       5         256       relu      adam   7.517463   \n",
       "  28      1    256      10          32       relu      adam   7.047982   \n",
       "  29      1    256      10          64       relu      adam   7.012208   \n",
       "  30      1    256      10         128       relu      adam   7.042295   \n",
       "  31      1    256      10         256       relu      adam   7.295012   \n",
       "  32      1    256      20          32       relu      adam   6.861979   \n",
       "  33      1    256      20          64       relu      adam   6.901323   \n",
       "  34      1    256      20         128       relu      adam   6.938537   \n",
       "  35      1    256      20         256       relu      adam   7.070056   \n",
       "  36      1    512       5          32       relu      adam   7.128464   \n",
       "  37      1    512       5          64       relu      adam   7.196950   \n",
       "  38      1    512       5         128       relu      adam   7.210919   \n",
       "  39      1    512       5         256       relu      adam   7.330745   \n",
       "  40      1    512      10          32       relu      adam   7.067546   \n",
       "  41      1    512      10          64       relu      adam   6.907340   \n",
       "  42      1    512      10         128       relu      adam   7.013269   \n",
       "  43      1    512      10         256       relu      adam   7.121381   \n",
       "  44      1    512      20          32       relu      adam   6.818527   \n",
       "  45      1    512      20          64       relu      adam   6.961171   \n",
       "  46      1    512      20         128       relu      adam   6.902625   \n",
       "  47      1    512      20         256       relu      adam   6.939386   \n",
       "  48      1   1024       5          32       relu      adam   7.035342   \n",
       "  49      1   1024       5          64       relu      adam   7.179379   \n",
       "  50      1   1024       5         128       relu      adam   7.155813   \n",
       "  51      1   1024       5         256       relu      adam   7.264668   \n",
       "  52      1   1024      10          32       relu      adam   7.083189   \n",
       "  53      1   1024      10          64       relu      adam   7.117007   \n",
       "  54      1   1024      10         128       relu      adam   6.973603   \n",
       "  55      1   1024      10         256       relu      adam   7.027978   \n",
       "  56      1   1024      20          32       relu      adam   6.817963   \n",
       "  57      1   1024      20          64       relu      adam   6.868446   \n",
       "  58      1   1024      20         128       relu      adam   6.838010   \n",
       "  59      1   1024      20         256       relu      adam   6.903898   \n",
       "  \n",
       "      train_mape  train_rmse  test_mae  test_mape  test_rmse  \n",
       "  0    26.867494   10.513423  8.814265  30.203649  14.235764  \n",
       "  1    27.840731   10.702858  8.814265  30.550179  14.235764  \n",
       "  2    28.310767   10.895464  8.814265  30.916697  14.235764  \n",
       "  3    29.462296   11.379990  8.814265  32.130453  14.235764  \n",
       "  4    25.865257   10.265084  8.814265  28.877708  14.235764  \n",
       "  5    26.319334   10.364886  8.814265  29.305026  14.235764  \n",
       "  6    27.234223   10.565355  8.814265  30.288008  14.235764  \n",
       "  7    28.191978   10.839045  8.814265  30.608165  14.235764  \n",
       "  8    25.393191   10.110911  8.814265  28.425452  14.235764  \n",
       "  9    25.477999   10.148047  8.814265  28.289160  14.235764  \n",
       "  10   25.820008   10.232150  8.814265  28.865618  14.235764  \n",
       "  11   26.922113   10.502598  8.814265  29.561046  14.235764  \n",
       "  12   26.304066   10.402760  8.814265  29.524481  14.235764  \n",
       "  13   26.949856   10.534756  8.814265  30.033284  14.235764  \n",
       "  14   27.925828   10.742990  8.814265  30.724344  14.235764  \n",
       "  15   28.723830   11.022014  8.814265  31.582803  14.235764  \n",
       "  16   25.828049   10.193872  8.814265  29.000866  14.235764  \n",
       "  17   25.845203   10.253260  8.814265  28.823009  14.235764  \n",
       "  18   26.715642   10.441261  8.814265  29.501614  14.235764  \n",
       "  19   27.511939   10.663535  8.814265  30.415085  14.235764  \n",
       "  20   25.157255   10.040302  8.814265  28.294250  14.235764  \n",
       "  21   25.177637   10.078141  8.814265  27.831212  14.235764  \n",
       "  22   25.664487   10.148164  8.814265  28.527346  14.235764  \n",
       "  23   26.108813   10.313967  8.814265  28.813469  14.235764  \n",
       "  24   26.320827   10.334130  8.814265  29.440042  14.235764  \n",
       "  25   26.961377   10.429958  8.814265  29.834452  14.235764  \n",
       "  26   27.419084   10.610795  8.814265  30.287585  14.235764  \n",
       "  27   27.960470   10.789133  8.814265  30.792031  14.235764  \n",
       "  28   25.101808   10.180927  8.814265  27.764949  14.235764  \n",
       "  29   25.496739   10.194585  8.814265  28.342685  14.235764  \n",
       "  30   26.164225   10.299470  8.814265  28.782758  14.235764  \n",
       "  31   27.344665   10.537040  8.814265  30.035484  14.235764  \n",
       "  32   24.910551   10.001297  8.814265  28.151566  14.235764  \n",
       "  33   25.187322   10.020196  8.814265  28.566703  14.235764  \n",
       "  34   25.270835   10.085079  8.814265  28.478631  14.235764  \n",
       "  35   26.046672   10.196156  8.814265  28.750688  14.235764  \n",
       "  36   26.534143   10.315096  8.814265  29.697806  14.235764  \n",
       "  37   27.091798   10.385955  8.814265  29.635158  14.235764  \n",
       "  38   26.813278   10.492345  8.814265  29.949370  14.235764  \n",
       "  39   27.468601   10.647756  8.814265  30.483970  14.235764  \n",
       "  40   26.003101   10.165714  8.814265  28.685716  14.235764  \n",
       "  41   24.757402   10.150599  8.814265  28.076562  14.235764  \n",
       "  42   25.389805   10.214761  8.814265  28.609350  14.235764  \n",
       "  43   26.453191   10.397882  8.814265  29.558724  14.235764  \n",
       "  44   24.616243    9.984857  8.814265  27.575654  14.235764  \n",
       "  45   25.484172    9.988877  8.814265  27.950019  14.235764  \n",
       "  46   25.526258   10.017166  8.814265  28.482956  14.235764  \n",
       "  47   25.498292   10.111879  8.814265  28.883645  14.235764  \n",
       "  48   25.879830   10.403912  8.814265  29.411975  14.235764  \n",
       "  49   26.392674   10.306543  8.814265  28.787819  14.235764  \n",
       "  50   26.722598   10.397544  8.814265  29.574838  14.235764  \n",
       "  51   27.147621   10.553978  8.814265  30.130416  14.235764  \n",
       "  52   25.010675   10.235291  8.814265  28.360054  14.235764  \n",
       "  53   26.321572   10.163582  8.814265  28.462175  14.235764  \n",
       "  54   25.512436   10.161572  8.814265  28.437641  14.235764  \n",
       "  55   26.109245   10.272085  8.814265  29.191670  14.235764  \n",
       "  56   24.844667    9.965611  8.814265  27.620825  14.235764  \n",
       "  57   24.699675    9.996111  8.814265  27.438450  14.235764  \n",
       "  58   25.042826    9.951021  8.814265  27.915215  14.235764  \n",
       "  59   25.416848   10.038055  8.814265  28.417304  14.235764  ),\n",
       " ('group_layer_2',\n",
       "       layer  units  epochs  batch_size activation optimizer  train_mae   \n",
       "  60       2     64       5          32       relu      adam   7.322351  \\\n",
       "  61       2     64       5          64       relu      adam   7.237823   \n",
       "  62       2     64       5         128       relu      adam   7.272233   \n",
       "  63       2     64       5         256       relu      adam   7.392141   \n",
       "  64       2     64      10          32       relu      adam   7.018354   \n",
       "  65       2     64      10          64       relu      adam   7.145233   \n",
       "  66       2     64      10         128       relu      adam   7.116014   \n",
       "  67       2     64      10         256       relu      adam   7.180126   \n",
       "  68       2     64      20          32       relu      adam   6.863499   \n",
       "  69       2     64      20          64       relu      adam   6.987978   \n",
       "  70       2     64      20         128       relu      adam   6.962858   \n",
       "  71       2     64      20         256       relu      adam   7.176427   \n",
       "  72       2    128       5          32       relu      adam   7.087594   \n",
       "  73       2    128       5          64       relu      adam   7.197142   \n",
       "  74       2    128       5         128       relu      adam   7.192100   \n",
       "  75       2    128       5         256       relu      adam   7.259961   \n",
       "  76       2    128      10          32       relu      adam   6.962783   \n",
       "  77       2    128      10          64       relu      adam   7.092328   \n",
       "  78       2    128      10         128       relu      adam   7.148702   \n",
       "  79       2    128      10         256       relu      adam   7.083694   \n",
       "  80       2    128      20          32       relu      adam   6.803002   \n",
       "  81       2    128      20          64       relu      adam   7.019327   \n",
       "  82       2    128      20         128       relu      adam   6.964567   \n",
       "  83       2    128      20         256       relu      adam   6.967438   \n",
       "  84       2    256       5          32       relu      adam   7.252266   \n",
       "  85       2    256       5          64       relu      adam   7.096948   \n",
       "  86       2    256       5         128       relu      adam   7.052067   \n",
       "  87       2    256       5         256       relu      adam   7.185576   \n",
       "  88       2    256      10          32       relu      adam   6.939160   \n",
       "  89       2    256      10          64       relu      adam   7.072593   \n",
       "  90       2    256      10         128       relu      adam   6.990259   \n",
       "  91       2    256      10         256       relu      adam   6.992162   \n",
       "  92       2    256      20          32       relu      adam   6.765221   \n",
       "  93       2    256      20          64       relu      adam   6.922616   \n",
       "  94       2    256      20         128       relu      adam   6.813764   \n",
       "  95       2    256      20         256       relu      adam   6.914530   \n",
       "  96       2    512       5          32       relu      adam   7.388790   \n",
       "  97       2    512       5          64       relu      adam   7.324462   \n",
       "  98       2    512       5         128       relu      adam   7.123043   \n",
       "  99       2    512       5         256       relu      adam   7.462074   \n",
       "  100      2    512      10          32       relu      adam   7.093779   \n",
       "  101      2    512      10          64       relu      adam   6.935197   \n",
       "  102      2    512      10         128       relu      adam   6.990811   \n",
       "  103      2    512      10         256       relu      adam   7.001943   \n",
       "  104      2    512      20          32       relu      adam   6.892273   \n",
       "  105      2    512      20          64       relu      adam   6.831229   \n",
       "  106      2    512      20         128       relu      adam   6.938877   \n",
       "  107      2    512      20         256       relu      adam   6.903495   \n",
       "  108      2   1024       5          32       relu      adam   7.064391   \n",
       "  109      2   1024       5          64       relu      adam   7.146898   \n",
       "  110      2   1024       5         128       relu      adam   7.093662   \n",
       "  111      2   1024       5         256       relu      adam   7.100760   \n",
       "  112      2   1024      10          32       relu      adam   7.273427   \n",
       "  113      2   1024      10          64       relu      adam   6.991772   \n",
       "  114      2   1024      10         128       relu      adam   6.933357   \n",
       "  115      2   1024      10         256       relu      adam   7.272090   \n",
       "  116      2   1024      20          32       relu      adam   6.800054   \n",
       "  117      2   1024      20          64       relu      adam   6.915031   \n",
       "  118      2   1024      20         128       relu      adam   7.300978   \n",
       "  119      2   1024      20         256       relu      adam   6.972286   \n",
       "  \n",
       "       train_mape  train_rmse  test_mae  test_mape  test_rmse  \n",
       "  60    27.779439   10.522661  8.814265  31.095123  14.235764  \n",
       "  61    27.277425   10.528871  8.814265  31.021020  14.235764  \n",
       "  62    27.055231   10.599528  8.814265  31.213132  14.235764  \n",
       "  63    27.749807   10.680265  8.814265  31.111485  14.235764  \n",
       "  64    25.579825   10.216839  8.814265  29.487509  14.235764  \n",
       "  65    25.219256   10.379192  8.814265  30.553156  14.235764  \n",
       "  66    26.275605   10.413264  8.814265  30.223823  14.235764  \n",
       "  67    26.792330   10.429300  8.814265  30.474880  14.235764  \n",
       "  68    24.326919   10.107742  8.814265  29.356769  14.235764  \n",
       "  69    25.994223   10.097107  8.814265  29.735705  14.235764  \n",
       "  70    25.747737   10.143605  8.814265  29.797477  14.235764  \n",
       "  71    26.888245   10.400428  8.814265  30.111393  14.235764  \n",
       "  72    25.637767   10.283868  8.814265  29.350942  14.235764  \n",
       "  73    27.096331   10.404793  8.814265  30.219758  14.235764  \n",
       "  74    27.529499   10.500989  8.814265  31.479830  14.235764  \n",
       "  75    27.405271   10.537173  8.814265  30.765551  14.235764  \n",
       "  76    24.598625   10.166634  8.814265  29.267249  14.235764  \n",
       "  77    25.130698   10.253815  8.814265  29.503411  14.235764  \n",
       "  78    26.795840   10.259445  8.814265  30.185553  14.235764  \n",
       "  79    26.455870   10.361026  8.814265  30.739605  14.235764  \n",
       "  80    23.949242    9.878315  8.814265  28.027010  14.235764  \n",
       "  81    25.728413    9.945126  8.814265  29.345483  14.235764  \n",
       "  82    25.647217   10.024109  8.814265  29.395887  14.235764  \n",
       "  83    25.911349   10.135960  8.814265  30.285233  14.235764  \n",
       "  84    25.033852   10.467559  8.814265  29.266971  14.235764  \n",
       "  85    26.304275   10.276248  8.814265  29.661706  14.235764  \n",
       "  86    26.007530   10.312518  8.814265  30.027556  14.235764  \n",
       "  87    26.908156   10.462467  8.814265  30.513480  14.235764  \n",
       "  88    24.286069   10.187375  8.814265  28.533196  14.235764  \n",
       "  89    26.071551   10.163736  8.814265  29.202759  14.235764  \n",
       "  90    25.783360   10.104160  8.814265  29.269952  14.235764  \n",
       "  91    25.799766   10.172763  8.814265  29.562244  14.235764  \n",
       "  92    23.710951    9.957311  8.814265  27.353606  14.235764  \n",
       "  93    24.780630    9.915363  8.814265  28.495890  14.235764  \n",
       "  94    24.194247    9.953151  8.814265  29.074219  14.235764  \n",
       "  95    25.120828   10.012789  8.814265  29.227862  14.235764  \n",
       "  96    25.046432   10.583962  8.814265  29.229119  14.235764  \n",
       "  97    25.750232   10.385632  8.814265  29.780975  14.235764  \n",
       "  98    25.415978   10.350587  8.814265  30.050698  14.235764  \n",
       "  99    28.652731   10.554290  8.814265  31.279179  14.235764  \n",
       "  100   25.069046   10.183953  8.814265  28.019160  14.235764  \n",
       "  101   25.206643   10.073517  8.814265  29.057205  14.235764  \n",
       "  102   24.846187   10.188417  8.814265  28.814542  14.235764  \n",
       "  103   25.576678   10.156598  8.814265  29.533538  14.235764  \n",
       "  104   24.631684    9.881731  8.814265  27.271482  14.235764  \n",
       "  105   24.766400    9.914083  8.814265  27.994099  14.235764  \n",
       "  106   25.207227   10.036363  8.814265  29.203692  14.235764  \n",
       "  107   24.993896    9.949273  8.814265  29.126051  14.235764  \n",
       "  108   25.592777   10.272214  8.814265  28.078395  14.235764  \n",
       "  109   25.949591   10.228700  8.814265  29.312372  14.235764  \n",
       "  110   25.206792   10.291629  8.814265  29.191801  14.235764  \n",
       "  111   26.057661   10.220246  8.814265  29.716280  14.235764  \n",
       "  112   25.970596   10.200581  8.814265  28.139493  14.235764  \n",
       "  113   24.846631   10.194695  8.814265  28.939807  14.235764  \n",
       "  114   24.344532   10.199606  8.814265  28.825763  14.235764  \n",
       "  115   27.034876   10.227498  8.814265  30.126864  14.235764  \n",
       "  116   24.659385    9.886831  8.814265  27.365774  14.235764  \n",
       "  117   24.097613    9.982701  8.814265  27.466294  14.235764  \n",
       "  118   27.096111   10.173240  8.814265  29.676947  14.235764  \n",
       "  119   25.741974    9.967084  8.814265  29.277208  14.235764  ),\n",
       " ('group_layer_3',\n",
       "       layer  units  epochs  batch_size activation optimizer  train_mae   \n",
       "  120      3     64       5          32       relu      adam   7.180906  \\\n",
       "  121      3     64       5          64       relu      adam   7.219195   \n",
       "  122      3     64       5         128       relu      adam   7.166183   \n",
       "  123      3     64       5         256       relu      adam   7.307331   \n",
       "  124      3     64      10          32       relu      adam   7.016322   \n",
       "  125      3     64      10          64       relu      adam   7.401422   \n",
       "  126      3     64      10         128       relu      adam   7.076371   \n",
       "  127      3     64      10         256       relu      adam   7.102923   \n",
       "  128      3     64      20          32       relu      adam   7.065622   \n",
       "  129      3     64      20          64       relu      adam   6.936967   \n",
       "  130      3     64      20         128       relu      adam   6.982697   \n",
       "  131      3     64      20         256       relu      adam   7.013964   \n",
       "  132      3    128       5          32       relu      adam   7.176850   \n",
       "  133      3    128       5          64       relu      adam   7.184059   \n",
       "  134      3    128       5         128       relu      adam   7.104924   \n",
       "  135      3    128       5         256       relu      adam   7.249289   \n",
       "  136      3    128      10          32       relu      adam   6.980802   \n",
       "  137      3    128      10          64       relu      adam   6.996909   \n",
       "  138      3    128      10         128       relu      adam   7.131484   \n",
       "  139      3    128      10         256       relu      adam   7.040078   \n",
       "  140      3    128      20          32       relu      adam   6.747612   \n",
       "  141      3    128      20          64       relu      adam   6.864102   \n",
       "  142      3    128      20         128       relu      adam   6.976304   \n",
       "  143      3    128      20         256       relu      adam   6.865986   \n",
       "  144      3    256       5          32       relu      adam   7.376525   \n",
       "  145      3    256       5          64       relu      adam   7.257163   \n",
       "  146      3    256       5         128       relu      adam   7.223186   \n",
       "  147      3    256       5         256       relu      adam   7.085070   \n",
       "  148      3    256      10          32       relu      adam   7.650609   \n",
       "  149      3    256      10          64       relu      adam   7.168907   \n",
       "  150      3    256      10         128       relu      adam   7.125515   \n",
       "  151      3    256      10         256       relu      adam   6.959590   \n",
       "  152      3    256      20          32       relu      adam   6.802662   \n",
       "  153      3    256      20          64       relu      adam   6.962076   \n",
       "  154      3    256      20         128       relu      adam   6.846905   \n",
       "  155      3    256      20         256       relu      adam   6.842969   \n",
       "  156      3    512       5          32       relu      adam   7.138010   \n",
       "  157      3    512       5          64       relu      adam   7.094333   \n",
       "  158      3    512       5         128       relu      adam   6.976547   \n",
       "  159      3    512       5         256       relu      adam   7.143445   \n",
       "  160      3    512      10          32       relu      adam   6.931684   \n",
       "  161      3    512      10          64       relu      adam   6.970807   \n",
       "  162      3    512      10         128       relu      adam   7.002332   \n",
       "  163      3    512      10         256       relu      adam   7.486171   \n",
       "  164      3    512      20          32       relu      adam   6.803994   \n",
       "  165      3    512      20          64       relu      adam   6.853389   \n",
       "  166      3    512      20         128       relu      adam   6.802764   \n",
       "  167      3    512      20         256       relu      adam   6.695350   \n",
       "  168      3   1024       5          32       relu      adam   7.174644   \n",
       "  169      3   1024       5          64       relu      adam   7.204618   \n",
       "  170      3   1024       5         128       relu      adam   7.098246   \n",
       "  171      3   1024       5         256       relu      adam   7.112067   \n",
       "  172      3   1024      10          32       relu      adam   7.038696   \n",
       "  173      3   1024      10          64       relu      adam   7.043175   \n",
       "  174      3   1024      10         128       relu      adam   7.154345   \n",
       "  175      3   1024      10         256       relu      adam   6.969263   \n",
       "  176      3   1024      20          32       relu      adam   6.804991   \n",
       "  177      3   1024      20          64       relu      adam   6.684804   \n",
       "  178      3   1024      20         128       relu      adam   6.893187   \n",
       "  179      3   1024      20         256       relu      adam   6.788782   \n",
       "  \n",
       "       train_mape  train_rmse  test_mae  test_mape  test_rmse  \n",
       "  120   25.688726   10.314154  8.814265  29.402262  14.235764  \n",
       "  121   26.783773   10.360743  8.814265  30.130172  14.235764  \n",
       "  122   26.711324   10.453422  8.814265  30.877292  14.235764  \n",
       "  123   27.491367   10.590366  8.814265  31.151789  14.235764  \n",
       "  124   25.046378   10.209609  8.814265  28.769416  14.235764  \n",
       "  125   27.692807   10.388061  8.814265  30.105025  14.235764  \n",
       "  126   26.186982   10.222710  8.814265  29.991928  14.235764  \n",
       "  127   26.082006   10.342921  8.814265  29.736692  14.235764  \n",
       "  128   26.353732   10.085178  8.814265  29.443422  14.235764  \n",
       "  129   24.611796   10.073744  8.814265  29.076663  14.235764  \n",
       "  130   25.384185   10.061551  8.814265  28.674209  14.235764  \n",
       "  131   25.011867   10.179985  8.814265  29.205859  14.235764  \n",
       "  132   24.705550   10.511782  8.814265  29.132685  14.235764  \n",
       "  133   25.331888   10.363341  8.814265  29.311529  14.235764  \n",
       "  134   25.774094   10.316804  8.814265  29.610100  14.235764  \n",
       "  135   26.921484   10.399654  8.814265  30.053407  14.235764  \n",
       "  136   24.714206   10.159568  8.814265  28.093830  14.235764  \n",
       "  137   25.475308   10.130843  8.814265  29.125100  14.235764  \n",
       "  138   26.395303   10.174246  8.814265  30.067870  14.235764  \n",
       "  139   26.236790   10.173603  8.814265  29.975507  14.235764  \n",
       "  140   24.004361    9.876380  8.814265  28.053832  14.235764  \n",
       "  141   24.730411    9.878408  8.814265  28.542459  14.235764  \n",
       "  142   23.579381   10.153466  8.814265  28.577030  14.235764  \n",
       "  143   24.707842    9.972813  8.814265  29.196724  14.235764  \n",
       "  144   27.229884   10.341874  8.814265  29.607967  14.235764  \n",
       "  145   26.314551   10.281631  8.814265  28.874692  14.235764  \n",
       "  146   25.012323   10.432000  8.814265  29.061911  14.235764  \n",
       "  147   25.822744   10.290506  8.814265  29.906631  14.235764  \n",
       "  148   28.844544   10.532204  8.814265  30.429396  14.235764  \n",
       "  149   27.019778   10.209006  8.814265  29.383430  14.235764  \n",
       "  150   26.051077   10.139574  8.814265  29.339722  14.235764  \n",
       "  151   25.213748   10.081484  8.814265  28.788537  14.235764  \n",
       "  152   24.318990    9.874215  8.814265  27.507243  14.235764  \n",
       "  153   24.819897    9.889110  8.814265  28.328177  14.235764  \n",
       "  154   24.346851    9.853494  8.814265  28.340334  14.235764  \n",
       "  155   23.932856    9.973909  8.814265  28.507692  14.235764  \n",
       "  156   26.111156   10.270707  8.814265  28.651813  14.235764  \n",
       "  157   25.479075   10.257135  8.814265  29.143265  14.235764  \n",
       "  158   25.801942   10.187586  8.814265  29.632461  14.235764  \n",
       "  159   25.664830   10.265993  8.814265  29.271734  14.235764  \n",
       "  160   25.198314   10.034894  8.814265  27.544063  14.235764  \n",
       "  161   24.480279   10.165779  8.814265  28.425977  14.235764  \n",
       "  162   24.726766   10.144531  8.814265  28.764805  14.235764  \n",
       "  163   28.097376   10.358832  8.814265  30.602285  14.235764  \n",
       "  164   23.866035    9.909740  8.814265  27.774346  14.235764  \n",
       "  165   24.639240    9.871462  8.814265  27.841523  14.235764  \n",
       "  166   25.086030    9.826342  8.814265  28.509951  14.235764  \n",
       "  167   24.234784    9.868124  8.814265  28.763956  14.235764  \n",
       "  168   25.034812   10.297002  8.814265  28.460222  14.235764  \n",
       "  169   25.963122   10.276287  8.814265  28.640667  14.235764  \n",
       "  170   24.849212   10.479728  8.814265  29.957750  14.235764  \n",
       "  171   24.980646   10.366513  8.814265  29.932424  14.235764  \n",
       "  172   25.509128   10.125141  8.814265  28.191319  14.235764  \n",
       "  173   24.371894   10.193334  8.814265  28.162959  14.235764  \n",
       "  174   25.940084   10.147507  8.814265  28.919005  14.235764  \n",
       "  175   25.120077   10.088078  8.814265  29.284897  14.235764  \n",
       "  176   24.605036    9.828307  8.814265  27.223855  14.235764  \n",
       "  177   24.181522    9.820546  8.814265  27.840683  14.235764  \n",
       "  178   23.682790    9.973673  8.814265  27.869645  14.235764  \n",
       "  179   24.262929    9.885332  8.814265  28.714076  14.235764  )]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = record_df.groupby('layer')\n",
    "\n",
    "grouped_dfs = []\n",
    "\n",
    "for layer, group in grouped:\n",
    "    group_name = f\"group_layer_{layer}\"\n",
    "    group_df = pd.DataFrame(group)\n",
    "    grouped_dfs.append((group_name, group_df))\n",
    "\n",
    "grouped_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d76ad75a-7fb2-4999-aa91-d89ad9d3649d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>units</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>train_mae</th>\n",
       "      <th>train_mape</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>test_mae</th>\n",
       "      <th>test_mape</th>\n",
       "      <th>test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>7.192100</td>\n",
       "      <td>27.529499</td>\n",
       "      <td>10.500989</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>31.479830</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>256</td>\n",
       "      <td>7.462074</td>\n",
       "      <td>28.652731</td>\n",
       "      <td>10.554290</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>31.279179</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>7.272233</td>\n",
       "      <td>27.055231</td>\n",
       "      <td>10.599528</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>31.213132</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>256</td>\n",
       "      <td>7.392141</td>\n",
       "      <td>27.749807</td>\n",
       "      <td>10.680265</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>31.111485</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>7.322351</td>\n",
       "      <td>27.779439</td>\n",
       "      <td>10.522661</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>31.095123</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>7.237823</td>\n",
       "      <td>27.277425</td>\n",
       "      <td>10.528871</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>31.021020</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>256</td>\n",
       "      <td>7.259961</td>\n",
       "      <td>27.405271</td>\n",
       "      <td>10.537173</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>30.765551</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>7.083694</td>\n",
       "      <td>26.455870</td>\n",
       "      <td>10.361026</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>30.739605</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>7.145233</td>\n",
       "      <td>25.219256</td>\n",
       "      <td>10.379192</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>30.553156</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>5</td>\n",
       "      <td>256</td>\n",
       "      <td>7.185576</td>\n",
       "      <td>26.908156</td>\n",
       "      <td>10.462467</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>30.513480</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>7.180126</td>\n",
       "      <td>26.792330</td>\n",
       "      <td>10.429300</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>30.474880</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>20</td>\n",
       "      <td>256</td>\n",
       "      <td>6.967438</td>\n",
       "      <td>25.911349</td>\n",
       "      <td>10.135960</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>30.285233</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>7.116014</td>\n",
       "      <td>26.275605</td>\n",
       "      <td>10.413264</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>30.223823</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>7.197142</td>\n",
       "      <td>27.096331</td>\n",
       "      <td>10.404793</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>30.219758</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>7.148702</td>\n",
       "      <td>26.795840</td>\n",
       "      <td>10.259445</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>30.185553</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>7.272090</td>\n",
       "      <td>27.034876</td>\n",
       "      <td>10.227498</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>30.126864</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>20</td>\n",
       "      <td>256</td>\n",
       "      <td>7.176427</td>\n",
       "      <td>26.888245</td>\n",
       "      <td>10.400428</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>30.111393</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>7.123043</td>\n",
       "      <td>25.415978</td>\n",
       "      <td>10.350587</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>30.050698</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>7.052067</td>\n",
       "      <td>26.007530</td>\n",
       "      <td>10.312518</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>30.027556</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>20</td>\n",
       "      <td>128</td>\n",
       "      <td>6.962858</td>\n",
       "      <td>25.747737</td>\n",
       "      <td>10.143605</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>29.797477</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>7.324462</td>\n",
       "      <td>25.750232</td>\n",
       "      <td>10.385632</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>29.780975</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>20</td>\n",
       "      <td>64</td>\n",
       "      <td>6.987978</td>\n",
       "      <td>25.994223</td>\n",
       "      <td>10.097107</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>29.735705</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>5</td>\n",
       "      <td>256</td>\n",
       "      <td>7.100760</td>\n",
       "      <td>26.057661</td>\n",
       "      <td>10.220246</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>29.716280</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>20</td>\n",
       "      <td>128</td>\n",
       "      <td>7.300978</td>\n",
       "      <td>27.096111</td>\n",
       "      <td>10.173240</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>29.676947</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>7.096948</td>\n",
       "      <td>26.304275</td>\n",
       "      <td>10.276248</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>29.661706</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>6.992162</td>\n",
       "      <td>25.799766</td>\n",
       "      <td>10.172763</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>29.562244</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2</td>\n",
       "      <td>512</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>7.001943</td>\n",
       "      <td>25.576678</td>\n",
       "      <td>10.156598</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>29.533538</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>7.092328</td>\n",
       "      <td>25.130698</td>\n",
       "      <td>10.253815</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>29.503411</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>7.018354</td>\n",
       "      <td>25.579825</td>\n",
       "      <td>10.216839</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>29.487509</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>20</td>\n",
       "      <td>128</td>\n",
       "      <td>6.964567</td>\n",
       "      <td>25.647217</td>\n",
       "      <td>10.024109</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>29.395887</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>6.863499</td>\n",
       "      <td>24.326919</td>\n",
       "      <td>10.107742</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>29.356769</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>7.087594</td>\n",
       "      <td>25.637767</td>\n",
       "      <td>10.283868</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>29.350942</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>20</td>\n",
       "      <td>64</td>\n",
       "      <td>7.019327</td>\n",
       "      <td>25.728413</td>\n",
       "      <td>9.945126</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>29.345483</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>7.146898</td>\n",
       "      <td>25.949591</td>\n",
       "      <td>10.228700</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>29.312372</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>20</td>\n",
       "      <td>256</td>\n",
       "      <td>6.972286</td>\n",
       "      <td>25.741974</td>\n",
       "      <td>9.967084</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>29.277208</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>6.990259</td>\n",
       "      <td>25.783360</td>\n",
       "      <td>10.104160</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>29.269952</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>6.962783</td>\n",
       "      <td>24.598625</td>\n",
       "      <td>10.166634</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>29.267249</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>7.252266</td>\n",
       "      <td>25.033852</td>\n",
       "      <td>10.467559</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>29.266971</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>7.388790</td>\n",
       "      <td>25.046432</td>\n",
       "      <td>10.583962</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>29.229119</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>20</td>\n",
       "      <td>256</td>\n",
       "      <td>6.914530</td>\n",
       "      <td>25.120828</td>\n",
       "      <td>10.012789</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>29.227862</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2</td>\n",
       "      <td>512</td>\n",
       "      <td>20</td>\n",
       "      <td>128</td>\n",
       "      <td>6.938877</td>\n",
       "      <td>25.207227</td>\n",
       "      <td>10.036363</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>29.203692</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>7.072593</td>\n",
       "      <td>26.071551</td>\n",
       "      <td>10.163736</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>29.202759</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>7.093662</td>\n",
       "      <td>25.206792</td>\n",
       "      <td>10.291629</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>29.191801</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2</td>\n",
       "      <td>512</td>\n",
       "      <td>20</td>\n",
       "      <td>256</td>\n",
       "      <td>6.903495</td>\n",
       "      <td>24.993896</td>\n",
       "      <td>9.949273</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>29.126051</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>20</td>\n",
       "      <td>128</td>\n",
       "      <td>6.813764</td>\n",
       "      <td>24.194247</td>\n",
       "      <td>9.953151</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>29.074219</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2</td>\n",
       "      <td>512</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>6.935197</td>\n",
       "      <td>25.206643</td>\n",
       "      <td>10.073517</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>29.057205</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>6.991772</td>\n",
       "      <td>24.846631</td>\n",
       "      <td>10.194695</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>28.939807</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>6.933357</td>\n",
       "      <td>24.344532</td>\n",
       "      <td>10.199606</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>28.825763</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2</td>\n",
       "      <td>512</td>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>6.990811</td>\n",
       "      <td>24.846187</td>\n",
       "      <td>10.188417</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>28.814542</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>6.939160</td>\n",
       "      <td>24.286069</td>\n",
       "      <td>10.187375</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>28.533196</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>20</td>\n",
       "      <td>64</td>\n",
       "      <td>6.922616</td>\n",
       "      <td>24.780630</td>\n",
       "      <td>9.915363</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>28.495890</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>7.273427</td>\n",
       "      <td>25.970596</td>\n",
       "      <td>10.200581</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>28.139493</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>7.064391</td>\n",
       "      <td>25.592777</td>\n",
       "      <td>10.272214</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>28.078395</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>6.803002</td>\n",
       "      <td>23.949242</td>\n",
       "      <td>9.878315</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>28.027010</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2</td>\n",
       "      <td>512</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>7.093779</td>\n",
       "      <td>25.069046</td>\n",
       "      <td>10.183953</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>28.019160</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2</td>\n",
       "      <td>512</td>\n",
       "      <td>20</td>\n",
       "      <td>64</td>\n",
       "      <td>6.831229</td>\n",
       "      <td>24.766400</td>\n",
       "      <td>9.914083</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>27.994099</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>20</td>\n",
       "      <td>64</td>\n",
       "      <td>6.915031</td>\n",
       "      <td>24.097613</td>\n",
       "      <td>9.982701</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>27.466294</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>6.800054</td>\n",
       "      <td>24.659385</td>\n",
       "      <td>9.886831</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>27.365774</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>6.765221</td>\n",
       "      <td>23.710951</td>\n",
       "      <td>9.957311</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>27.353606</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2</td>\n",
       "      <td>512</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>6.892273</td>\n",
       "      <td>24.631684</td>\n",
       "      <td>9.881731</td>\n",
       "      <td>8.814265</td>\n",
       "      <td>27.271482</td>\n",
       "      <td>14.235764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     layer  units  epochs  batch_size  train_mae  train_mape  train_rmse   \n",
       "74       2    128       5         128   7.192100   27.529499   10.500989  \\\n",
       "99       2    512       5         256   7.462074   28.652731   10.554290   \n",
       "62       2     64       5         128   7.272233   27.055231   10.599528   \n",
       "63       2     64       5         256   7.392141   27.749807   10.680265   \n",
       "60       2     64       5          32   7.322351   27.779439   10.522661   \n",
       "61       2     64       5          64   7.237823   27.277425   10.528871   \n",
       "75       2    128       5         256   7.259961   27.405271   10.537173   \n",
       "79       2    128      10         256   7.083694   26.455870   10.361026   \n",
       "65       2     64      10          64   7.145233   25.219256   10.379192   \n",
       "87       2    256       5         256   7.185576   26.908156   10.462467   \n",
       "67       2     64      10         256   7.180126   26.792330   10.429300   \n",
       "83       2    128      20         256   6.967438   25.911349   10.135960   \n",
       "66       2     64      10         128   7.116014   26.275605   10.413264   \n",
       "73       2    128       5          64   7.197142   27.096331   10.404793   \n",
       "78       2    128      10         128   7.148702   26.795840   10.259445   \n",
       "115      2   1024      10         256   7.272090   27.034876   10.227498   \n",
       "71       2     64      20         256   7.176427   26.888245   10.400428   \n",
       "98       2    512       5         128   7.123043   25.415978   10.350587   \n",
       "86       2    256       5         128   7.052067   26.007530   10.312518   \n",
       "70       2     64      20         128   6.962858   25.747737   10.143605   \n",
       "97       2    512       5          64   7.324462   25.750232   10.385632   \n",
       "69       2     64      20          64   6.987978   25.994223   10.097107   \n",
       "111      2   1024       5         256   7.100760   26.057661   10.220246   \n",
       "118      2   1024      20         128   7.300978   27.096111   10.173240   \n",
       "85       2    256       5          64   7.096948   26.304275   10.276248   \n",
       "91       2    256      10         256   6.992162   25.799766   10.172763   \n",
       "103      2    512      10         256   7.001943   25.576678   10.156598   \n",
       "77       2    128      10          64   7.092328   25.130698   10.253815   \n",
       "64       2     64      10          32   7.018354   25.579825   10.216839   \n",
       "82       2    128      20         128   6.964567   25.647217   10.024109   \n",
       "68       2     64      20          32   6.863499   24.326919   10.107742   \n",
       "72       2    128       5          32   7.087594   25.637767   10.283868   \n",
       "81       2    128      20          64   7.019327   25.728413    9.945126   \n",
       "109      2   1024       5          64   7.146898   25.949591   10.228700   \n",
       "119      2   1024      20         256   6.972286   25.741974    9.967084   \n",
       "90       2    256      10         128   6.990259   25.783360   10.104160   \n",
       "76       2    128      10          32   6.962783   24.598625   10.166634   \n",
       "84       2    256       5          32   7.252266   25.033852   10.467559   \n",
       "96       2    512       5          32   7.388790   25.046432   10.583962   \n",
       "95       2    256      20         256   6.914530   25.120828   10.012789   \n",
       "106      2    512      20         128   6.938877   25.207227   10.036363   \n",
       "89       2    256      10          64   7.072593   26.071551   10.163736   \n",
       "110      2   1024       5         128   7.093662   25.206792   10.291629   \n",
       "107      2    512      20         256   6.903495   24.993896    9.949273   \n",
       "94       2    256      20         128   6.813764   24.194247    9.953151   \n",
       "101      2    512      10          64   6.935197   25.206643   10.073517   \n",
       "113      2   1024      10          64   6.991772   24.846631   10.194695   \n",
       "114      2   1024      10         128   6.933357   24.344532   10.199606   \n",
       "102      2    512      10         128   6.990811   24.846187   10.188417   \n",
       "88       2    256      10          32   6.939160   24.286069   10.187375   \n",
       "93       2    256      20          64   6.922616   24.780630    9.915363   \n",
       "112      2   1024      10          32   7.273427   25.970596   10.200581   \n",
       "108      2   1024       5          32   7.064391   25.592777   10.272214   \n",
       "80       2    128      20          32   6.803002   23.949242    9.878315   \n",
       "100      2    512      10          32   7.093779   25.069046   10.183953   \n",
       "105      2    512      20          64   6.831229   24.766400    9.914083   \n",
       "117      2   1024      20          64   6.915031   24.097613    9.982701   \n",
       "116      2   1024      20          32   6.800054   24.659385    9.886831   \n",
       "92       2    256      20          32   6.765221   23.710951    9.957311   \n",
       "104      2    512      20          32   6.892273   24.631684    9.881731   \n",
       "\n",
       "     test_mae  test_mape  test_rmse  \n",
       "74   8.814265  31.479830  14.235764  \n",
       "99   8.814265  31.279179  14.235764  \n",
       "62   8.814265  31.213132  14.235764  \n",
       "63   8.814265  31.111485  14.235764  \n",
       "60   8.814265  31.095123  14.235764  \n",
       "61   8.814265  31.021020  14.235764  \n",
       "75   8.814265  30.765551  14.235764  \n",
       "79   8.814265  30.739605  14.235764  \n",
       "65   8.814265  30.553156  14.235764  \n",
       "87   8.814265  30.513480  14.235764  \n",
       "67   8.814265  30.474880  14.235764  \n",
       "83   8.814265  30.285233  14.235764  \n",
       "66   8.814265  30.223823  14.235764  \n",
       "73   8.814265  30.219758  14.235764  \n",
       "78   8.814265  30.185553  14.235764  \n",
       "115  8.814265  30.126864  14.235764  \n",
       "71   8.814265  30.111393  14.235764  \n",
       "98   8.814265  30.050698  14.235764  \n",
       "86   8.814265  30.027556  14.235764  \n",
       "70   8.814265  29.797477  14.235764  \n",
       "97   8.814265  29.780975  14.235764  \n",
       "69   8.814265  29.735705  14.235764  \n",
       "111  8.814265  29.716280  14.235764  \n",
       "118  8.814265  29.676947  14.235764  \n",
       "85   8.814265  29.661706  14.235764  \n",
       "91   8.814265  29.562244  14.235764  \n",
       "103  8.814265  29.533538  14.235764  \n",
       "77   8.814265  29.503411  14.235764  \n",
       "64   8.814265  29.487509  14.235764  \n",
       "82   8.814265  29.395887  14.235764  \n",
       "68   8.814265  29.356769  14.235764  \n",
       "72   8.814265  29.350942  14.235764  \n",
       "81   8.814265  29.345483  14.235764  \n",
       "109  8.814265  29.312372  14.235764  \n",
       "119  8.814265  29.277208  14.235764  \n",
       "90   8.814265  29.269952  14.235764  \n",
       "76   8.814265  29.267249  14.235764  \n",
       "84   8.814265  29.266971  14.235764  \n",
       "96   8.814265  29.229119  14.235764  \n",
       "95   8.814265  29.227862  14.235764  \n",
       "106  8.814265  29.203692  14.235764  \n",
       "89   8.814265  29.202759  14.235764  \n",
       "110  8.814265  29.191801  14.235764  \n",
       "107  8.814265  29.126051  14.235764  \n",
       "94   8.814265  29.074219  14.235764  \n",
       "101  8.814265  29.057205  14.235764  \n",
       "113  8.814265  28.939807  14.235764  \n",
       "114  8.814265  28.825763  14.235764  \n",
       "102  8.814265  28.814542  14.235764  \n",
       "88   8.814265  28.533196  14.235764  \n",
       "93   8.814265  28.495890  14.235764  \n",
       "112  8.814265  28.139493  14.235764  \n",
       "108  8.814265  28.078395  14.235764  \n",
       "80   8.814265  28.027010  14.235764  \n",
       "100  8.814265  28.019160  14.235764  \n",
       "105  8.814265  27.994099  14.235764  \n",
       "117  8.814265  27.466294  14.235764  \n",
       "116  8.814265  27.365774  14.235764  \n",
       "92   8.814265  27.353606  14.235764  \n",
       "104  8.814265  27.271482  14.235764  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_name = 'group_layer_2'\n",
    "group_df = next(df for name, df in grouped_dfs if name == group_name)\n",
    "# print(group_df)\n",
    "sorted_group_df = group_df[['layer', 'units', 'epochs', 'batch_size', 'train_mae', 'train_mape', 'train_rmse', 'test_mae', 'test_mape', 'test_rmse']]\n",
    "\n",
    "\n",
    "sorted_group_df = sorted_group_df.sort_values(by=['test_mae', 'test_mape', 'test_rmse'], ascending=[False, False, False])\n",
    "sorted_group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b249691e-5842-4b36-964a-8049ad931ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'layer': 1, 'units': 64, 'epochs': 20, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.968047618865967, 'train_mape': 25.477999448776245, 'train_rmse': 10.148047318567391, 'test_mae': 8.814265251159668, 'test_mape': 28.289160132408142, 'test_rmse': 14.235763666311897}]\n",
      "[{'layer': 1, 'units': 128, 'epochs': 20, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.963493824005127, 'train_mape': 25.177636742591858, 'train_rmse': 10.078141276028523, 'test_mae': 8.814265251159668, 'test_mape': 27.83121168613434, 'test_rmse': 14.235763666311897}]\n",
      "[{'layer': 1, 'units': 256, 'epochs': 20, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.901322841644287, 'train_mape': 25.18732249736786, 'train_rmse': 10.020196356457925, 'test_mae': 8.814265251159668, 'test_mape': 28.56670320034027, 'test_rmse': 14.235763666311897}]\n",
      "[{'layer': 1, 'units': 512, 'epochs': 20, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.961170673370361, 'train_mape': 25.484171509742737, 'train_rmse': 9.988876641303355, 'test_mae': 8.814265251159668, 'test_mape': 27.950018644332886, 'test_rmse': 14.235763666311897}]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "layer_to_test = 1\n",
    "epoch_to_test = 20\n",
    "batch_size_to_test = 64\n",
    "\n",
    "# 要看的項目變動，其他不動\n",
    "unit_numbers = [64, 128, 256, 512]  \n",
    "mae_scores = []\n",
    "mape_scores = []\n",
    "rmse_score = []\n",
    "\n",
    "for unit_num in unit_numbers:\n",
    "    # 過濾 找出藥用的\n",
    "    filtered_records = [record for record in all_record if \n",
    "                        record[\"batch_size\"] == batch_size_to_test and\n",
    "                        record[\"epochs\"] == epoch_to_test and\n",
    "                        record[\"units\"] == unit_num and\n",
    "                        record[\"layer\"] == layer_to_test]\n",
    "    print(filtered_records)\n",
    "    mae_scores.append([record[\"train_mae\"] for record in filtered_records][0])\n",
    "    mape_scores.append([record[\"train_mape\"] for record in filtered_records][0])\n",
    "    rmse_score.append([record[\"train_rmse\"] for record in filtered_records][0])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(unit_numbers, mae_scores, marker='o', label=\"MAE\")\n",
    "plt.plot(unit_numbers, mape_scores, marker='o', label=\"MAPE\")\n",
    "plt.plot(unit_numbers, rmse_score, marker='o', label=\"RMSE\")\n",
    "\n",
    "\n",
    "plt.xlabel('Units')\n",
    "plt.ylabel('performance')\n",
    "plt.title('The change of units influence the performance.')\n",
    "plt.grid(True)\n",
    "plt.legend(loc = 'lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "143c3ac8-09ad-473b-8363-25eb77339286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'layer': 1, 'units': 128, 'epochs': 5, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.220568656921387, 'train_mape': 26.94985568523407, 'train_rmse': 10.534756492693676, 'test_mae': 8.814265251159668, 'test_mape': 30.033284425735474, 'test_rmse': 14.235763666311897}]\n",
      "[{'layer': 1, 'units': 128, 'epochs': 10, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.043642044067383, 'train_mape': 25.845202803611755, 'train_rmse': 10.253259652232247, 'test_mae': 8.814265251159668, 'test_mape': 28.823009133338928, 'test_rmse': 14.235763666311897}]\n",
      "[{'layer': 1, 'units': 128, 'epochs': 20, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.963493824005127, 'train_mape': 25.177636742591858, 'train_rmse': 10.078141276028523, 'test_mae': 8.814265251159668, 'test_mape': 27.83121168613434, 'test_rmse': 14.235763666311897}]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "layer_to_test = 1\n",
    "epoch_to_test = [5, 10, 20]\n",
    "batch_size_to_test = 64\n",
    "\n",
    "# 要看的項目變動，其他不動\n",
    "unit_numbers = 128  \n",
    "mae_scores = []\n",
    "mape_scores = []\n",
    "rmse_score = []\n",
    "\n",
    "for epo in epoch_to_test:\n",
    "    # 過濾 找出藥用的\n",
    "    filtered_records = [record for record in all_record if \n",
    "                        record[\"batch_size\"] == batch_size_to_test and\n",
    "                        record[\"epochs\"] == epo and\n",
    "                        record[\"units\"] == unit_numbers and\n",
    "                        record[\"layer\"] == layer_to_test]\n",
    "    print(filtered_records)\n",
    "    mae_scores.append([record[\"train_mae\"] for record in filtered_records][0])\n",
    "    mape_scores.append([record[\"train_mape\"] for record in filtered_records][0])\n",
    "    rmse_score.append([record[\"train_rmse\"] for record in filtered_records][0])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epoch_to_test, mae_scores, marker='o', label=\"MAE\")\n",
    "plt.plot(epoch_to_test, mape_scores, marker='o', label=\"MAPE\")\n",
    "plt.plot(epoch_to_test, rmse_score, marker='o', label=\"RMSE\")\n",
    "\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('performance')\n",
    "plt.title('The change of epoch influence the performance.')\n",
    "plt.grid(True)\n",
    "plt.legend(loc = 'lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2033d60c-6c8c-46ed-92f9-03180a751408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'layer': 1, 'units': 128, 'epochs': 10, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.043642044067383, 'train_mape': 25.845202803611755, 'train_rmse': 10.253259652232247, 'test_mae': 8.814265251159668, 'test_mape': 28.823009133338928, 'test_rmse': 14.235763666311897}]\n",
      "[{'layer': 2, 'units': 128, 'epochs': 10, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.09232759475708, 'train_mape': 25.130698084831238, 'train_rmse': 10.253815103761571, 'test_mae': 8.814265251159668, 'test_mape': 29.503411054611206, 'test_rmse': 14.235763666311897}]\n",
      "[{'layer': 3, 'units': 128, 'epochs': 10, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 6.996908664703369, 'train_mape': 25.475308299064636, 'train_rmse': 10.130842618853022, 'test_mae': 8.814265251159668, 'test_mape': 29.1251003742218, 'test_rmse': 14.235763666311897}]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "layer_to_test = [1, 2, 3]\n",
    "epoch_to_test = 10\n",
    "batch_size_to_test = 64\n",
    "\n",
    "# 要看的項目變動，其他不動\n",
    "unit_numbers = 128  \n",
    "mae_scores = []\n",
    "mape_scores = []\n",
    "rmse_score = []\n",
    "\n",
    "for lay in layer_to_test:\n",
    "    # 過濾 找出藥用的\n",
    "    filtered_records = [record for record in all_record if \n",
    "                        record[\"batch_size\"] == batch_size_to_test and\n",
    "                        record[\"epochs\"] == epoch_to_test and\n",
    "                        record[\"units\"] == unit_numbers and\n",
    "                        record[\"layer\"] == lay]\n",
    "    print(filtered_records)\n",
    "    mae_scores.append([record[\"train_mae\"] for record in filtered_records][0])\n",
    "    mape_scores.append([record[\"train_mape\"] for record in filtered_records][0])\n",
    "    rmse_score.append([record[\"train_rmse\"] for record in filtered_records][0])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(layer_to_test, mae_scores, marker='o', label=\"MAE\")\n",
    "plt.plot(layer_to_test, mape_scores, marker='o', label=\"MAPE\")\n",
    "plt.plot(layer_to_test, rmse_score, marker='o', label=\"RMSE\")\n",
    "\n",
    "\n",
    "plt.xlabel('layer')\n",
    "plt.ylabel('performance')\n",
    "plt.title('The change of layer influence the performance.')\n",
    "plt.grid(True)\n",
    "plt.legend(loc = 'upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0a1b63cc-0043-437d-92dc-bb85e4c9f9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'layer': 1, 'units': 128, 'epochs': 10, 'batch_size': 32, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.095277786254883, 'train_mape': 25.828048586845398, 'train_rmse': 10.193871874989942, 'test_mae': 8.814265251159668, 'test_mape': 29.000866413116455, 'test_rmse': 14.235763666311897}]\n",
      "[{'layer': 1, 'units': 128, 'epochs': 10, 'batch_size': 64, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.043642044067383, 'train_mape': 25.845202803611755, 'train_rmse': 10.253259652232247, 'test_mae': 8.814265251159668, 'test_mape': 28.823009133338928, 'test_rmse': 14.235763666311897}]\n",
      "[{'layer': 1, 'units': 128, 'epochs': 10, 'batch_size': 128, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.164577960968018, 'train_mape': 26.71564221382141, 'train_rmse': 10.44126120772343, 'test_mae': 8.814265251159668, 'test_mape': 29.501613974571228, 'test_rmse': 14.235763666311897}]\n",
      "[{'layer': 1, 'units': 128, 'epochs': 10, 'batch_size': 256, 'activation': 'relu', 'optimizer': 'adam', 'train_mae': 7.4119181632995605, 'train_mape': 27.51193940639496, 'train_rmse': 10.663534857024318, 'test_mae': 8.814265251159668, 'test_mape': 30.415084958076477, 'test_rmse': 14.235763666311897}]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "layer_to_test = 1\n",
    "epoch_to_test = 10\n",
    "batch_size_to_test = [32, 64, 128, 256]\n",
    "\n",
    "# 要看的項目變動，其他不動\n",
    "unit_numbers = 128  \n",
    "mae_scores = []\n",
    "mape_scores = []\n",
    "rmse_score = []\n",
    "\n",
    "for bat in batch_size_to_test:\n",
    "    # 過濾 找出藥用的\n",
    "    filtered_records = [record for record in all_record if \n",
    "                        record[\"batch_size\"] == bat and\n",
    "                        record[\"epochs\"] == epoch_to_test and\n",
    "                        record[\"units\"] == unit_numbers and\n",
    "                        record[\"layer\"] == layer_to_test]\n",
    "    print(filtered_records)\n",
    "    mae_scores.append([record[\"train_mae\"] for record in filtered_records][0])\n",
    "    mape_scores.append([record[\"train_mape\"] for record in filtered_records][0])\n",
    "    rmse_score.append([record[\"train_rmse\"] for record in filtered_records][0])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(batch_size_to_test, mae_scores, marker='o', label=\"MAE\")\n",
    "plt.plot(batch_size_to_test, mape_scores, marker='o', label=\"MAPE\")\n",
    "plt.plot(batch_size_to_test, rmse_score, marker='o', label=\"RMSE\")\n",
    "\n",
    "\n",
    "plt.xlabel('batch_size')\n",
    "plt.ylabel('performance')\n",
    "plt.title('The change of batch size influence the performance.')\n",
    "plt.grid(True)\n",
    "plt.legend(loc = 'upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "25cc5907-34b1-4b0e-b6f1-7177af19d345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# train_data_path = \"./adult/adult.data\"\n",
    "\n",
    "# column_name = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', 'relationship', 'race', 'sex', \n",
    "#                'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income']\n",
    "\n",
    "# aaaa = pd.read_csv(train_data_path, names = column_name)\n",
    "\n",
    "# print(\"trian data shape: \", train_data_df.shape)\n",
    "# print(\"test data shape: \", test_data_df.shape)\n",
    "\n",
    "# #測試資料的第一row非資料內容，移除掉\n",
    "# print(\"Train features shape:\", train_data_df.shape)\n",
    "# print(\"Test features shape:\", test_data_df.shape)\n",
    "\n",
    "# test_data_df = test_data_df.drop(test_data_df.index[0])\n",
    "# test_data_df.reset_index(drop=True, inplace=True)\n",
    "# test_data_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
